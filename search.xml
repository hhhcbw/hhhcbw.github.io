<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>深度学习(六)——GoogleNet+Pytorch实现</title>
      <link href="/2022/01/11/DL6_GoogleNet/"/>
      <url>/2022/01/11/DL6_GoogleNet/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>inception（也称GoogLeNet）是2014年Christian Szegedy提出的一种全新的深度学习结构，在这之前的AlexNet、VGG等结构都是通过增大网络的深度（层数）来获得更好的训练效果，但层数的增加会带来很多负作用，比如overfit、梯度消失、梯度爆炸等。inception的提出则从另一种角度来提升训练结果：能更高效的利用计算资源，在相同的计算量下能提取到更多的特征，从而提升训练结果。</p><span id="more"></span><hr><h1 id="Inception模块"><a href="#Inception模块" class="headerlink" title="Inception模块"></a>Inception模块</h1><h2 id="为什么要提出Inception"><a href="#为什么要提出Inception" class="headerlink" title="为什么要提出Inception?"></a>为什么要提出Inception?</h2><p>一般来说，提升网络性能最直接的办法就是增加网络深度和宽度，但一味地增加，会带来诸多问题：<br>1）参数太多，如果训练数据集有限，很容易产生过拟合；<br>2）网络越大、参数越多，计算复杂度越大，难以应用；<br>3）网络越深，容易出现梯度弥散问题（梯度越往后穿越容易消失），难以优化模型。<br>我们希望在增加网络深度和宽度的同时减少参数，为了减少参数，自然就想到将全连接变成稀疏连接。但是在实现上，全连接变成稀疏连接后实际计算量并不会有质的提升，因为大部分硬件是针对密集矩阵计算优化的，稀疏矩阵虽然数据量少，但是计算所消耗的时间却很难减少。在这种需求和形势下，Google研究人员提出了Inception的方法。</p><h2 id="什么是Inception"><a href="#什么是Inception" class="headerlink" title="什么是Inception?"></a>什么是Inception?</h2><p>Inception就是把多个卷积或池化操作，放在一起组装成一个网络模块，设计神经网络时以模块为单位去组装整个网络结构。模块如下图所示<br><img src="https://img-blog.csdnimg.cn/24a0ad63c76c4d25be9080b100d228aa.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>在未使用这种方式的网络里，我们一层往往只使用一种操作，比如卷积或者池化，而且卷积操作的卷积核尺寸也是固定大小的。但是，在实际情况下，在不同尺度的图片里，需要不同大小的卷积核，这样才能使性能最好，或者或，对于同一张图片，不同尺寸的卷积核的表现效果是不一样的，因为他们的感受野不同。所以，我们希望让网络自己去选择，Inception便能够满足这样的需求，一个Inception模块中并列提供多种卷积核的操作，网络在训练的过程中通过调节参数自己去选择使用，同时，由于网络中都需要池化操作，所以此处也把池化层并列加入网络中。</p><h2 id="实际中需要什么样的Inception"><a href="#实际中需要什么样的Inception" class="headerlink" title="实际中需要什么样的Inception?"></a>实际中需要什么样的Inception?</h2><p>我们在上面提供了一种Inception的结构，但是这个结构存在很多问题，是不能够直接使用的。首要问题就是参数太多，导致特征图厚度太大。为了解决这个问题，作者在其中加入了1X1的卷积核，改进后的Inception结构如下图<br><img src="https://img-blog.csdnimg.cn/30b36247b3744f70b2b0dffb317db1be.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>这样做有两个好处，首先是大大减少了参数量，其次，增加的1X1卷积后面也会跟着有非线性激励，这样同时也能够提升网络的表达能力。</p><hr><h1 id="整体网络结构设计"><a href="#整体网络结构设计" class="headerlink" title="整体网络结构设计"></a>整体网络结构设计</h1><p><img src="https://img-blog.csdnimg.cn/e0a1938b050e4ac1a059d5762b077b6b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/871803efec7b48cc82193ba3f078a842.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>对上图说明如下：<br>1）GoogLeNet采用了模块化的结构（Inception结构），方便增添和修改；<br>2）网络最后采用了average pooling（平均池化）来代替全连接层，该想法来自NIN（Network in Network），事实证明这样可以将准确率提高0.6%。<br>3）虽然移除了全连接，但是网络中依然使用了Dropout ;<br>4）为了避免梯度消失，网络额外增加了2个辅助的softmax用于向前传导梯度（辅助分类器）<br>对于前三点都很好理解，下面我们重点看一下第4点。这里的辅助分类器只是在训练时使用，在正常预测时会被去掉。辅助分类器促进了更稳定的学习和更好的收敛，往往在接近训练结束时，辅助分支网络开始超越没有任何分支的网络的准确性，达到了更高的水平。</p><hr><h1 id="Pytorch实现"><a href="#Pytorch实现" class="headerlink" title="Pytorch实现"></a>Pytorch实现</h1><p>从<a href="http://download.tensorflow.org/example_images/flower_photos.tgz">http://download.tensorflow.org/example_images/flower_photos.tgz</a>下载数据集<br>执行下面代码，将数据集划分为训练集与验证集。<br><strong>split_data.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> shutil <span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mkfile</span>(<span class="params">file</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file):</span><br><span class="line">        os.makedirs(file)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">file = <span class="string">&#x27;flower_data/flower_photos&#x27;</span></span><br><span class="line">flower_class = [cla <span class="keyword">for</span> cla <span class="keyword">in</span> os.listdir(file) <span class="keyword">if</span> <span class="string">&quot;.txt&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> cla]</span><br><span class="line">mkfile(<span class="string">&#x27;flower_data/train&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">    mkfile(<span class="string">&#x27;flower_data/train/&#x27;</span>+cla)</span><br><span class="line"></span><br><span class="line">mkfile(<span class="string">&#x27;flower_data/val&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">    mkfile(<span class="string">&#x27;flower_data/val/&#x27;</span>+cla)</span><br><span class="line"></span><br><span class="line">split_rate = <span class="number">0.1</span></span><br><span class="line"><span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">    cla_path = file + <span class="string">&#x27;/&#x27;</span> + cla + <span class="string">&#x27;/&#x27;</span></span><br><span class="line">    images = os.listdir(cla_path)</span><br><span class="line">    num = <span class="built_in">len</span>(images)</span><br><span class="line">    eval_index = random.sample(images, k=<span class="built_in">int</span>(num*split_rate))</span><br><span class="line">    <span class="keyword">for</span> index, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(images):</span><br><span class="line">        <span class="keyword">if</span> image <span class="keyword">in</span> eval_index:</span><br><span class="line">            image_path = cla_path + image</span><br><span class="line">            new_path = <span class="string">&#x27;flower_data/val/&#x27;</span> + cla</span><br><span class="line">            copy(image_path, new_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            image_path = cla_path + image</span><br><span class="line">            new_path = <span class="string">&#x27;flower_data/train/&#x27;</span> + cla</span><br><span class="line">            copy(image_path, new_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\r[&#123;&#125;] processing [&#123;&#125;/&#123;&#125;]&quot;</span>.<span class="built_in">format</span>(cla, index+<span class="number">1</span>, num), end=<span class="string">&quot;&quot;</span>)  <span class="comment"># processing bar</span></span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;processing done!&quot;</span>)</span><br></pre></td></tr></table></figure><p><strong>model.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GoogLeNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes=<span class="number">1000</span>, aux_logits=<span class="literal">True</span>, init_weights=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(GoogLeNet, self).__init__()</span><br><span class="line">        self.aux_logits = aux_logits</span><br><span class="line"></span><br><span class="line">        self.conv1 = BasicConv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>)</span><br><span class="line">        self.maxpool1 = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.conv2 = BasicConv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.conv3 = BasicConv2d(<span class="number">64</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.maxpool2 = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.inception3a = Inception(<span class="number">192</span>, <span class="number">64</span>, <span class="number">96</span>, <span class="number">128</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">        self.inception3b = Inception(<span class="number">256</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="number">192</span>, <span class="number">32</span>, <span class="number">96</span>, <span class="number">64</span>)</span><br><span class="line">        self.maxpool3 = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.inception4a = Inception(<span class="number">480</span>, <span class="number">192</span>, <span class="number">96</span>, <span class="number">208</span>, <span class="number">16</span>, <span class="number">48</span>, <span class="number">64</span>)</span><br><span class="line">        self.inception4b = Inception(<span class="number">512</span>, <span class="number">160</span>, <span class="number">112</span>, <span class="number">224</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">        self.inception4c = Inception(<span class="number">512</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">        self.inception4d = Inception(<span class="number">512</span>, <span class="number">112</span>, <span class="number">144</span>, <span class="number">288</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">        self.inception4e = Inception(<span class="number">528</span>, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">        self.maxpool4 = nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.inception5a = Inception(<span class="number">832</span>, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">        self.inception5b = Inception(<span class="number">832</span>, <span class="number">384</span>, <span class="number">192</span>, <span class="number">384</span>, <span class="number">48</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.aux_logits:</span><br><span class="line">            self.aux1 = InceptionAux(<span class="number">512</span>, num_classes)</span><br><span class="line">            self.aux2 = InceptionAux(<span class="number">528</span>, num_classes)</span><br><span class="line"></span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.dropout = nn.Dropout(<span class="number">0.4</span>)</span><br><span class="line">        self.fc = nn.Linear(<span class="number">1024</span>, num_classes)</span><br><span class="line">        <span class="keyword">if</span> init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># N x 3 x 224 x 224</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="comment"># N x 64 x 112 x 112</span></span><br><span class="line">        x = self.maxpool1(x)</span><br><span class="line">        <span class="comment"># N x 64 x 56 x 56</span></span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        <span class="comment"># N x 64 x 56 x 56</span></span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        <span class="comment"># N x 192 x 56 x 56</span></span><br><span class="line">        x = self.maxpool2(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># N x 192 x 28 x 28</span></span><br><span class="line">        x = self.inception3a(x)</span><br><span class="line">        <span class="comment"># N x 256 x 28 x 28</span></span><br><span class="line">        x = self.inception3b(x)</span><br><span class="line">        <span class="comment"># N x 480 x 28 x 28</span></span><br><span class="line">        x = self.maxpool3(x)</span><br><span class="line">        <span class="comment"># N x 480 x 14 x 14</span></span><br><span class="line">        x = self.inception4a(x)</span><br><span class="line">        <span class="comment"># N x 512 x 14 x 14</span></span><br><span class="line">        <span class="keyword">if</span> self.training <span class="keyword">and</span> self.aux_logits:    <span class="comment"># eval model lose this layer</span></span><br><span class="line">            aux1 = self.aux1(x)</span><br><span class="line"></span><br><span class="line">        x = self.inception4b(x)</span><br><span class="line">        <span class="comment"># N x 512 x 14 x 14</span></span><br><span class="line">        x = self.inception4c(x)</span><br><span class="line">        <span class="comment"># N x 512 x 14 x 14</span></span><br><span class="line">        x = self.inception4d(x)</span><br><span class="line">        <span class="comment"># N x 528 x 14 x 14</span></span><br><span class="line">        <span class="keyword">if</span> self.training <span class="keyword">and</span> self.aux_logits:    <span class="comment"># eval model lose this layer</span></span><br><span class="line">            aux2 = self.aux2(x)</span><br><span class="line"></span><br><span class="line">        x = self.inception4e(x)</span><br><span class="line">        <span class="comment"># N x 832 x 14 x 14</span></span><br><span class="line">        x = self.maxpool4(x)</span><br><span class="line">        <span class="comment"># N x 832 x 7 x 7</span></span><br><span class="line">        x = self.inception5a(x)</span><br><span class="line">        <span class="comment"># N x 832 x 7 x 7</span></span><br><span class="line">        x = self.inception5b(x)</span><br><span class="line">        <span class="comment"># N x 1024 x 7 x 7</span></span><br><span class="line"></span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        <span class="comment"># N x 1024 x 1 x 1</span></span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># N x 1024</span></span><br><span class="line">        x = self.dropout(x)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="comment"># N x 1000 (num_classes)</span></span><br><span class="line">        <span class="keyword">if</span> self.training <span class="keyword">and</span> self.aux_logits:   <span class="comment"># eval model lose this layer</span></span><br><span class="line">            <span class="keyword">return</span> x, aux2, aux1</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_initialize_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#inception结构</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Inception</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Inception, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.branch2 = nn.Sequential(</span><br><span class="line">            BasicConv2d(in_channels, ch3x3red, kernel_size=<span class="number">1</span>),</span><br><span class="line">            BasicConv2d(ch3x3red, ch3x3, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)   <span class="comment"># 保证输出大小等于输入大小</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.branch3 = nn.Sequential(</span><br><span class="line">            BasicConv2d(in_channels, ch5x5red, kernel_size=<span class="number">1</span>),</span><br><span class="line">            BasicConv2d(ch5x5red, ch5x5, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)   <span class="comment"># 保证输出大小等于输入大小</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.branch4 = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            BasicConv2d(in_channels, pool_proj, kernel_size=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        branch1 = self.branch1(x)</span><br><span class="line">        branch2 = self.branch2(x)</span><br><span class="line">        branch3 = self.branch3(x)</span><br><span class="line">        branch4 = self.branch4(x)</span><br><span class="line"></span><br><span class="line">        outputs = [branch1, branch2, branch3, branch4]</span><br><span class="line">        <span class="keyword">return</span> torch.cat(outputs, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#辅助分类器</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InceptionAux</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, num_classes</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(InceptionAux, self).__init__()</span><br><span class="line">        self.averagePool = nn.AvgPool2d(kernel_size=<span class="number">5</span>, stride=<span class="number">3</span>)</span><br><span class="line">        self.conv = BasicConv2d(in_channels, <span class="number">128</span>, kernel_size=<span class="number">1</span>)  <span class="comment"># output[batch, 128, 4, 4]</span></span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">2048</span>, <span class="number">1024</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">1024</span>, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14</span></span><br><span class="line">        x = self.averagePool(x)</span><br><span class="line">        <span class="comment"># aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        <span class="comment"># N x 128 x 4 x 4</span></span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        x = F.dropout(x, <span class="number">0.5</span>, training=self.training)</span><br><span class="line">        <span class="comment"># N x 2048</span></span><br><span class="line">        x = F.relu(self.fc1(x), inplace=<span class="literal">True</span>)</span><br><span class="line">        x = F.dropout(x, <span class="number">0.5</span>, training=self.training)</span><br><span class="line">        <span class="comment"># N x 1024</span></span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="comment"># N x num_classes</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicConv2d</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(BasicConv2d, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p><strong>train.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, datasets</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> GoogLeNet</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(device)</span><br><span class="line"></span><br><span class="line">data_transform = &#123;</span><br><span class="line">    <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">                                 transforms.RandomHorizontalFlip(),</span><br><span class="line">                                 transforms.ToTensor(),</span><br><span class="line">                                 transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))]),</span><br><span class="line">    <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">                               transforms.ToTensor(),</span><br><span class="line">                               transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#data_root = os.path.abspath(os.path.join(os.getcwd(), &quot;../..&quot;))  # get data root path</span></span><br><span class="line">data_root = os.getcwd()</span><br><span class="line">image_path = data_root + <span class="string">&quot;/flower_data/&quot;</span>  <span class="comment"># flower data set path</span></span><br><span class="line"></span><br><span class="line">train_dataset = datasets.ImageFolder(root=image_path + <span class="string">&quot;train&quot;</span>,</span><br><span class="line">                                     transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">train_num = <span class="built_in">len</span>(train_dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &#123;&#x27;daisy&#x27;:0, &#x27;dandelion&#x27;:1, &#x27;roses&#x27;:2, &#x27;sunflower&#x27;:3, &#x27;tulips&#x27;:4&#125;</span></span><br><span class="line">flower_list = train_dataset.class_to_idx</span><br><span class="line">cla_dict = <span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> flower_list.items())</span><br><span class="line"><span class="comment"># write dict into json file</span></span><br><span class="line">json_str = json.dumps(cla_dict, indent=<span class="number">4</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    json_file.write(json_str)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                           batch_size=batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                           num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">validate_dataset = datasets.ImageFolder(root=image_path + <span class="string">&quot;val&quot;</span>,</span><br><span class="line">                                        transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line">val_num = <span class="built_in">len</span>(validate_dataset)</span><br><span class="line">validate_loader = torch.utils.data.DataLoader(validate_dataset,</span><br><span class="line">                                              batch_size=batch_size, shuffle=<span class="literal">False</span>,</span><br><span class="line">                                              num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># test_data_iter = iter(validate_loader)</span></span><br><span class="line"><span class="comment"># test_image, test_label = test_data_iter.next()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># net = torchvision.models.googlenet(num_classes=5)</span></span><br><span class="line"><span class="comment"># model_dict = net.state_dict()</span></span><br><span class="line"><span class="comment"># pretrain_model = torch.load(&quot;googlenet.pth&quot;)</span></span><br><span class="line"><span class="comment"># del_list = [&quot;aux1.fc2.weight&quot;, &quot;aux1.fc2.bias&quot;,</span></span><br><span class="line"><span class="comment">#             &quot;aux2.fc2.weight&quot;, &quot;aux2.fc2.bias&quot;,</span></span><br><span class="line"><span class="comment">#             &quot;fc.weight&quot;, &quot;fc.bias&quot;]</span></span><br><span class="line"><span class="comment"># pretrain_dict = &#123;k: v for k, v in pretrain_model.items() if k not in del_list&#125;</span></span><br><span class="line"><span class="comment"># model_dict.update(pretrain_dict)</span></span><br><span class="line"><span class="comment"># net.load_state_dict(model_dict)</span></span><br><span class="line">net = GoogLeNet(num_classes=<span class="number">5</span>, aux_logits=<span class="literal">True</span>, init_weights=<span class="literal">True</span>)</span><br><span class="line">net.to(device)</span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.0003</span>)</span><br><span class="line"></span><br><span class="line">best_acc = <span class="number">0.0</span></span><br><span class="line">save_path = <span class="string">&#x27;./googleNet.pth&#x27;</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">30</span>):</span><br><span class="line">    <span class="comment"># train</span></span><br><span class="line">    net.train()</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">        images, labels = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        logits, aux_logits2, aux_logits1 = net(images.to(device))</span><br><span class="line">        loss0 = loss_function(logits, labels.to(device))</span><br><span class="line">        loss1 = loss_function(aux_logits1, labels.to(device))</span><br><span class="line">        loss2 = loss_function(aux_logits2, labels.to(device))</span><br><span class="line">        loss = loss0 + loss1 * <span class="number">0.3</span> + loss2 * <span class="number">0.3</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="comment"># print train process</span></span><br><span class="line">        rate = (step + <span class="number">1</span>) / <span class="built_in">len</span>(train_loader)</span><br><span class="line">        a = <span class="string">&quot;*&quot;</span> * <span class="built_in">int</span>(rate * <span class="number">50</span>)</span><br><span class="line">        b = <span class="string">&quot;.&quot;</span> * <span class="built_in">int</span>((<span class="number">1</span> - rate) * <span class="number">50</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\rtrain loss: &#123;:^3.0f&#125;%[&#123;&#125;-&gt;&#123;&#125;]&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">int</span>(rate * <span class="number">100</span>), a, b, loss), end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># validate</span></span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    acc = <span class="number">0.0</span>  <span class="comment"># accumulate accurate number / epoch</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> val_data <span class="keyword">in</span> validate_loader:</span><br><span class="line">            val_images, val_labels = val_data</span><br><span class="line">            outputs = net(val_images.to(device))  <span class="comment"># eval model only have last output layer</span></span><br><span class="line">            predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">            acc += (predict_y == val_labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line">        val_accurate = acc / val_num</span><br><span class="line">        <span class="keyword">if</span> val_accurate &gt; best_acc:</span><br><span class="line">            best_acc = val_accurate</span><br><span class="line">            torch.save(net.state_dict(), save_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">              (epoch + <span class="number">1</span>, running_loss / step, val_accurate))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><p><img src="https://img-blog.csdnimg.cn/c3be690c36c84255b12fe4dcaeae0784.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><strong>predict.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> GoogLeNet</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>]=<span class="string">&quot;TRUE&quot;</span></span><br><span class="line"></span><br><span class="line">data_transform = transforms.Compose(</span><br><span class="line">    [transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># load image</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&quot;./sunflower.jpg&quot;</span>)</span><br><span class="line">plt.imshow(img)</span><br><span class="line"><span class="comment"># [N, C, H, W]</span></span><br><span class="line">img = data_transform(img)</span><br><span class="line"><span class="comment"># expand batch dimension</span></span><br><span class="line">img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># read class_indict</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    json_file = <span class="built_in">open</span>(<span class="string">&#x27;./class_indices.json&#x27;</span>, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    class_indict = json.load(json_file)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br><span class="line">    exit(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create model</span></span><br><span class="line">model = GoogLeNet(num_classes=<span class="number">5</span>, aux_logits=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># load model weights</span></span><br><span class="line">model_weight_path = <span class="string">&quot;./googleNet.pth&quot;</span></span><br><span class="line">missing_keys, unexpected_keys = model.load_state_dict(torch.load(model_weight_path), strict=<span class="literal">False</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="comment"># predict class</span></span><br><span class="line">    output = torch.squeeze(model(img))</span><br><span class="line">    predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">    predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"><span class="built_in">print</span>(class_indict[<span class="built_in">str</span>(predict_cla)])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>Output:<br><img src="https://img-blog.csdnimg.cn/c899379d7892472a8b8905c6a230e8ca.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> GoogleNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习(五)——ZFNet+Pytorch实现</title>
      <link href="/2022/01/09/DL5_ZFNet/"/>
      <url>/2022/01/09/DL5_ZFNet/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>AlexNet的提出使得大型卷积网络开始变得流行起来，但是人们对于CNN网络究竟为什么能表现这么好，以及怎么样能变得更好尚不清楚，因此为了解决上述两个问题，ZFNet提出了一种可视化技术，用于理解网络中间的特征层和最后的分类器层，并且找到改进神经网络的结构的方法。ZFNet是Matthew D.Zeiler 和 Rob Fergus 在2013年撰写的论文Visualizing and Understanding Convolutional Networks中提出的，是当年ILSVRC的冠军。ZFNet使用反卷积（deconv）和可视化特征图来达到可视化AlexNet的目的，并指出不足，最后修改网络结构，提升分类结果。</p><span id="more"></span><hr><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><h2 id="反卷积网络结构"><a href="#反卷积网络结构" class="headerlink" title="反卷积网络结构"></a>反卷积网络结构</h2><p>论文使用反卷积网络(deconvnet)进行可视化。反卷积网络可以看成是卷积网络的逆过程，但它不具有学习的能力，只是用于探测卷积网络。</p><p>反卷积网络依附于网络中的每一层，不断地将特征图映射回输入图并可视化。过程中将需要检测的激活图送入反卷积网络，而其余激活图都设置为0。进入反卷积网络后，经过1.unpool；2.rectify；3.filter；不断生成新的激活图，直到映射回原图。大致流程如下：</p><p><img src="https://img-blog.csdnimg.cn/e420b3b113ee4ceb945eaf5d126f35f2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><ul><li><strong>unpool</strong><br>首先说明，AlexNet中使用的max pooling是不可逆的，因为最大池化丢失了一部分图像信息。但是，如果我们记录了最大池化过程中最大值所在的位置，就可以近似地反池化。<br>为了记录池化过程中最大值的位置，论文中使用了一种开关（switch）结构，如上图所示。需要说明的一点是，当输入图像确定时，最大池化过程中最大值的位置时固定的，所以开关设置是特定的。</li><li><strong>rectification</strong><br>AlexNet使用非线性的ReLU作为激活函数，从而修正特征图，使其始终为正。“反激活”的过程，仍使用ReLU进行映射。</li><li><strong>filtering</strong><br>反卷积的过程使用了一个转置卷积，顾名思义即卷积网络中卷积矩阵的转置（具体查阅<a href="https://blog.csdn.net/LoseInVain/article/details/81098502">一文搞懂反卷积，转置卷积</a>），直接作用在修正后的反池化图上。<h2 id="卷积网络可视化"><a href="#卷积网络可视化" class="headerlink" title="卷积网络可视化"></a>卷积网络可视化</h2>在训练结束后，我们在测试集上运用反卷积网络可视化激活特征图。</li><li>特征可视化（feature visualization）<br><img src="https://img-blog.csdnimg.cn/e84ea1721f254b649299714befcfd283.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>在每一层中，随机选取9个激活程度最高的特征图，反卷积结果如下：</li></ul><ol><li>第二层主要相应图像的角点、边缘和颜色。</li><li>第三层具有更复杂的不变形，主要捕获相似的纹理。</li><li>第四层提取具有类别性的内容，例如狗脸、鸟腿等。</li><li>第五层提取具有重要意义的整个对象，例如键盘、狗等。</li></ol><ul><li>训练时的特征演变（evolution）<br><img src="https://img-blog.csdnimg.cn/277d4675777b433e95dfd9423fe9c1c9.png"><br>图中每一行代表同一张图片在不同epoch时反卷积的结果（论文中选取1,2,5,10,,20,30,40,64epoch）。结果表明：较低层的特征收敛更快，在几个epoch之后就会收敛、固定；较高层特征收敛更慢，在40-50epochs之后在完全收敛。</li><li>特征不变性<br><img src="https://img-blog.csdnimg.cn/de96df0bc724460bb1a12e92981508b0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>论文分别对5张图像进行了三种处理：（从上到下分别是）水平平移、尺寸缩放、旋转图像。第二列的图像表示卷积网络第一层中原始图和特征图向量间的欧式距离。第三列是第七层的欧氏距离。第四列则代表处理后归属正确标签的概率。<br>实验表明，在前期（layer1），微小的转变（transformation）会导致一个明显的变化。而后期（layer7），水平平移和尺寸缩放带来的改变逐渐稳定，近似呈线性。旋转处理仍有较大变化。这说明CNN具有平移、缩放不变性，而不具有旋转不变性。</li><li>AlexNet存在的问题<br><img src="https://img-blog.csdnimg.cn/6a8fa9002cf34752a783f1d567467db7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>AlexNet中第一层使用11*11，步长为4的卷积核。然而在可视化时发现，第一层提取的信息多为高、低频，而中频的信息很少提取出。同时在可视化第二层是会发现由于步长过大引起的混叠伪像（aliasing artifact，参考<a href="https://zhuanlan.zhihu.com/p/438190575">这篇文章</a>）。所以论文采用更小的卷积核（7*7）和更短的步长（2）。<br>下面是ZFNet的网络结构。<br><img src="https://img-blog.csdnimg.cn/2911adef369a4d69ac64fe061d131431.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></li></ul><h2 id="遮挡实验"><a href="#遮挡实验" class="headerlink" title="遮挡实验"></a>遮挡实验</h2><p><img src="https://img-blog.csdnimg.cn/88c52d2b221943b6a1d6cc427adaa535.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>可以发现，遮挡到目标物体就很难识别出来，遮挡背景并不会有太大影响，可见网络确实是根据物体判断的。<br><img src="https://img-blog.csdnimg.cn/e9f86fabb9bd4e37af66c176ee089719.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_16,color_FFFFFF,t_70,g_se,x_16"><br>可以看出，狗的眼睛和鼻子对于狗的识别有很强的相关性。</p><h2 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h2><p>通过移除不同层，或者调整每层特征图个数，来观察对识别准确率产生的影响。<br><img src="https://img-blog.csdnimg.cn/5cf7fa2ff9f24ddb9c9a5ef986f7faea.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>可以发现只移除最后两层全连接层或者只移除最后的两层卷积层，并不会对结果产生特别大的影响，但是同时移除掉，就会使误差产生巨大的上升，可见总体的深度对于获得好的效果是重要的。还发现，增加中间卷积层的大小确实可以降低错误，但是导致的扩大的全连接层会导致过拟合。</p><h2 id="泛化实验"><a href="#泛化实验" class="headerlink" title="泛化实验"></a>泛化实验</h2><p>通过在ImageNet数据集上预训练，再在Caltech与PASCAL VOC 2012数据集上训练最后的softmax层。<br><img src="https://img-blog.csdnimg.cn/78a125072c0f4133956366cca757a3de.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="Caltech-256"><br><img src="https://img-blog.csdnimg.cn/2d3f8ebd1da7490dbd18aaddf9bac1fe.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="PASCAL VOC 2012"><br>从上面可以看出ZFNet在其它数据集上效果也是不错的，即网络确实是学到了一般的特征，在Caltech-256只需要不到十张图片即可超过之前最强的算法。在PASCAL 2012效果不是最好的，可能的原因是，PASCAL数据集多是多物体图片，而ImageNet数据集多是单物体图片，所以本质上是不同的。如果使用的损失函数是多标签的，可能可以改善这个结果。</p><hr><h1 id="Pytorch实现"><a href="#Pytorch实现" class="headerlink" title="Pytorch实现"></a>Pytorch实现</h1><p>从<a href="http://download.tensorflow.org/example_images/flower_photos.tgz">http://download.tensorflow.org/example_images/flower_photos.tgz</a>下载数据集<br>执行下面代码，将数据集划分为训练集与验证集。<br><strong>split_data.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> shutil <span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mkfile</span>(<span class="params">file</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file):</span><br><span class="line">        os.makedirs(file)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">file = <span class="string">&#x27;flower_data/flower_photos&#x27;</span></span><br><span class="line">flower_class = [cla <span class="keyword">for</span> cla <span class="keyword">in</span> os.listdir(file) <span class="keyword">if</span> <span class="string">&quot;.txt&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> cla]</span><br><span class="line">mkfile(<span class="string">&#x27;flower_data/train&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">    mkfile(<span class="string">&#x27;flower_data/train/&#x27;</span>+cla)</span><br><span class="line"></span><br><span class="line">mkfile(<span class="string">&#x27;flower_data/val&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">    mkfile(<span class="string">&#x27;flower_data/val/&#x27;</span>+cla)</span><br><span class="line"></span><br><span class="line">split_rate = <span class="number">0.1</span></span><br><span class="line"><span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">    cla_path = file + <span class="string">&#x27;/&#x27;</span> + cla + <span class="string">&#x27;/&#x27;</span></span><br><span class="line">    images = os.listdir(cla_path)</span><br><span class="line">    num = <span class="built_in">len</span>(images)</span><br><span class="line">    eval_index = random.sample(images, k=<span class="built_in">int</span>(num*split_rate))</span><br><span class="line">    <span class="keyword">for</span> index, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(images):</span><br><span class="line">        <span class="keyword">if</span> image <span class="keyword">in</span> eval_index:</span><br><span class="line">            image_path = cla_path + image</span><br><span class="line">            new_path = <span class="string">&#x27;flower_data/val/&#x27;</span> + cla</span><br><span class="line">            copy(image_path, new_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            image_path = cla_path + image</span><br><span class="line">            new_path = <span class="string">&#x27;flower_data/train/&#x27;</span> + cla</span><br><span class="line">            copy(image_path, new_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\r[&#123;&#125;] processing [&#123;&#125;/&#123;&#125;]&quot;</span>.<span class="built_in">format</span>(cla, index+<span class="number">1</span>, num), end=<span class="string">&quot;&quot;</span>)  <span class="comment"># processing bar</span></span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;processing done!&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>model.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZFNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes=<span class="number">1000</span>, init_weights=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ZFNet, self).__init__()</span><br><span class="line">        self.features = nn.Sequential(  <span class="comment"># 打包</span></span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">48</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),   <span class="comment"># input[3, 224, 224]  output[48, 110, 110] 自动舍去小数点后</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),  <span class="comment"># inplace 可以载入更大模型</span></span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),       <span class="comment"># output[48, 55, 55] kernel_num为原论文一半</span></span><br><span class="line">            nn.Conv2d(<span class="number">48</span>, <span class="number">128</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">2</span>),            <span class="comment"># output[128, 26, 26]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),       <span class="comment"># output[128, 13, 13]</span></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),          <span class="comment"># output[192, 13, 13]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">192</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),          <span class="comment"># output[192, 13, 13]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">192</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),          <span class="comment"># output[128, 13, 13]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),                  <span class="comment"># output[128, 6, 6]</span></span><br><span class="line">        )</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            <span class="comment"># 全连接</span></span><br><span class="line">            nn.Linear(<span class="number">128</span> * <span class="number">6</span> * <span class="number">6</span>, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, num_classes),</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = torch.flatten(x, start_dim=<span class="number">1</span>)  <span class="comment"># 展平   或者view()</span></span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_initialize_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 何教授方法</span></span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)  <span class="comment"># 正态分布赋值</span></span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>train.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, datasets, utils</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> ZFNet</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># device : GPU or CPU</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据转换</span></span><br><span class="line">data_transform = &#123;</span><br><span class="line">    <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">                                 transforms.RandomHorizontalFlip(),</span><br><span class="line">                                 transforms.ToTensor(),</span><br><span class="line">                                 transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))]),</span><br><span class="line">    <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),  <span class="comment"># cannot 224, must (224, 224)</span></span><br><span class="line">                               transforms.ToTensor(),</span><br><span class="line">                               transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># data_root = os.path.abspath(os.path.join(os.getcwd(), &quot;../..&quot;))  # get data root path</span></span><br><span class="line">data_root = os.getcwd()</span><br><span class="line">image_path = data_root + <span class="string">&quot;/flower_data/&quot;</span>  <span class="comment"># flower data set path</span></span><br><span class="line">train_dataset = datasets.ImageFolder(root=image_path + <span class="string">&quot;/train&quot;</span>,</span><br><span class="line">                                     transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">train_num = <span class="built_in">len</span>(train_dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &#123;&#x27;daisy&#x27;:0, &#x27;dandelion&#x27;:1, &#x27;roses&#x27;:2, &#x27;sunflower&#x27;:3, &#x27;tulips&#x27;:4&#125;</span></span><br><span class="line">flower_list = train_dataset.class_to_idx</span><br><span class="line">cla_dict = <span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> flower_list.items())</span><br><span class="line"><span class="comment"># write dict into json file</span></span><br><span class="line"></span><br><span class="line">json_str = json.dumps(cla_dict, indent=<span class="number">4</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    json_file.write(json_str)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                           batch_size=batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                           num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">validate_dataset = datasets.ImageFolder(root=image_path + <span class="string">&quot;/val&quot;</span>,</span><br><span class="line">                                        transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line">val_num = <span class="built_in">len</span>(validate_dataset)</span><br><span class="line">validate_loader = torch.utils.data.DataLoader(validate_dataset,</span><br><span class="line">                                              batch_size=batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                              num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">test_data_iter = <span class="built_in">iter</span>(validate_loader)</span><br><span class="line">test_image, test_label = test_data_iter.<span class="built_in">next</span>()</span><br><span class="line"><span class="comment"># print(test_image[0].size(),type(test_image[0]))</span></span><br><span class="line"><span class="comment"># print(test_label[0],test_label[0].item(),type(test_label[0]))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图像，之前需把validate_loader中batch_size改为4</span></span><br><span class="line"><span class="comment"># def imshow(img):</span></span><br><span class="line"><span class="comment">#     img = img / 2 + 0.5  # unnormalize</span></span><br><span class="line"><span class="comment">#     npimg = img.numpy()</span></span><br><span class="line"><span class="comment">#     plt.imshow(np.transpose(npimg, (1, 2, 0)))</span></span><br><span class="line"><span class="comment">#     plt.show()</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># print(&#x27; &#x27;.join(&#x27;%5s&#x27; % cla_dict[test_label[j].item()] for j in range(4)))</span></span><br><span class="line"><span class="comment"># imshow(utils.make_grid(test_image))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = ZFNet(num_classes=<span class="number">5</span>, init_weights=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">net.to(device)</span><br><span class="line"><span class="comment"># 损失函数:这里用交叉熵</span></span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 优化器 这里用Adam</span></span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.0002</span>)</span><br><span class="line"><span class="comment"># 训练参数保存路径</span></span><br><span class="line">save_path = <span class="string">&#x27;./AlexNet.pth&#x27;</span></span><br><span class="line"><span class="comment"># 训练过程中最高准确率</span></span><br><span class="line">best_acc = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始进行训练和测试，训练一轮，测试一轮</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="comment"># train</span></span><br><span class="line">    net.train()    <span class="comment"># 训练过程中，使用之前定义网络中的dropout</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    t1 = time.perf_counter()</span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">        images, labels = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = net(images.to(device))</span><br><span class="line">        loss = loss_function(outputs, labels.to(device))</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="comment"># print train process</span></span><br><span class="line">        rate = (step + <span class="number">1</span>) / <span class="built_in">len</span>(train_loader)</span><br><span class="line">        a = <span class="string">&quot;*&quot;</span> * <span class="built_in">int</span>(rate * <span class="number">50</span>)</span><br><span class="line">        b = <span class="string">&quot;.&quot;</span> * <span class="built_in">int</span>((<span class="number">1</span> - rate) * <span class="number">50</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\rtrain loss: &#123;:^3.0f&#125;%[&#123;&#125;-&gt;&#123;&#125;]&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">int</span>(rate * <span class="number">100</span>), a, b, loss), end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>(time.perf_counter()-t1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># validate</span></span><br><span class="line">    net.<span class="built_in">eval</span>()    <span class="comment"># 测试过程中不需要dropout，使用所有的神经元</span></span><br><span class="line">    acc = <span class="number">0.0</span>  <span class="comment"># accumulate accurate number / epoch</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> val_data <span class="keyword">in</span> validate_loader:</span><br><span class="line">            val_images, val_labels = val_data</span><br><span class="line">            outputs = net(val_images.to(device))</span><br><span class="line">            predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">            acc += (predict_y == val_labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line">        val_accurate = acc / val_num</span><br><span class="line">        <span class="keyword">if</span> val_accurate &gt; best_acc:</span><br><span class="line">            best_acc = val_accurate</span><br><span class="line">            torch.save(net.state_dict(), save_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">              (epoch + <span class="number">1</span>, running_loss / step, val_accurate))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Output:<br><img src="https://img-blog.csdnimg.cn/a6efac7fc7334419aef16673651a329f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><strong>predict.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> ZFNet</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>]=<span class="string">&quot;TRUE&quot;</span></span><br><span class="line"></span><br><span class="line">data_transform = transforms.Compose(</span><br><span class="line">    [transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># load image</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&quot;./sunflower.jpg&quot;</span>)  <span class="comment"># 验证太阳花</span></span><br><span class="line"><span class="comment"># img = Image.open(&quot;./roses.jpg&quot;)     # 验证玫瑰花</span></span><br><span class="line">plt.imshow(img)</span><br><span class="line"><span class="comment"># [N, C, H, W]</span></span><br><span class="line">img = data_transform(img)</span><br><span class="line"><span class="comment"># expand batch dimension</span></span><br><span class="line">img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># read class_indict</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    json_file = <span class="built_in">open</span>(<span class="string">&#x27;./class_indices.json&#x27;</span>, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    class_indict = json.load(json_file)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br><span class="line">    exit(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create model</span></span><br><span class="line">model = ZFNet(num_classes=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># load model weights</span></span><br><span class="line">model_weight_path = <span class="string">&quot;./AlexNet.pth&quot;</span></span><br><span class="line">model.load_state_dict(torch.load(model_weight_path))</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="comment"># predict class</span></span><br><span class="line">    output = torch.squeeze(model(img))</span><br><span class="line">    predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">    predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"><span class="built_in">print</span>(class_indict[<span class="built_in">str</span>(predict_cla)], predict[predict_cla].item())</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Output:<br><img src="https://img-blog.csdnimg.cn/6c1dde3c5a944bf9a59e4dd3e6623ab6.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> ZFNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习(四)——VGG+Pytorch实现</title>
      <link href="/2022/01/09/DL4_VGG/"/>
      <url>/2022/01/09/DL4_VGG/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>VGG是牛津大学的Visual Geometry Group的组提出的。该网络是在ILSVRC 2014上的相关工作（定位任务第一，分类任务第二），主要工作是证明了增加网络的深度能够在一定程度上影响网络的最终性能（对比了多个不同深度网络的性能）。<br><img src="https://img-blog.csdnimg.cn/4d95dfe0dd25494f8866768f67d60c53.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>从上表可以发现，VGG只使用了两个网络就能获得非常好的效果。</p><span id="more"></span><hr><h1 id="主要方法"><a href="#主要方法" class="headerlink" title="主要方法"></a>主要方法</h1><h2 id="采用3x3卷积核"><a href="#采用3x3卷积核" class="headerlink" title="采用3x3卷积核"></a>采用3x3卷积核</h2><p>AlexNet采用了 11x11 7x7 5x5较大卷积核，而在VGG中，使用连续的 3x3 卷积核代替大卷积核，可以在保持感受野不变的情况下，减小参数量。</p><p><strong>感受野计算</strong><br><img src="https://img-blog.csdnimg.cn/e095597185b74b779c8b82595a854435.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>计算公式如下<br><img src="https://img-blog.csdnimg.cn/2ca01679a5294b1096082bc604b74bd4.png"><br><strong>下面证明了为什么2个 3x3 的卷积核和1个 5x5 的卷积感受野一样</strong><br>F(2) = 3<br>F(1) = (3-1)X1 + 3=5<br>而2个 3x3 的卷积核的参数量为 2X(9XC^2)，1个 5x5 的卷积核的参数量为 25XC^2，C为输入和输出的通道数，并且层数会提高网络性能。</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>除了A-LRN采用了LRN（发现并没有什么用），以及C采用了1x1卷积核，其它都只使用了3x3卷积核。<br><img src="https://img-blog.csdnimg.cn/f4e5f03fdf414a0ca4d2ba07452e4bca.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="多尺度训练和测试"><a href="#多尺度训练和测试" class="headerlink" title="多尺度训练和测试"></a>多尺度训练和测试</h2><p>使用多个尺度训练与测试，可以提高网络的性能。<br><img src="https://img-blog.csdnimg.cn/6f5358d0b2e740b7aff4f97f584ed931.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="multi-crop-evaluation与-dense-evaluation"><a href="#multi-crop-evaluation与-dense-evaluation" class="headerlink" title="multi-crop evaluation与 dense evaluation"></a>multi-crop evaluation与 dense evaluation</h2><p>multi-crop evaluation就是裁剪为多个图片然后塞进网络进行测试，而dense evaluation是将最后的三层全连接层转化为全卷积层，这样可以接受所有尺度的图片。实验发现，这两种方法是互补的，因为他们关注的卷积边界情况不同，multi-crop为0填充，而dense为相邻像素填充。所以两者方法都使用会产生最好的结果。<br><img src="https://img-blog.csdnimg.cn/88b3623c73d740abad2372d2446d4446.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="参数初始化"><a href="#参数初始化" class="headerlink" title="参数初始化"></a>参数初始化</h2><p>除了A随机初始化参数，其它更深的网络使用了A网络第一个四个卷积层以及最后三个全连接的参数，随机初始化从零均值10^-2^方差的正态分布中采样获得，偏差初始化为0。并且发现使用Glorot and Bengio的初始化方法可以获得同样的效果。</p><hr><h1 id="Pytorch实现"><a href="#Pytorch实现" class="headerlink" title="Pytorch实现"></a>Pytorch实现</h1><p>从<a href="http://download.tensorflow.org/example_images/flower_photos.tgz">http://download.tensorflow.org/example_images/flower_photos.tgz</a>下载数据集<br>执行下面代码，将数据集划分为训练集与验证集。<br><strong>split_data.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> shutil <span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mkfile</span>(<span class="params">file</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file):</span><br><span class="line">        os.makedirs(file)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">file = <span class="string">&#x27;flower_data/flower_photos&#x27;</span></span><br><span class="line">flower_class = [cla <span class="keyword">for</span> cla <span class="keyword">in</span> os.listdir(file) <span class="keyword">if</span> <span class="string">&quot;.txt&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> cla]</span><br><span class="line">mkfile(<span class="string">&#x27;flower_data/train&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">    mkfile(<span class="string">&#x27;flower_data/train/&#x27;</span>+cla)</span><br><span class="line"></span><br><span class="line">mkfile(<span class="string">&#x27;flower_data/val&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">    mkfile(<span class="string">&#x27;flower_data/val/&#x27;</span>+cla)</span><br><span class="line"></span><br><span class="line">split_rate = <span class="number">0.1</span></span><br><span class="line"><span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">    cla_path = file + <span class="string">&#x27;/&#x27;</span> + cla + <span class="string">&#x27;/&#x27;</span></span><br><span class="line">    images = os.listdir(cla_path)</span><br><span class="line">    num = <span class="built_in">len</span>(images)</span><br><span class="line">    eval_index = random.sample(images, k=<span class="built_in">int</span>(num*split_rate))</span><br><span class="line">    <span class="keyword">for</span> index, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(images):</span><br><span class="line">        <span class="keyword">if</span> image <span class="keyword">in</span> eval_index:</span><br><span class="line">            image_path = cla_path + image</span><br><span class="line">            new_path = <span class="string">&#x27;flower_data/val/&#x27;</span> + cla</span><br><span class="line">            copy(image_path, new_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            image_path = cla_path + image</span><br><span class="line">            new_path = <span class="string">&#x27;flower_data/train/&#x27;</span> + cla</span><br><span class="line">            copy(image_path, new_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\r[&#123;&#125;] processing [&#123;&#125;/&#123;&#125;]&quot;</span>.<span class="built_in">format</span>(cla, index+<span class="number">1</span>, num), end=<span class="string">&quot;&quot;</span>)  <span class="comment"># processing bar</span></span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;processing done!&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>model.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># official pretrain weights</span></span><br><span class="line">model_urls = &#123;</span><br><span class="line">    <span class="string">&#x27;vgg11&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg11-bbd30ac9.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg13&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg13-c768596a.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg16&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg16-397923af.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg19&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg19-dcbb9e9d.pth&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGG</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, features, num_classes=<span class="number">1000</span>, init_weights=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(VGG, self).__init__()</span><br><span class="line">        self.features = features</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 构建分类网络结构</span></span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">512</span> * <span class="number">7</span> * <span class="number">7</span>, <span class="number">4096</span>),  <span class="comment"># 第一层全连接层</span></span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),  <span class="comment"># 50%的比例随机失活</span></span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),  <span class="comment"># 第二层全连接层</span></span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, num_classes)  <span class="comment"># 第三层全连接层</span></span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> init_weights:  <span class="comment"># 是否进行权重初始化</span></span><br><span class="line">            self._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 正向传播过程</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># N x 3 x 224 x 224</span></span><br><span class="line">        x = self.features(x)  <span class="comment"># 输入到特征提取网络</span></span><br><span class="line">        <span class="comment"># N x 512 x 7 x 7</span></span><br><span class="line">        x = torch.flatten(x, start_dim=<span class="number">1</span>)  <span class="comment"># 展平处理，从第1维度展平(第0维度为batch)</span></span><br><span class="line">        <span class="comment"># N x 512*7*7</span></span><br><span class="line">        x = self.classifier(x)  <span class="comment"># 输入到分类网络中，得到输出</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_initialize_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                <span class="comment"># nn.init.kaiming_normal_(m.weight, mode=&#x27;fan_out&#x27;, nonlinearity=&#x27;relu&#x27;)</span></span><br><span class="line">                nn.init.xavier_uniform_(m.weight)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.xavier_uniform_(m.weight)</span><br><span class="line">                <span class="comment"># nn.init.normal_(m.weight, 0, 0.01)</span></span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建提取特征网络结构</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_features</span>(<span class="params">cfg: <span class="built_in">list</span></span>):</span>  <span class="comment"># 传入对应配置的列表</span></span><br><span class="line">    layers = []  <span class="comment"># 定义空列表，存放每一层的结构</span></span><br><span class="line">    in_channels = <span class="number">3</span>  <span class="comment"># 输入为RGB图片，输入通道为3</span></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> cfg:  <span class="comment"># 遍历配置列表</span></span><br><span class="line">        <span class="keyword">if</span> v == <span class="string">&quot;M&quot;</span>:  <span class="comment"># 如果为M，则为池化层，创建一个最大池化下采样层</span></span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)]</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 不等于M，则为数字，创建卷积层</span></span><br><span class="line">            conv2d = nn.Conv2d(in_channels, v, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">            layers += [conv2d, nn.ReLU(<span class="literal">True</span>)]  <span class="comment"># 每个卷积层都采用RELU激活函数，将定义好的卷积层和RELU拼接</span></span><br><span class="line">            in_channels = v</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)  <span class="comment"># 非关键字参数，*layers可以传递任意数量的实参，以元组的形式导入</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cfgs = &#123;</span><br><span class="line">    <span class="string">&#x27;vgg11&#x27;</span>: [<span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;vgg13&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;vgg16&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;vgg19&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化配置模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg</span>(<span class="params">model_name=<span class="string">&quot;vgg16&quot;</span>, **kwargs</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> model_name <span class="keyword">in</span> cfgs, <span class="string">&quot;Warning: model number &#123;&#125; not in cfgs dict!&quot;</span>.<span class="built_in">format</span>(model_name)</span><br><span class="line">    cfg = cfgs[model_name]</span><br><span class="line"></span><br><span class="line">    model = VGG(make_features(cfg), **kwargs)  <span class="comment"># 可以传递任意数量的实参，以字典的形式导入</span></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>train.py</strong><br>VGG网络还是很大的，如果发现训不了，可以调小batch_size，或者使用cpu训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, datasets</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> vgg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    <span class="comment"># device = &quot;cpu&quot; #使用cpu训练</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; device.&quot;</span>.<span class="built_in">format</span>(device))</span><br><span class="line"></span><br><span class="line">    data_transform = &#123;</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">                                     transforms.RandomHorizontalFlip(),</span><br><span class="line">                                     transforms.ToTensor(),</span><br><span class="line">                                     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))]),</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">                                   transforms.ToTensor(),</span><br><span class="line">                                   transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])&#125;</span><br><span class="line"></span><br><span class="line">data_root = os.getcwd()</span><br><span class="line">image_path = data_root + <span class="string">&quot;/flower_data/&quot;</span>  <span class="comment"># flower data set path</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(image_path), <span class="string">&quot;&#123;&#125; path does not exist.&quot;</span>.<span class="built_in">format</span>(image_path)</span><br><span class="line">    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;train&quot;</span>),</span><br><span class="line">                                         transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">    train_num = <span class="built_in">len</span>(train_dataset)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># &#123;&#x27;daisy&#x27;:0, &#x27;dandelion&#x27;:1, &#x27;roses&#x27;:2, &#x27;sunflower&#x27;:3, &#x27;tulips&#x27;:4&#125;</span></span><br><span class="line">    flower_list = train_dataset.class_to_idx</span><br><span class="line">    cla_dict = <span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> flower_list.items())</span><br><span class="line">    <span class="comment"># write dict into json file</span></span><br><span class="line">    json_str = json.dumps(cla_dict, indent=<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">        json_file.write(json_str)</span><br><span class="line"></span><br><span class="line">    batch_size = <span class="number">32</span></span><br><span class="line">    nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">8</span>])  <span class="comment"># number of workers</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="built_in">format</span>(nw))</span><br><span class="line"></span><br><span class="line">    train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                               batch_size=batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                               num_workers=nw)</span><br><span class="line"></span><br><span class="line">    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="string">&quot;val&quot;</span>),</span><br><span class="line">                                            transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line">    val_num = <span class="built_in">len</span>(validate_dataset)</span><br><span class="line">    validate_loader = torch.utils.data.DataLoader(validate_dataset,</span><br><span class="line">                                                  batch_size=batch_size, shuffle=<span class="literal">False</span>,</span><br><span class="line">                                                  num_workers=nw)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; images for training, &#123;&#125; images for validation.&quot;</span>.<span class="built_in">format</span>(train_num,</span><br><span class="line">                                                                           val_num))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># test_data_iter = iter(validate_loader)</span></span><br><span class="line">    <span class="comment"># test_image, test_label = test_data_iter.next()</span></span><br><span class="line"></span><br><span class="line">    model_name = <span class="string">&quot;vgg16&quot;</span></span><br><span class="line">    net = vgg(model_name=model_name, num_classes=<span class="number">5</span>, init_weights=<span class="literal">True</span>)</span><br><span class="line">    net.to(device)</span><br><span class="line">    loss_function = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line">    epochs = <span class="number">30</span></span><br><span class="line">    best_acc = <span class="number">0.0</span></span><br><span class="line">    save_path = <span class="string">&#x27;./&#123;&#125;Net.pth&#x27;</span>.<span class="built_in">format</span>(model_name)</span><br><span class="line">    train_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="comment"># train</span></span><br><span class="line">        net.train()</span><br><span class="line">        running_loss = <span class="number">0.0</span></span><br><span class="line">        train_bar = tqdm(train_loader)</span><br><span class="line">        <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_bar):</span><br><span class="line">            images, labels = data</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            outputs = net(images.to(device))</span><br><span class="line">            loss = loss_function(outputs, labels.to(device))</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># print statistics</span></span><br><span class="line">            running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">            train_bar.desc = <span class="string">&quot;train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                                                                     epochs,</span><br><span class="line">                                                                     loss)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># validate</span></span><br><span class="line">        net.<span class="built_in">eval</span>()</span><br><span class="line">        acc = <span class="number">0.0</span>  <span class="comment"># accumulate accurate number / epoch</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            val_bar = tqdm(validate_loader)</span><br><span class="line">            <span class="keyword">for</span> val_data <span class="keyword">in</span> val_bar:</span><br><span class="line">                val_images, val_labels = val_data</span><br><span class="line">                outputs = net(val_images.to(device))</span><br><span class="line">                predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">                acc += torch.eq(predict_y, val_labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">        val_accurate = acc / val_num</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  val_accuracy: %.3f&#x27;</span> %</span><br><span class="line">              (epoch + <span class="number">1</span>, running_loss / train_steps, val_accurate))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> val_accurate &gt; best_acc:</span><br><span class="line">            best_acc = val_accurate</span><br><span class="line">            torch.save(net.state_dict(), save_path)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>predict.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> vgg</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>]=<span class="string">&quot;TRUE&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    data_transform = transforms.Compose(</span><br><span class="line">        [transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">         transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    img_path = <span class="string">&quot;./sunflower.jpg&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    <span class="comment"># [N, C, H, W]</span></span><br><span class="line">    img = data_transform(img)</span><br><span class="line">    <span class="comment"># expand batch dimension</span></span><br><span class="line">    img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read class_indict</span></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line">    json_file = <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>)</span><br><span class="line">    class_indict = json.load(json_file)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    model = vgg(model_name=<span class="string">&quot;vgg16&quot;</span>, num_classes=<span class="number">5</span>).to(device)</span><br><span class="line">    <span class="comment"># load model weights</span></span><br><span class="line">    weights_path = <span class="string">&quot;./vgg16Net.pth&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(weights_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(weights_path)</span><br><span class="line">    model.load_state_dict(torch.load(weights_path, map_location=device))</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># predict class</span></span><br><span class="line">        output = torch.squeeze(model(img.to(device))).cpu()</span><br><span class="line">        predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">        predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"></span><br><span class="line">    print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_cla)],</span><br><span class="line">                                                 predict[predict_cla].numpy())</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    <span class="built_in">print</span>(print_res)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Output:<br><img src="https://img-blog.csdnimg.cn/fac1bb28add540c294d30f2302f7d7a9.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> VGG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习(三)——AlexNet+Pytorch实现</title>
      <link href="/2022/01/07/DL3_AlexNet/"/>
      <url>/2022/01/07/DL3_AlexNet/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>在2010年的ImageNet LSVRC-2010上，AlexNet在给包含有1000种类别的共120万张高分辨率图片的分类任务中，在测试集上的top-1和top-5错误率为37.5%和17.0%<strong>（top-5 错误率：即对一张图像预测5个类别，只要有一个和人工标注类别相同就算对，否则算错。同理top-1对一张图像只预测1个类别）</strong>，在ImageNet LSVRC-2012的比赛中，取得了top-5错误率为15.3%的成绩，而第二名的成绩为26.2%，可见AlexNet在当时有多强大。</p><span id="more"></span><hr><h1 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h1><p><img src="https://img-blog.csdnimg.cn/749ba554c5f24107aca65e43371b4b80.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="AlexNet网络结构"><br>网络放在两块GPU上，一块GPU放一半。</p><h2 id="第一阶段卷积"><a href="#第一阶段卷积" class="headerlink" title="第一阶段卷积"></a>第一阶段卷积</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> <span class="number">224</span>*<span class="number">224</span>*<span class="number">3</span></span><br><span class="line">Conv(kernel_size=<span class="number">11</span>*<span class="number">11</span>, kernel_num=<span class="number">96</span>, stride=<span class="number">4</span>, padding=<span class="number">2</span>)</span><br><span class="line">output (<span class="number">224</span>-<span class="number">11</span>+<span class="number">2</span>*<span class="number">2</span>)/<span class="number">4</span>+<span class="number">1</span>=<span class="number">55</span> -&gt; <span class="number">55</span>*<span class="number">55</span>*<span class="number">96</span></span><br><span class="line">Relu</span><br><span class="line">Pool(kernel_size=<span class="number">3</span>*<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line">output (<span class="number">55</span>-<span class="number">3</span>)/<span class="number">2</span>+<span class="number">1</span>=<span class="number">27</span> -&gt; <span class="number">27</span>*<span class="number">27</span>*<span class="number">96</span></span><br><span class="line">Local Response Normalization(local_size=<span class="number">5</span>)</span><br><span class="line">output <span class="number">27</span>*<span class="number">27</span>*<span class="number">96</span></span><br></pre></td></tr></table></figure><h2 id="第二阶段卷积"><a href="#第二阶段卷积" class="headerlink" title="第二阶段卷积"></a>第二阶段卷积</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> <span class="number">27</span>*<span class="number">27</span>*<span class="number">96</span></span><br><span class="line">Conv(kernel_size=<span class="number">5</span>*<span class="number">5</span>, kernel_num=<span class="number">256</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>)</span><br><span class="line">output (<span class="number">27</span>-<span class="number">5</span>+<span class="number">2</span>*<span class="number">2</span>)/<span class="number">1</span>+<span class="number">1</span>=<span class="number">27</span> -&gt; <span class="number">27</span>*<span class="number">27</span>*<span class="number">256</span></span><br><span class="line">Relu</span><br><span class="line">Pool(kernel_size=<span class="number">3</span>*<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line">output (<span class="number">27</span>-<span class="number">3</span>)/<span class="number">2</span>+<span class="number">1</span>=<span class="number">13</span> -&gt; <span class="number">13</span>*<span class="number">13</span>*<span class="number">256</span></span><br><span class="line">Local Response Normalization(local_size=<span class="number">5</span>)</span><br><span class="line">output <span class="number">13</span>*<span class="number">13</span>*<span class="number">256</span></span><br></pre></td></tr></table></figure><h2 id="第三阶段卷积"><a href="#第三阶段卷积" class="headerlink" title="第三阶段卷积"></a>第三阶段卷积</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> <span class="number">13</span>*<span class="number">13</span>*<span class="number">256</span></span><br><span class="line">Conv(kernel_size=<span class="number">3</span>*<span class="number">3</span>, kernel_num=<span class="number">384</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">output (<span class="number">13</span>-<span class="number">3</span>+<span class="number">2</span>*<span class="number">1</span>)/<span class="number">1</span>+<span class="number">1</span>=<span class="number">13</span> -&gt; <span class="number">13</span>*<span class="number">13</span>*<span class="number">384</span></span><br><span class="line">Relu</span><br><span class="line">output <span class="number">13</span>*<span class="number">13</span>*<span class="number">256</span></span><br></pre></td></tr></table></figure><h2 id="第四阶段卷积"><a href="#第四阶段卷积" class="headerlink" title="第四阶段卷积"></a>第四阶段卷积</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> <span class="number">13</span>*<span class="number">13</span>*<span class="number">256</span></span><br><span class="line">Conv(kernel_size=<span class="number">3</span>*<span class="number">3</span>, kernel_num=<span class="number">384</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">output (<span class="number">13</span>-<span class="number">3</span>+<span class="number">2</span>*<span class="number">1</span>)/<span class="number">1</span>+<span class="number">1</span>=<span class="number">13</span> -&gt; <span class="number">13</span>*<span class="number">13</span>*<span class="number">384</span></span><br><span class="line">Relu</span><br><span class="line">output <span class="number">13</span>*<span class="number">13</span>*<span class="number">384</span></span><br></pre></td></tr></table></figure><h2 id="第五阶段卷积"><a href="#第五阶段卷积" class="headerlink" title="第五阶段卷积"></a>第五阶段卷积</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> <span class="number">13</span>*<span class="number">13</span>*<span class="number">256</span></span><br><span class="line">Conv(kernel_size=<span class="number">3</span>*<span class="number">3</span>, kernel_num=<span class="number">256</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">output (<span class="number">13</span>-<span class="number">3</span>+<span class="number">2</span>*<span class="number">1</span>)/<span class="number">1</span>+<span class="number">1</span>=<span class="number">13</span> -&gt; <span class="number">13</span>*<span class="number">13</span>*<span class="number">256</span></span><br><span class="line">Relu</span><br><span class="line">Pool(kernel_size=<span class="number">3</span>*<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line">output (<span class="number">13</span>-<span class="number">3</span>)/<span class="number">2</span>+<span class="number">1</span>=<span class="number">6</span> -&gt; <span class="number">6</span>*<span class="number">6</span>*<span class="number">256</span></span><br></pre></td></tr></table></figure><h2 id="第六阶段全连接"><a href="#第六阶段全连接" class="headerlink" title="第六阶段全连接"></a>第六阶段全连接</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> <span class="number">6</span>*<span class="number">6</span>*<span class="number">256</span></span><br><span class="line">Fc</span><br><span class="line">Relu</span><br><span class="line">Dropout</span><br><span class="line">output <span class="number">4096</span></span><br></pre></td></tr></table></figure><h2 id="第七阶段全连接"><a href="#第七阶段全连接" class="headerlink" title="第七阶段全连接"></a>第七阶段全连接</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> <span class="number">4096</span></span><br><span class="line">Fc</span><br><span class="line">Relu</span><br><span class="line">Dropout</span><br><span class="line">output <span class="number">4096</span></span><br></pre></td></tr></table></figure><h2 id="第八阶段全连接"><a href="#第八阶段全连接" class="headerlink" title="第八阶段全连接"></a>第八阶段全连接</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> <span class="number">4096</span></span><br><span class="line">Fc</span><br><span class="line">Relu</span><br><span class="line">Dropout</span><br><span class="line">output <span class="number">1000</span></span><br></pre></td></tr></table></figure><p>Alexnet网络中各个层发挥的作用如下表所述：</p><p><img src="https://img-blog.csdnimg.cn/459340957d4a45cbbc576552ddad38f7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="Pytorch实现"><a href="#Pytorch实现" class="headerlink" title="Pytorch实现"></a>Pytorch实现</h1><p><strong>model.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlexNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes=<span class="number">1000</span>, init_weights=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(AlexNet, self).__init__()</span><br><span class="line">        self.features = nn.Sequential(  <span class="comment"># 打包</span></span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">48</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">2</span>),  <span class="comment"># input[3, 224, 224]  output[48, 55, 55] 自动舍去小数点后</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),  <span class="comment"># inplace 可以载入更大模型</span></span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),                  <span class="comment"># output[48, 27, 27] kernel_num为原论文一半</span></span><br><span class="line">            nn.Conv2d(<span class="number">48</span>, <span class="number">128</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),           <span class="comment"># output[128, 27, 27]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),                  <span class="comment"># output[128, 13, 13]</span></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),          <span class="comment"># output[192, 13, 13]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">192</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),          <span class="comment"># output[192, 13, 13]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">192</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),          <span class="comment"># output[128, 13, 13]</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),                  <span class="comment"># output[128, 6, 6]</span></span><br><span class="line">        )</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            <span class="comment"># 全连接</span></span><br><span class="line">            nn.Linear(<span class="number">128</span> * <span class="number">6</span> * <span class="number">6</span>, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, num_classes),</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = torch.flatten(x, start_dim=<span class="number">1</span>)  <span class="comment"># 展平   或者view()</span></span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_initialize_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 何教授方法</span></span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)  <span class="comment"># 正态分布赋值</span></span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>从<a href="http://download.tensorflow.org/example_images/flower_photos.tgz">http://download.tensorflow.org/example_images/flower_photos.tgz</a>下载数据集<br>执行下面代码，将数据集划分为训练集与验证集。<br><strong>split_data.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> shutil <span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mkfile</span>(<span class="params">file</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file):</span><br><span class="line">        os.makedirs(file)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">file = <span class="string">&#x27;flower_data/flower_photos&#x27;</span></span><br><span class="line">flower_class = [cla <span class="keyword">for</span> cla <span class="keyword">in</span> os.listdir(file) <span class="keyword">if</span> <span class="string">&quot;.txt&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> cla]</span><br><span class="line">mkfile(<span class="string">&#x27;flower_data/train&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">    mkfile(<span class="string">&#x27;flower_data/train/&#x27;</span>+cla)</span><br><span class="line"></span><br><span class="line">mkfile(<span class="string">&#x27;flower_data/val&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">    mkfile(<span class="string">&#x27;flower_data/val/&#x27;</span>+cla)</span><br><span class="line"></span><br><span class="line">split_rate = <span class="number">0.1</span></span><br><span class="line"><span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">    cla_path = file + <span class="string">&#x27;/&#x27;</span> + cla + <span class="string">&#x27;/&#x27;</span></span><br><span class="line">    images = os.listdir(cla_path)</span><br><span class="line">    num = <span class="built_in">len</span>(images)</span><br><span class="line">    eval_index = random.sample(images, k=<span class="built_in">int</span>(num*split_rate))</span><br><span class="line">    <span class="keyword">for</span> index, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(images):</span><br><span class="line">        <span class="keyword">if</span> image <span class="keyword">in</span> eval_index:</span><br><span class="line">            image_path = cla_path + image</span><br><span class="line">            new_path = <span class="string">&#x27;flower_data/val/&#x27;</span> + cla</span><br><span class="line">            copy(image_path, new_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            image_path = cla_path + image</span><br><span class="line">            new_path = <span class="string">&#x27;flower_data/train/&#x27;</span> + cla</span><br><span class="line">            copy(image_path, new_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\r[&#123;&#125;] processing [&#123;&#125;/&#123;&#125;]&quot;</span>.<span class="built_in">format</span>(cla, index+<span class="number">1</span>, num), end=<span class="string">&quot;&quot;</span>)  <span class="comment"># processing bar</span></span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;processing done!&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>训练模型 <strong>train.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, datasets, utils</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> AlexNet</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># device : GPU or CPU</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据转换</span></span><br><span class="line">data_transform = &#123;</span><br><span class="line">    <span class="string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">                                 transforms.RandomHorizontalFlip(),</span><br><span class="line">                                 transforms.ToTensor(),</span><br><span class="line">                                 transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))]),</span><br><span class="line">    <span class="string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),  <span class="comment"># cannot 224, must (224, 224)</span></span><br><span class="line">                               transforms.ToTensor(),</span><br><span class="line">                               transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># data_root = os.path.abspath(os.path.join(os.getcwd(), &quot;../..&quot;))  # get data root path</span></span><br><span class="line">data_root = os.getcwd()</span><br><span class="line">image_path = data_root + <span class="string">&quot;/flower_data/&quot;</span>  <span class="comment"># flower data set path</span></span><br><span class="line">train_dataset = datasets.ImageFolder(root=image_path + <span class="string">&quot;/train&quot;</span>,</span><br><span class="line">                                     transform=data_transform[<span class="string">&quot;train&quot;</span>])</span><br><span class="line">train_num = <span class="built_in">len</span>(train_dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &#123;&#x27;daisy&#x27;:0, &#x27;dandelion&#x27;:1, &#x27;roses&#x27;:2, &#x27;sunflower&#x27;:3, &#x27;tulips&#x27;:4&#125;</span></span><br><span class="line">flower_list = train_dataset.class_to_idx</span><br><span class="line">cla_dict = <span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> flower_list.items())</span><br><span class="line"><span class="comment"># write dict into json file</span></span><br><span class="line"></span><br><span class="line">json_str = json.dumps(cla_dict, indent=<span class="number">4</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    json_file.write(json_str)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                                           batch_size=batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                           num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">validate_dataset = datasets.ImageFolder(root=image_path + <span class="string">&quot;/val&quot;</span>,</span><br><span class="line">                                        transform=data_transform[<span class="string">&quot;val&quot;</span>])</span><br><span class="line">val_num = <span class="built_in">len</span>(validate_dataset)</span><br><span class="line">validate_loader = torch.utils.data.DataLoader(validate_dataset,</span><br><span class="line">                                              batch_size=batch_size, shuffle=<span class="literal">True</span>,</span><br><span class="line">                                              num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">test_data_iter = <span class="built_in">iter</span>(validate_loader)</span><br><span class="line">test_image, test_label = test_data_iter.<span class="built_in">next</span>()</span><br><span class="line"><span class="comment"># print(test_image[0].size(),type(test_image[0]))</span></span><br><span class="line"><span class="comment"># print(test_label[0],test_label[0].item(),type(test_label[0]))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图像，之前需把validate_loader中batch_size改为4</span></span><br><span class="line"><span class="comment"># def imshow(img):</span></span><br><span class="line"><span class="comment">#     img = img / 2 + 0.5  # unnormalize</span></span><br><span class="line"><span class="comment">#     npimg = img.numpy()</span></span><br><span class="line"><span class="comment">#     plt.imshow(np.transpose(npimg, (1, 2, 0)))</span></span><br><span class="line"><span class="comment">#     plt.show()</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># print(&#x27; &#x27;.join(&#x27;%5s&#x27; % cla_dict[test_label[j].item()] for j in range(4)))</span></span><br><span class="line"><span class="comment"># imshow(utils.make_grid(test_image))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = AlexNet(num_classes=<span class="number">5</span>, init_weights=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">net.to(device)</span><br><span class="line"><span class="comment"># 损失函数:这里用交叉熵</span></span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 优化器 这里用Adam</span></span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.0002</span>)</span><br><span class="line"><span class="comment"># 训练参数保存路径</span></span><br><span class="line">save_path = <span class="string">&#x27;./AlexNet.pth&#x27;</span></span><br><span class="line"><span class="comment"># 训练过程中最高准确率</span></span><br><span class="line">best_acc = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始进行训练和测试，训练一轮，测试一轮</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="comment"># train</span></span><br><span class="line">    net.train()    <span class="comment"># 训练过程中，使用之前定义网络中的dropout</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    t1 = time.perf_counter()</span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">        images, labels = data</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = net(images.to(device))</span><br><span class="line">        loss = loss_function(outputs, labels.to(device))</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="comment"># print train process</span></span><br><span class="line">        rate = (step + <span class="number">1</span>) / <span class="built_in">len</span>(train_loader)</span><br><span class="line">        a = <span class="string">&quot;*&quot;</span> * <span class="built_in">int</span>(rate * <span class="number">50</span>)</span><br><span class="line">        b = <span class="string">&quot;.&quot;</span> * <span class="built_in">int</span>((<span class="number">1</span> - rate) * <span class="number">50</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\rtrain loss: &#123;:^3.0f&#125;%[&#123;&#125;-&gt;&#123;&#125;]&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">int</span>(rate * <span class="number">100</span>), a, b, loss), end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>(time.perf_counter()-t1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># validate</span></span><br><span class="line">    net.<span class="built_in">eval</span>()    <span class="comment"># 测试过程中不需要dropout，使用所有的神经元</span></span><br><span class="line">    acc = <span class="number">0.0</span>  <span class="comment"># accumulate accurate number / epoch</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> val_data <span class="keyword">in</span> validate_loader:</span><br><span class="line">            val_images, val_labels = val_data</span><br><span class="line">            outputs = net(val_images.to(device))</span><br><span class="line">            predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">            acc += (predict_y == val_labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line">        val_accurate = acc / val_num</span><br><span class="line">        <span class="keyword">if</span> val_accurate &gt; best_acc:</span><br><span class="line">            best_acc = val_accurate</span><br><span class="line">            torch.save(net.state_dict(), save_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;[epoch %d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">              (epoch + <span class="number">1</span>, running_loss / step, val_accurate))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Output如下<br><img src="https://img-blog.csdnimg.cn/e3668dec58664d7cb0d7ef64dce06d31.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>使用向日葵图片进行测试 <strong>predict.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> AlexNet</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>]=<span class="string">&quot;TRUE&quot;</span></span><br><span class="line"></span><br><span class="line">data_transform = transforms.Compose(</span><br><span class="line">    [transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">     transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># load image</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&quot;./sunflower.jpg&quot;</span>)  <span class="comment"># 验证太阳花</span></span><br><span class="line"><span class="comment"># img = Image.open(&quot;./roses.jpg&quot;)     # 验证玫瑰花</span></span><br><span class="line">plt.imshow(img)</span><br><span class="line"><span class="comment"># [N, C, H, W]</span></span><br><span class="line">img = data_transform(img)</span><br><span class="line"><span class="comment"># expand batch dimension</span></span><br><span class="line">img = torch.unsqueeze(img, dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># read class_indict</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    json_file = <span class="built_in">open</span>(<span class="string">&#x27;./class_indices.json&#x27;</span>, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    class_indict = json.load(json_file)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br><span class="line">    exit(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create model</span></span><br><span class="line">model = AlexNet(num_classes=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># load model weights</span></span><br><span class="line">model_weight_path = <span class="string">&quot;./AlexNet.pth&quot;</span></span><br><span class="line">model.load_state_dict(torch.load(model_weight_path))</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="comment"># predict class</span></span><br><span class="line">    output = torch.squeeze(model(img))</span><br><span class="line">    predict = torch.softmax(output, dim=<span class="number">0</span>)</span><br><span class="line">    predict_cla = torch.argmax(predict).numpy()</span><br><span class="line"><span class="built_in">print</span>(class_indict[<span class="built_in">str</span>(predict_cla)], predict[predict_cla].item())</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Output如下<br><img src="https://img-blog.csdnimg.cn/bd002ce165204e70825f2bbba436ee8e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/cbcb064375b646fc8709f2e4227c5cd9.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> AlexNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习(二)——经典网络LeNet+Pytorch实现</title>
      <link href="/2021/12/30/DL2_LeNet/"/>
      <url>/2021/12/30/DL2_LeNet/</url>
      
        <content type="html"><![CDATA[<h1 id="LeNet神经网络介绍"><a href="#LeNet神经网络介绍" class="headerlink" title="LeNet神经网络介绍"></a>LeNet神经网络介绍</h1><p>LeNet神经网络由深度学习三巨头之一的Yan LeCun提出，他同时也是卷积神经网络 (CNN，Convolutional Neural Networks)之父。LeNet主要用来进行手写字符的识别与分类，并在美国的银行中投入了使用。LeNet的实现确立了CNN的结构，现在神经网络中的许多内容在LeNet的网络结构中都能看到，例如卷积层，Pooling层，ReLU层。虽然LeNet早在20世纪90年代就已经提出了，但由于当时缺乏大规模的训练数据，计算机硬件的性能也较低，因此LeNet神经网络在处理复杂问题时效果并不理想。虽然LeNet网络结构比较简单，但是刚好适合神经网络的入门学习。</p><span id="more"></span><hr><h1 id="LeNet神经网络结构"><a href="#LeNet神经网络结构" class="headerlink" title="LeNet神经网络结构"></a>LeNet神经网络结构</h1><p>LeNet的神经网络结构图如下：<br><img src="https://img-blog.csdnimg.cn/a388e1eda7124fe4b206d56e086fa57b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="LeNet网络图"><br>LeNet网络的执行流程图如下：<br><img src="https://img-blog.csdnimg.cn/f38683c1dbd34117a0c88f861c1d465e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="LeNet图像处理流程"></p><h2 id="LeNet各层的参数变化"><a href="#LeNet各层的参数变化" class="headerlink" title="LeNet各层的参数变化"></a>LeNet各层的参数变化</h2><ul><li><p>C1<br>输入大小：32*32<br>核大小：5*5<br>核数目：6<br>输出大小：28*28*6<br>训练参数数目：(5*5+1)*6=156<br>连接数：(5*5+1)*6*(32-2-2)*(32-2-2)=122304</p></li><li><p>S2<br>输入大小：28*28*6<br>核大小：2*2<br>核数目：1<br>输出大小：14*14*6<br>训练参数数目：2*6=12，2=(w,b)<br>连接数：(2*2+1)*1*14*14*6 = 5880</p></li><li><p>C3<br>输入大小：14*14*6<br>核大小：5*5<br>核数目：16<br>输出大小：10*10*16<br>训练参数数目：6*(3*5*5+1) + 6*(4*5*5+1) + 3*(4*5*5+1) + 1*(6*5*5+1)=1516<br>连接数：(6*(3*5*5+1) + 6*(4*5*5+1) + 3*(4*5*5+1) + 1*(6*5*5+1))*10*10=151600</p></li><li><p>S4<br>输入大小：10*10*16<br>核大小：2*2<br>核数目：1<br>输出大小：5*5*16<br>训练参数数目：2*16=32<br>连接数：(2*2+1)*1*5*5*16=2000</p></li><li><p>C5<br>输入大小：5*5*16<br>核大小：5*5<br>核数目：120<br>输出大小：120*1*1<br>训练参数数目：(5*5*16+1)*120*1*1=48120（因为是全连接）<br>连接数：(5*5*16+1)*120*1*1=48120</p></li><li><p>F6<br>输入大小：120<br>输出大小：84<br>训练参数数目：(120+1)*84=10164<br>连接数：(120+1)*84=10164</p></li></ul><h2 id="LeNet第三层（卷积操作）"><a href="#LeNet第三层（卷积操作）" class="headerlink" title="LeNet第三层（卷积操作）"></a>LeNet第三层（卷积操作）</h2><p>值得关注的是<code>LeNet</code>第三层，<code>LeNet</code>第三层（<code>C3</code>层）也是卷积层，卷积核大小仍为<code>5*5</code>，不过卷积核的数量变为<code>16</code>个。第三层的输入为<code>14*14</code>的<code>6</code>个<code>feature map</code>，卷积核大小为<code>5*5</code>，因此卷积之后输出的<code>feature map</code>大小为<code>10*10</code>，由于卷积核有<code>16</code>个，因此希望输出的<code>feature map</code>也为<code>16</code>个，但由于输入有<code>6</code>个<code>feature map</code>，因此需要进行额外的处理。输入的<code>6</code>个<code>feature map</code>与输出的<code>16</code>个<code>feature map</code>的关系图如下：<br><img src="https://img-blog.csdnimg.cn/28f261a71de444e78fbe2a66ff3c8a2c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16" alt="S2层与C3层的关系图"><br>如上图所示，第一个卷积核处理前三幅输入的<code>feature map</code>，得出一个新的<code>feature map</code>。</p><hr><h1 id="LetNet-Pytorch版本"><a href="#LetNet-Pytorch版本" class="headerlink" title="LetNet(Pytorch版本)"></a>LetNet(Pytorch版本)</h1><p><strong>model.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LeNet,self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>,<span class="number">16</span>,<span class="number">5</span>)</span><br><span class="line">        self.pool1 = nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">16</span>,<span class="number">32</span>,<span class="number">5</span>)</span><br><span class="line">        self.pool2 = nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>,<span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>,<span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>,<span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = F.relu(self.conv1(x))<span class="comment">#input(3,32,32) output(16,28,28)</span></span><br><span class="line">        x = self.pool1(x) <span class="comment">#output(16，14，14)</span></span><br><span class="line">        x = F.relu(self.conv2(x)) <span class="comment">#output(32,10.10)</span></span><br><span class="line">        x = self.pool2(x) <span class="comment">#output(32,5,5)</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>,<span class="number">32</span>*<span class="number">5</span>*<span class="number">5</span>) <span class="comment">#output(5*5*32)</span></span><br><span class="line">        x = F.relu(self.fc1(x)) <span class="comment">#output(120)</span></span><br><span class="line">        x = F.relu(self.fc2(x)) <span class="comment">#output(84)</span></span><br><span class="line">        x = self.fc3(x) <span class="comment">#output(10)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment">#model调试</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义shape</span></span><br><span class="line">input1 = torch.rand([<span class="number">32</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>])</span><br><span class="line">model = LeNet()<span class="comment">#实例化</span></span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"><span class="comment">#输入网络中</span></span><br><span class="line">output = model(input1)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/4d98840e38214e63933eea9bcb4622e5.png"><br><strong>train.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#train.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, datasets, utils</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#device : GPU or CPU</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 50000张训练图片</span></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                         download=<span class="literal">False</span>, transform=transform)</span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_set, batch_size=<span class="number">36</span>,</span><br><span class="line">                                           shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 10000张验证图片</span></span><br><span class="line">val_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                       download=<span class="literal">False</span>, transform=transform)</span><br><span class="line">val_loader = torch.utils.data.DataLoader(val_set, batch_size=<span class="number">5000</span>,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">val_data_iter = <span class="built_in">iter</span>(val_loader)</span><br><span class="line">val_image, val_label = val_data_iter.<span class="built_in">next</span>()</span><br><span class="line"><span class="built_in">print</span>(val_image.size())</span><br><span class="line"><span class="comment"># print(train_set.class_to_idx)</span></span><br><span class="line"><span class="comment"># classes = (&#x27;plane&#x27;, &#x27;car&#x27;, &#x27;bird&#x27;, &#x27;cat&#x27;,</span></span><br><span class="line"><span class="comment">#           &#x27;deer&#x27;, &#x27;dog&#x27;, &#x27;frog&#x27;, &#x27;horse&#x27;, &#x27;ship&#x27;, &#x27;truck&#x27;)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># #显示图像，之前需把validate_loader中batch_size改为4</span></span><br><span class="line"><span class="comment"># aaa = train_set.class_to_idx</span></span><br><span class="line"><span class="comment"># cla_dict = dict((val, key) for key, val in aaa.items())</span></span><br><span class="line"><span class="comment"># def imshow(img):</span></span><br><span class="line"><span class="comment">#     img = img / 2 + 0.5  # unnormalize</span></span><br><span class="line"><span class="comment">#     npimg = img.numpy()</span></span><br><span class="line"><span class="comment">#     plt.imshow(np.transpose(npimg, (1, 2, 0)))</span></span><br><span class="line"><span class="comment">#     plt.show()</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># print(&#x27; &#x27;.join(&#x27;%5s&#x27; % cla_dict[val_label[j].item()] for j in range(4)))</span></span><br><span class="line"><span class="comment"># imshow(utils.make_grid(val_image))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = LeNet()</span><br><span class="line">net.to(device)</span><br><span class="line"></span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment">#定义优化器</span></span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练过程</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):  <span class="comment"># loop over the dataset multiple times</span></span><br><span class="line"></span><br><span class="line">    running_loss = <span class="number">0.0</span> <span class="comment">#累加损失</span></span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, start=<span class="number">0</span>):</span><br><span class="line">        <span class="comment"># get the inputs; data is a list of [inputs, labels]</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line">        <span class="comment">#print(inputs.size(), labels.size())</span></span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()<span class="comment">#如果不清除历史梯度，就会对计算的历史梯度进行累加</span></span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs.to(device))</span><br><span class="line">        loss = loss_function(outputs, labels.to(device))</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">499</span>:    <span class="comment"># print every 500 mini-batches</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():<span class="comment">#上下文管理器</span></span><br><span class="line">                outputs = net(val_image.to(device))  <span class="comment"># [batch, 10]</span></span><br><span class="line">                predict_y = torch.<span class="built_in">max</span>(outputs, dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">                accuracy = (predict_y == val_label.to(device)).<span class="built_in">sum</span>().item() / val_label.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] train_loss: %.3f  test_accuracy: %.3f&#x27;</span> %</span><br><span class="line">                      (epoch + <span class="number">1</span>, step + <span class="number">1</span>, running_loss / <span class="number">500</span>, accuracy))</span><br><span class="line">                running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line">save_path = <span class="string">&#x27;./Lenet.pth&#x27;</span></span><br><span class="line">torch.save(net.state_dict(), save_path)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/6153c97ffb0340068c687a656d5b428c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> LeNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN图片分类(Pytorch)</title>
      <link href="/2021/12/12/DLPJ_CNN%E9%A3%9F%E7%89%A9%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB/"/>
      <url>/2021/12/12/DLPJ_CNN%E9%A3%9F%E7%89%A9%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<p>这篇文章主要讲述用 pytorch 完成简单 CNN 图片分类任务，如果想对 CNN 的理论知识进行了解，可以看我的这篇文章，<a href="https://blog.csdn.net/weixin_44491423/article/details/121876333?spm=1001.2014.3001.5501">深度学习(一)——CNN卷积神经网络</a>。</p><h1 id="图片分类"><a href="#图片分类" class="headerlink" title="图片分类"></a>图片分类</h1><p>我们以美食图片分类为例，有<code>testing</code>、<code>training</code>、<code>validation</code>文件夹。下载链接放下面。<br><a href="https://pan.baidu.com/s/1qQvYQ5AAPsw9kb7IaWy21w">点击提取</a>， 提取码：nefu<br><img src="https://img-blog.csdnimg.cn/e9e9d70dabfa4907a2f8e147a09abc1e.png"><br>前面的 0 表示其为 0 类，后面为其编号。</p><span id="more"></span><hr><h1 id="导入必要的包"><a href="#导入必要的包" class="headerlink" title="导入必要的包"></a>导入必要的包</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import需要的套件</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure><p><code>cv2</code> 我是通过如下命令下载</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install opencv-python</span><br></pre></td></tr></table></figure><p><code>torch</code> 我下载的是 <code>cuda10.2</code> 的版本，这里就简单放一下下载 <code>pytorch</code> 的代码，至于如何使用 <code>GPU</code> 加速，可以上网查查。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install torch==1.10.0+cu102 torchvision==0.11.1+cu102 torchaudio===0.10.0+cu102 -f https://download.pytorch.org/whl/cu102/torch_stable.html</span><br></pre></td></tr></table></figure><hr><h1 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h1><p>把训练集、验证集和测试集读取进来，放入 <code>numpy</code> 数组。 <code>x</code> 为其图片的像素张量，<code>y</code> 为其标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Read image 利用 OpenCV(cv2) 读入照片并存放在 numpy array 中</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readfile</span>(<span class="params">path, label</span>):</span></span><br><span class="line">    <span class="comment"># label 是一个 boolean variable, 代表需不需要回传 y 值</span></span><br><span class="line">    image_dir = <span class="built_in">sorted</span>(os.listdir(path))  <span class="comment"># os.listdir(path)将path路径下的文件名以列表形式读出</span></span><br><span class="line">    <span class="comment"># print(os.listdir(path))</span></span><br><span class="line">    <span class="comment"># print(image_dir)</span></span><br><span class="line">    x = np.zeros((<span class="built_in">len</span>(image_dir), <span class="number">128</span>, <span class="number">128</span>, <span class="number">3</span>), dtype=np.uint8)</span><br><span class="line">    y = np.zeros((<span class="built_in">len</span>(image_dir)), dtype=np.uint8)</span><br><span class="line">    <span class="keyword">for</span> i, file <span class="keyword">in</span> <span class="built_in">enumerate</span>(image_dir):</span><br><span class="line">        img = cv2.imread(os.path.join(path, file))  <span class="comment"># os.path.join(path, file) 路径名合并</span></span><br><span class="line">        x[i, :, :] = cv2.resize(img, (<span class="number">128</span>, <span class="number">128</span>))</span><br><span class="line">        <span class="keyword">if</span> label:</span><br><span class="line">            y[i] = <span class="built_in">int</span>(file.split(<span class="string">&quot;_&quot;</span>)[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">if</span> label:</span><br><span class="line">        <span class="keyword">return</span> x, y</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分别将 training set、validation set、testing set 用 readfile 函式读进来</span></span><br><span class="line">workspace_dir = <span class="string">&#x27;./food-11&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Reading data&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;...&quot;</span>)</span><br><span class="line">train_x, train_y = readfile(os.path.join(workspace_dir, <span class="string">&quot;training&quot;</span>), <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># print(&quot;Size of training data = &#123;&#125;&quot;.format(len(train_x)))</span></span><br><span class="line">val_x, val_y = readfile(os.path.join(workspace_dir, <span class="string">&quot;validation&quot;</span>), <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># print(&quot;Size of validation data = &#123;&#125;&quot;.format(len(val_x)</span></span><br><span class="line">test_x = readfile(os.path.join(workspace_dir, <span class="string">&quot;testing&quot;</span>), <span class="literal">False</span>)</span><br><span class="line"><span class="comment"># print(&quot;Size of Testing data = &#123;&#125;&quot;.format(len(test_x)))</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Reading data complicated&quot;</span>)</span><br></pre></td></tr></table></figure><hr><h1 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h1><p>定义数据增强操作（随机翻转、随机旋转），定义 <code>batch</code> 的大小。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27; Dataset &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Dataset&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;...&quot;</span>)</span><br><span class="line"><span class="comment"># training 时做 data augmentation</span></span><br><span class="line"><span class="comment"># transforms.Compose 将图像操作串联起来</span></span><br><span class="line">train_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(),</span><br><span class="line">    transforms.RandomHorizontalFlip(),  <span class="comment"># 随机将图片水平翻转</span></span><br><span class="line">    transforms.RandomRotation(<span class="number">15</span>),  <span class="comment"># 随机旋转图片 (-15,15)</span></span><br><span class="line">    transforms.ToTensor(),  <span class="comment"># 将图片转成 Tensor, 并把数值normalize到[0,1](data normalization)</span></span><br><span class="line">])</span><br><span class="line"><span class="comment"># testing 时不需做 data augmentation</span></span><br><span class="line">test_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImgDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, x, y=<span class="literal">None</span>, transform=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.x = x</span><br><span class="line">        <span class="comment"># label is required to be a LongTensor</span></span><br><span class="line">        self.y = y</span><br><span class="line">        <span class="keyword">if</span> y <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.y = torch.LongTensor(y)</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.x)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        X = self.x[index]</span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            X = self.transform(X)</span><br><span class="line">        <span class="keyword">if</span> self.y <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            Y = self.y[index]</span><br><span class="line">            <span class="keyword">return</span> X, Y</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 如果没有标签那么只返回X</span></span><br><span class="line">            <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">train_set = ImgDataset(train_x, train_y, train_transform)</span><br><span class="line">val_set = ImgDataset(val_x, val_y, test_transform)</span><br><span class="line">train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Dataset complicated&quot;</span>)</span><br></pre></td></tr></table></figure><hr><h1 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h1><p>定义CNN的结构。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27; Model &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;...&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Classifier</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Classifier, self).__init__()</span><br><span class="line">        <span class="comment"># torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)</span></span><br><span class="line">        <span class="comment"># torch.nn.MaxPool2d(kernel_size, stride, padding)</span></span><br><span class="line">        <span class="comment"># input 维度 [3, 128, 128]</span></span><br><span class="line">        self.cnn = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),  <span class="comment"># [64, 128, 128]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),  <span class="comment"># [64, 64, 64]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),  <span class="comment"># [128, 64, 64]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),  <span class="comment"># [128, 32, 32]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),  <span class="comment"># [256, 32, 32]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),  <span class="comment"># [256, 16, 16]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),  <span class="comment"># [512, 16, 16]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),  <span class="comment"># [512, 8, 8]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),  <span class="comment"># [512, 8, 8]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),  <span class="comment"># [512, 4, 4]</span></span><br><span class="line">        )</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">512</span> * <span class="number">4</span> * <span class="number">4</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">11</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        out = self.cnn(x)</span><br><span class="line">        out = out.view(out.size()[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.fc(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model complicated&quot;</span>)</span><br></pre></td></tr></table></figure><hr><h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><p>对模型进行训练，迭代30次，并用验证集测试，最后将训练集和验证集合并在进行训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27; Training &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;...&quot;</span>)</span><br><span class="line"><span class="comment"># 使用training set訓練，並使用validation set尋找好的參數</span></span><br><span class="line">model = Classifier().cuda()</span><br><span class="line">loss = nn.CrossEntropyLoss()  <span class="comment"># 因為是 classification task，所以 loss 使用 CrossEntropyLoss</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)  <span class="comment"># optimizer 使用 Adam</span></span><br><span class="line">num_epoch = <span class="number">30</span>  <span class="comment"># 迭代30次</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">    epoch_start_time = time.time()</span><br><span class="line">    train_acc = <span class="number">0.0</span></span><br><span class="line">    train_loss = <span class="number">0.0</span></span><br><span class="line">    val_acc = <span class="number">0.0</span></span><br><span class="line">    val_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    model.train()  <span class="comment"># 確保 model 是在 train model (開啟 Dropout 等...)</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># 用 optimizer 將 model 參數的 gradient 歸零</span></span><br><span class="line">        train_pred = model(data[<span class="number">0</span>].cuda())  <span class="comment"># 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數</span></span><br><span class="line">        batch_loss = loss(train_pred, data[<span class="number">1</span>].cuda())  <span class="comment"># 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）</span></span><br><span class="line">        batch_loss.backward()  <span class="comment"># 利用 back propagation 算出每個參數的 gradient</span></span><br><span class="line">        optimizer.step()  <span class="comment"># 以 optimizer 用 gradient 更新參數值</span></span><br><span class="line"></span><br><span class="line">        train_acc += np.<span class="built_in">sum</span>(np.argmax(train_pred.cpu().data.numpy(), axis=<span class="number">1</span>) == data[<span class="number">1</span>].numpy())</span><br><span class="line">        train_loss += batch_loss.item()</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(val_loader):</span><br><span class="line">            val_pred = model(data[<span class="number">0</span>].cuda())</span><br><span class="line">            batch_loss = loss(val_pred, data[<span class="number">1</span>].cuda())</span><br><span class="line"></span><br><span class="line">            val_acc += np.<span class="built_in">sum</span>(np.argmax(val_pred.cpu().data.numpy(), axis=<span class="number">1</span>) == data[<span class="number">1</span>].numpy())</span><br><span class="line">            val_loss += batch_loss.item()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 將結果 print 出來</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f&#x27;</span> % \</span><br><span class="line">              (epoch + <span class="number">1</span>, num_epoch, time.time() - epoch_start_time, \</span><br><span class="line">               train_acc / train_set.__len__(), train_loss / train_set.__len__(), val_acc / val_set.__len__(),</span><br><span class="line">               val_loss / val_set.__len__()))</span><br><span class="line"></span><br><span class="line">train_val_x = np.concatenate((train_x, val_x), axis=<span class="number">0</span>)</span><br><span class="line">train_val_y = np.concatenate((train_y, val_y), axis=<span class="number">0</span>)</span><br><span class="line">train_val_set = ImgDataset(train_val_x, train_val_y, train_transform)</span><br><span class="line">train_val_loader = DataLoader(train_val_set, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">model_best = Classifier().cuda()</span><br><span class="line">loss = nn.CrossEntropyLoss()  <span class="comment"># 因為是 classification task，所以 loss 使用 CrossEntropyLoss</span></span><br><span class="line">optimizer = torch.optim.Adam(model_best.parameters(), lr=<span class="number">0.001</span>)  <span class="comment"># optimizer 使用 Adam</span></span><br><span class="line">num_epoch = <span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">    epoch_start_time = time.time()</span><br><span class="line">    train_acc = <span class="number">0.0</span></span><br><span class="line">    train_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    model_best.train()</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_val_loader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        train_pred = model_best(data[<span class="number">0</span>].cuda())</span><br><span class="line">        batch_loss = loss(train_pred, data[<span class="number">1</span>].cuda())</span><br><span class="line">        batch_loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        train_acc += np.<span class="built_in">sum</span>(np.argmax(train_pred.cpu().data.numpy(), axis=<span class="number">1</span>) == data[<span class="number">1</span>].numpy())</span><br><span class="line">        train_loss += batch_loss.item()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 將結果 print 出來</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f&#x27;</span> % \</span><br><span class="line">          (epoch + <span class="number">1</span>, num_epoch, time.time() - epoch_start_time, \</span><br><span class="line">           train_acc / train_val_set.__len__(), train_loss / train_val_set.__len__()))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training complicated&quot;</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[001/030] <span class="number">70.94</span> sec(s) Train Acc: <span class="number">0.260997</span> Loss: <span class="number">0.065946</span> | Val Acc: <span class="number">0.303499</span> loss: <span class="number">0.060955</span></span><br><span class="line">[002/030] <span class="number">56.79</span> sec(s) Train Acc: <span class="number">0.362051</span> Loss: <span class="number">0.057194</span> | Val Acc: <span class="number">0.372595</span> loss: <span class="number">0.057390</span></span><br><span class="line">[003/030] <span class="number">57.03</span> sec(s) Train Acc: <span class="number">0.409588</span> Loss: <span class="number">0.053193</span> | Val Acc: <span class="number">0.395335</span> loss: <span class="number">0.054268</span></span><br><span class="line">[004/030] <span class="number">57.81</span> sec(s) Train Acc: <span class="number">0.455504</span> Loss: <span class="number">0.049251</span> | Val Acc: <span class="number">0.454519</span> loss: <span class="number">0.048942</span></span><br><span class="line">[005/030] <span class="number">57.97</span> sec(s) Train Acc: <span class="number">0.499899</span> Loss: <span class="number">0.045356</span> | Val Acc: <span class="number">0.455977</span> loss: <span class="number">0.051678</span></span><br><span class="line">[006/030] <span class="number">58.28</span> sec(s) Train Acc: <span class="number">0.535982</span> Loss: <span class="number">0.042452</span> | Val Acc: <span class="number">0.378717</span> loss: <span class="number">0.074250</span></span><br><span class="line">[007/030] <span class="number">59.17</span> sec(s) Train Acc: <span class="number">0.553720</span> Loss: <span class="number">0.040124</span> | Val Acc: <span class="number">0.568513</span> loss: <span class="number">0.039936</span></span><br><span class="line">[008/030] <span class="number">59.99</span> sec(s) Train Acc: <span class="number">0.579769</span> Loss: <span class="number">0.038209</span> | Val Acc: <span class="number">0.556268</span> loss: <span class="number">0.041599</span></span><br><span class="line">[009/030] <span class="number">59.79</span> sec(s) Train Acc: <span class="number">0.596392</span> Loss: <span class="number">0.036224</span> | Val Acc: <span class="number">0.502332</span> loss: <span class="number">0.045684</span></span><br><span class="line">[010/030] <span class="number">60.00</span> sec(s) Train Acc: <span class="number">0.618690</span> Loss: <span class="number">0.033986</span> | Val Acc: <span class="number">0.552770</span> loss: <span class="number">0.043603</span></span><br><span class="line">[011/030] <span class="number">60.34</span> sec(s) Train Acc: <span class="number">0.640482</span> Loss: <span class="number">0.032332</span> | Val Acc: <span class="number">0.569679</span> loss: <span class="number">0.040512</span></span><br><span class="line">[012/030] <span class="number">60.72</span> sec(s) Train Acc: <span class="number">0.664403</span> Loss: <span class="number">0.030329</span> | Val Acc: <span class="number">0.537609</span> loss: <span class="number">0.047755</span></span><br><span class="line">[013/030] <span class="number">59.88</span> sec(s) Train Acc: <span class="number">0.685181</span> Loss: <span class="number">0.028571</span> | Val Acc: <span class="number">0.534111</span> loss: <span class="number">0.045569</span></span><br><span class="line">[014/030] <span class="number">60.37</span> sec(s) Train Acc: <span class="number">0.690249</span> Loss: <span class="number">0.028063</span> | Val Acc: <span class="number">0.612828</span> loss: <span class="number">0.037240</span></span><br><span class="line">[015/030] <span class="number">60.48</span> sec(s) Train Acc: <span class="number">0.709811</span> Loss: <span class="number">0.026130</span> | Val Acc: <span class="number">0.649563</span> loss: <span class="number">0.034160</span></span><br><span class="line">[016/030] <span class="number">60.54</span> sec(s) Train Acc: <span class="number">0.720961</span> Loss: <span class="number">0.025035</span> | Val Acc: <span class="number">0.641691</span> loss: <span class="number">0.034600</span></span><br><span class="line">[017/030] <span class="number">60.84</span> sec(s) Train Acc: <span class="number">0.738901</span> Loss: <span class="number">0.023416</span> | Val Acc: <span class="number">0.635277</span> loss: <span class="number">0.034863</span></span><br><span class="line">[018/030] <span class="number">60.48</span> sec(s) Train Acc: <span class="number">0.757551</span> Loss: <span class="number">0.022210</span> | Val Acc: <span class="number">0.616035</span> loss: <span class="number">0.039769</span></span><br><span class="line">[019/030] <span class="number">59.98</span> sec(s) Train Acc: <span class="number">0.774073</span> Loss: <span class="number">0.020678</span> | Val Acc: <span class="number">0.649271</span> loss: <span class="number">0.035323</span></span><br><span class="line">[020/030] <span class="number">60.62</span> sec(s) Train Acc: <span class="number">0.779343</span> Loss: <span class="number">0.019825</span> | Val Acc: <span class="number">0.662099</span> loss: <span class="number">0.033701</span></span><br><span class="line">[021/030] <span class="number">60.04</span> sec(s) Train Acc: <span class="number">0.790999</span> Loss: <span class="number">0.018790</span> | Val Acc: <span class="number">0.682216</span> loss: <span class="number">0.032581</span></span><br><span class="line">[022/030] <span class="number">60.72</span> sec(s) Train Acc: <span class="number">0.800426</span> Loss: <span class="number">0.017761</span> | Val Acc: <span class="number">0.620408</span> loss: <span class="number">0.041586</span></span><br><span class="line">[023/030] <span class="number">60.28</span> sec(s) Train Acc: <span class="number">0.810156</span> Loss: <span class="number">0.016732</span> | Val Acc: <span class="number">0.674344</span> loss: <span class="number">0.036074</span></span><br><span class="line">[024/030] <span class="number">60.17</span> sec(s) Train Acc: <span class="number">0.825461</span> Loss: <span class="number">0.015653</span> | Val Acc: <span class="number">0.649271</span> loss: <span class="number">0.039717</span></span><br><span class="line">[025/030] <span class="number">59.96</span> sec(s) Train Acc: <span class="number">0.838638</span> Loss: <span class="number">0.014406</span> | Val Acc: <span class="number">0.639067</span> loss: <span class="number">0.041005</span></span><br><span class="line">[026/030] <span class="number">58.78</span> sec(s) Train Acc: <span class="number">0.842793</span> Loss: <span class="number">0.014155</span> | Val Acc: <span class="number">0.657434</span> loss: <span class="number">0.040948</span></span><br><span class="line">[027/030] <span class="number">60.47</span> sec(s) Train Acc: <span class="number">0.854247</span> Loss: <span class="number">0.013192</span> | Val Acc: <span class="number">0.664140</span> loss: <span class="number">0.042358</span></span><br><span class="line">[028/030] <span class="number">59.34</span> sec(s) Train Acc: <span class="number">0.861443</span> Loss: <span class="number">0.012012</span> | Val Acc: <span class="number">0.687755</span> loss: <span class="number">0.038089</span></span><br><span class="line">[029/030] <span class="number">59.39</span> sec(s) Train Acc: <span class="number">0.876748</span> Loss: <span class="number">0.010853</span> | Val Acc: <span class="number">0.676385</span> loss: <span class="number">0.038813</span></span><br><span class="line">[030/030] <span class="number">59.35</span> sec(s) Train Acc: <span class="number">0.882222</span> Loss: <span class="number">0.010558</span> | Val Acc: <span class="number">0.648105</span> loss: <span class="number">0.043327</span></span><br></pre></td></tr></table></figure><hr><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>对测试集进行预测</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27; Testing &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Testing&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;...&quot;</span>)</span><br><span class="line">test_set = ImgDataset(test_x, transform=test_transform)</span><br><span class="line">test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=<span class="literal">False</span>)</span><br><span class="line">model_best.<span class="built_in">eval</span>()</span><br><span class="line">prediction = []</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader):</span><br><span class="line">        test_pred = model_best(data.cuda())</span><br><span class="line">        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> test_label:</span><br><span class="line">            prediction.append(y)</span><br><span class="line"><span class="comment"># 將結果寫入 csv 檔</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;predict.csv&quot;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">&#x27;Id,Category\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i, y <span class="keyword">in</span> <span class="built_in">enumerate</span>(prediction):</span><br><span class="line">        f.write(<span class="string">&#x27;&#123;&#125;,&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(i, y))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Testing complicated&quot;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习(一)——CNN卷积神经网络</title>
      <link href="/2021/12/12/DL1_CNN/"/>
      <url>/2021/12/12/DL1_CNN/</url>
      
        <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>我们知道，如果将全连接的神经网络应用到图像上是非常困难的，因为如果是 1000x1000 像素的图片，参数量可能就上亿了。<br>我们能否能设计一种网络，可以减少我们的参数量。<br><img src="https://img-blog.csdnimg.cn/1d9d72bf6cfc417ea1ba2feb7dc1379c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><span id="more"></span><p>实际上，我们的眼睛是先找出图像的特征，再根据特征分辨图像到底是什么的，我们也可以设计网络去识别特征，再根据特征识别图像。如果可以这样，就能大大减少参数量，因为特征比整个图像小得多。<br><img src="https://img-blog.csdnimg.cn/e54b339751bd4582b385a2396a5f3e5f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>并且，无论这个特征出现在什么地方，我们都可以使用一个神经元来完成这个工作，这样就可以减少参数量。<br><img src="https://img-blog.csdnimg.cn/b80b44fc6d51417ea2159e2fc66a6c4d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>图像还有个特点就是，假如我们把奇数像素点提取出来，而删去偶数像素点，其实对我们识别图像是没有什么太大的影响的。</p><p><strong>CNN就是利用图像的这些特定来简化参数量的。</strong></p><hr><h1 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h1><p>CNN整个网络结构如下<br><img src="https://img-blog.csdnimg.cn/f2bb7fa7531944c4a403fb70526c5a74.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="Convolution-卷积层"><a href="#Convolution-卷积层" class="headerlink" title="Convolution 卷积层"></a>Convolution 卷积层</h2><p><img src="https://img-blog.csdnimg.cn/e44e9038bffd41cd93f0ae828fb2eeff.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>卷积层简单来说就是通过多个卷积核（过滤器）来提取特征。<br><img src="https://img-blog.csdnimg.cn/9e228f2f5fff4345883e55e6dc98aefa.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>卷积过程就是设定一个 stride(步长)，然后每次和过滤器内积完之后，移动 stride。<br><img src="https://img-blog.csdnimg.cn/d9b535a9a2ac40909ee547e9c476032d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>从下图可以看出，无论特征在哪，都可以通过一个过滤器提取出来。<br><img src="https://img-blog.csdnimg.cn/ed9377d48d86488e8d69f504461c4e8c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>之后，每个过滤器重复上面的操作即可。<br><img src="https://img-blog.csdnimg.cn/0872bfd96fa1447bb9369ee0b97802a3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>对于RGB图像，我们设计三层的过滤器即可。<br><img src="https://img-blog.csdnimg.cn/98cc85c338fc4d47b913ba2973e6b4d7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>有人可能会有疑问，滤波器和神经元有什么关系，看着一点都不像啊？其实过滤器就是神经元。<br>如果我们将图像展平，是不是就和神经元的连接差不多了。<br><img src="https://img-blog.csdnimg.cn/c9f49b2d9d2f4452899a2e7262a3191a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>而且神经元和神经元之间还是权值共享的，这样做既可以省好多参数，还可以避免过拟合。<br><img src="https://img-blog.csdnimg.cn/6cbdad7175874787a8b4ae8ba98e878a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>我们以最大池化为例。<br><img src="https://img-blog.csdnimg.cn/f73a0084fe124fcbac657b074a95e560.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>最大池化就是在卷积之后，从每个块中提取出最大的，这就和提取奇数像素点一样，即使少了这些像素也对我们识别图像产生不了太大影响，这既可以减少参数，也可以防止过拟合。<br><img src="https://img-blog.csdnimg.cn/fd192a2eab9e4c3287239ef3f965f64d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h1><p>我们在经过多次卷积池化这样操作后，需要将提取到的特征展平，放入全连接层。<br><img src="https://img-blog.csdnimg.cn/83422a736a2845b8bdce3e5b13a48a17.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>Flatten操作可以根据下面的图，很方便地理解。<br><img src="https://img-blog.csdnimg.cn/c52adc8c80dd45d18f3ee256c092963e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="使用Keras设计CNN"><a href="#使用Keras设计CNN" class="headerlink" title="使用Keras设计CNN"></a>使用Keras设计CNN</h1><p><img src="https://img-blog.csdnimg.cn/ed6cc2151db24606a6fb7e77f77b82b9.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>需要注意的是，从第二卷积层开始，每一个过滤器的深度都是上一层过滤器的个数。<br><img src="https://img-blog.csdnimg.cn/1fd502b01ed340dcb8cb172935d11162.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/2f1354230903476c8d60847aaa1b5fd4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="Pytorch搭建CNN"><a href="#Pytorch搭建CNN" class="headerlink" title="Pytorch搭建CNN"></a>Pytorch搭建CNN</h1><p>可以看我的这篇文章，<a href="https://blog.csdn.net/weixin_44491423/article/details/121892838">CNN图片分类(Pytorch)</a>。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习(十三)——神经网络</title>
      <link href="/2021/12/09/ML13_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2021/12/09/ML13_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<blockquote><p>人工神经网络（artificial neural network，ANN），简称神经网络（neural network，NN），是一种模仿生物神经网络的结构和功能的数学模型或计算模型。神经网络由大量的人工神经元联结进行计算。大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种自适应系统。现代神经网络是一种非线性统计性数据建模工具，常用来对输入和输出间复杂的关系进行建模，或用来探索数据的模式。</p></blockquote><span id="more"></span><hr><h1 id="神经网络概述"><a href="#神经网络概述" class="headerlink" title="神经网络概述"></a>神经网络概述</h1><p><img src="https://img-blog.csdnimg.cn/655ec7a727ec4f9c8d73ff57448b9aed.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>神经网络是一种运算模型，由大量的节点（或称“神经元”）和之间相互的联接构成。每个节点代表一种特定的输出函数，称为<strong>激励函数</strong>、<strong>激活函数</strong>（activation function）。每两个节点间的联接都代表一个对于通过该连接信号的加权值，称之为<strong>权重</strong>，这相当于人工神经网络的记忆。网络的输出则依网络的连接方式，权重值和激励函数的不同而不同。而网络自身通常都是对自然界某种算法或者函数的逼近，也可能是对一种逻辑策略的表达。</p><p>对于上面的神经网络我们需要估计以下参数：<br><strong>(w<sub>11</sub>，w<sub>12</sub>，w<sub>21</sub>，w<sub>22</sub>，w<sub>1</sub>，w<sub>2</sub>，b<sub>1</sub>，b<sub>2</sub>，b<sub>3</sub>)</strong><br>目标函数为：<br><strong>Minimize: E(W,b) = 1/2(y-Y)<sup>2</sup></strong></p><hr><h1 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h1><p><img src="https://img-blog.csdnimg.cn/ec503ca0e3174fb2ad8c63c2c8e9df34.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>我们先以简单的神经网络为例。<br><img src="https://img-blog.csdnimg.cn/a7da1d7b2c39412593841ee49f7148f0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>要求九个偏导数<br><img src="https://img-blog.csdnimg.cn/adbde9f8ef6b43a4ae68e48bed114086.png"><br>虽然我们可以逐一的计算这些偏导数，但是这样做的计算量太大，我们其实可以利用神经网络这种分层结构，来简化求解偏导数的计算，这个算法也被称为后向传播算法。</p><p>可以用已经算出的偏导数去计算还没有算出的另一些偏导数，这比直接计算9个偏导数要方便很多。<br>在这个网络中先计算<strong>Z<sub>1</sub>,Z<sub>2</sub>,y</strong>的偏导数。因为这三个点是整个网络的枢纽，其他偏导数都可以很容易地通过这三个点的偏导数算出来，接下来我们来计算这三个偏导数。<br><img src="https://img-blog.csdnimg.cn/7a421c710d2e4713b0d60b211cfbbf17.png"><br><img src="https://img-blog.csdnimg.cn/2132ffe4bf6d475fb4ae5333f3151aba.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/766d410e863a4f75a5b1594a08f45f33.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/fd24d27cf7bf4a3e9d8d81f0ecafbd3c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/f9e94a3ce67a4832baae21015456cbd2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_11,color_FFFFFF,t_70,g_se,x_16"><br>通过这三个关键位置的偏导数，很容易求出前面9个偏导数。<br><img src="https://img-blog.csdnimg.cn/f1572e2129a940b580a933a06a75e493.png"><br><img src="https://img-blog.csdnimg.cn/35f12169c1ef47adae1128f90ab68586.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/fbd16d582e0d4e9da75848dda4d5ff1b.png"><br><img src="https://img-blog.csdnimg.cn/effd083a9d8d483d89c28274769ff610.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/6172b355147047d0ad8686f4181c3cf3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/e01a26c777e54bd2a523a529dfd1f58a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/87a75722dc6c4572a98b5ebed8bb3d4b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/590de8798fad47fea83351d0fde97a9a.png"></p><hr><h1 id="后向传播"><a href="#后向传播" class="headerlink" title="后向传播"></a>后向传播</h1><p>人工神经网络后向传播算法的步骤：<br><img src="https://img-blog.csdnimg.cn/2467979bd1a0442492092fc6a68319a8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/79e7f223721244f2831b671139c32d1d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="更一般的神经网络"><a href="#更一般的神经网络" class="headerlink" title="更一般的神经网络"></a>更一般的神经网络</h1><p>之前我们是通过简单的神经网络模型来推到后向传播的，下面我们通过更一般的神经网络进行后向传播。<br><img src="https://img-blog.csdnimg.cn/a21d099f957c4323887bf976c606a128.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/ff229a08531c4506b6b813cd14f5978f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/1cd248c81ec546d7b48fd998b0f055e3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/d688a6255a2943d6a960797d795afc20.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/1cadcbaf5ed3463b8a0a07dcfa0f3a1d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/2ac1eab55d074a0197be6d38b0c8041f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/49931ce4bf994ea0a20a1850193583d3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/feff54a1d5194b418fc16239ba96ba0c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/71204a6adfc741d491e652fe3bdb1a66.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/cf14b57d59e042c696774b0336951e68.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/f595e7986f40451795dde6ed76186c0d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>一般情况下，反向传播算法的算法流程：<br><img src="https://img-blog.csdnimg.cn/ebb830d8741d46d3a494c5e8535f24a6.png"><br><img src="https://img-blog.csdnimg.cn/0a90bdecadb94b0bbeeac8a9201836cf.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/a1540b09d4614003b8786c1782fc203e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/70071ffa66da4836b9a57130dfd4359d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/6a1f55d1bcb64df2940e99167ac7a801.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="神经网络的改进"><a href="#神经网络的改进" class="headerlink" title="神经网络的改进"></a>神经网络的改进</h1><h2 id="对非线性（激活函数）的改进"><a href="#对非线性（激活函数）的改进" class="headerlink" title="对非线性（激活函数）的改进"></a>对非线性（激活函数）的改进</h2><p><img src="https://img-blog.csdnimg.cn/6f2e25b2d3a343a7ab7caab7e7c8f821.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>如果使用阶跃函数，导数就不是连续的了，所以我们对其进行改进，有以下几种选择。</p><ol><li><strong>sigmoid函数</strong><br>这个我们在逻辑回归中使用过。<br><img src="https://img-blog.csdnimg.cn/c121e152904342d49295e2dfd804b249.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/f88fae5158864207a49e5b1fea5147cd.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/4634bb40d79e4d438812fc5b1c6314f2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></li></ol><ol start="2"><li><p><strong>双曲正切tanh函数</strong><br><img src="https://img-blog.csdnimg.cn/9ef2ef5e5ed342b7827a43b47777a0ea.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/2a16eb780f6244b9ac7e38b9b5e8aa00.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p></li><li><p><strong>ReLU函数</strong><br><img src="https://img-blog.csdnimg.cn/11169790f748439fb3f6e1d2739f9d03.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/e6b96633923c490d9693c960bb16cfef.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/e72ea2c70ab6465b89b91c95d6137a7e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p></li><li><p><strong>Leaky Relu函数</strong><br><img src="https://img-blog.csdnimg.cn/ef5ef9fb8e604e47bd465607127698a0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p></li><li><p><strong>Maxout函数</strong><br><img src="https://img-blog.csdnimg.cn/c4670a59010344ebadab51b1014491c4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p></li></ol><p><strong>如何选择非线性函数作为激活函数</strong><br><img src="https://img-blog.csdnimg.cn/e88f82ddf9d34883a708c6f76387d9ce.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h2 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h2><p><img src="https://img-blog.csdnimg.cn/f6c6b9e6daa540d7beb14de0ad38e47d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/e69757801af046a3b2f22fa4f621d236.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/a4530e2799354a118329e7a97129fe9f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/94ce94989b794b2b97204279aa0b4144.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/de86becad1704b288b4dad0c4f82340d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/21c7016b570746048b8545fa5ad27166.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/85fdfe54de73448d9f6ee5d4b32837f4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/4713282e103b40fd834fdb2a49425a55.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/ab5142feb4e64db6abb63e632127e1f1.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/ac4ac3c1a3f24854820808395ccfe7d7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="随机梯度下降法（SGD）"><a href="#随机梯度下降法（SGD）" class="headerlink" title="随机梯度下降法（SGD）"></a>随机梯度下降法（SGD）</h2><p><img src="https://img-blog.csdnimg.cn/0d2487fe28ad45e79e2763b0b5bdd5d0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/c44d566cd9524c0abea02faf32c8aece.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/458cdbc02f004ba58ebff0597ca1c521.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/4d25b65809414f60a9c0351c2708eccc.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/c56362bc7f4d4db889dca16ad48de1e8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="鸢尾花分类"><a href="#鸢尾花分类" class="headerlink" title="鸢尾花分类"></a>鸢尾花分类</h1><p> Iris数据集是常用的分类实验数据集，由Fisher, 1936收集整理。Iris也称鸢尾花卉数据集，是一类多重变量分析的数据集。数据集包含150个数据集，分为3类，每类50个数据，每个数据包含4个属性。可通过花萼长度，花萼宽度，花瓣长度，花瓣宽度4个属性预测鸢尾花卉属于（Setosa，Versicolour，Virginica）三个种类中的哪一类。</p><ul><li>属性：<br>Sepal.Length（花萼长度），单位是cm;<br>Sepal.Width（花萼宽度），单位是cm;<br>Petal.Length（花瓣长度），单位是cm;<br>Petal.Width（花瓣宽度），单位是cm;</li><li>种类：<br>Iris Setosa（山鸢尾）（本例中使用数字‘0’表示）<br>Iris Versicolour（杂色鸢尾）（本例中使用数字‘1’表示）<br>Iris Virginica（维吉尼亚鸢尾）（本例中使用数字‘2’表示）</li></ul><ol><li>定义sigmoid函数</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define sigmoid function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span>(<span class="params">z</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))</span><br></pre></td></tr></table></figure><ol start="2"><li><p>神经网络结构确定<br>该函数主要是为了获取输入量x的矩阵大小，以及标签y的矩阵大小。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">layer_size</span>(<span class="params">X, Y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param X: input dataset of shape (input size, number of examples)  (输入数据集大小（几个属性，样本量）)</span></span><br><span class="line"><span class="string">    :param Y: labels of shape (output size, number of exmaples) (标签数据大小（标签数，样本量）)</span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    n_x: the size of the input layer</span></span><br><span class="line"><span class="string">    n_y: the size of the output layer</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    n_x = X.shape[<span class="number">0</span>]</span><br><span class="line">    n_y = Y.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (n_x, n_y)</span><br></pre></td></tr></table></figure></li><li><p>权重和偏移量参数初始化<br>该函数主要是为了初始化我们的连接权重w和偏移量b。要注意的是确保参数矩阵大小正确。</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_parameters</span>(<span class="params">n_x, n_h, n_y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    initialize_parameters</span></span><br><span class="line"><span class="string">    (参数初始化)</span></span><br><span class="line"><span class="string">    :param n_x: size of the input layer </span></span><br><span class="line"><span class="string">    :param n_h: size of the hidden layer</span></span><br><span class="line"><span class="string">    :param n_y: size of the output layer</span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    W1: weight matrix of shape (n_h, n_x) (第1层的权重矩阵(n_h, n_x))</span></span><br><span class="line"><span class="string">    b1: bias vector of shape (n_h, 1) (第1层的偏移量向量(n_h, 1))</span></span><br><span class="line"><span class="string">    W2: weight matrix of shape (n_y, n_h) (第2层的权重矩阵(n_y, n_h))</span></span><br><span class="line"><span class="string">    b2: bias vector of shape (n_y, 1) (第2层的偏移量向量(n_y, 1))</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># np.random.seed(2)  #Random initialization (随机种子初始化参数)</span></span><br><span class="line"></span><br><span class="line">    W1 = np.random.randn(n_h, n_x) * <span class="number">0.01</span></span><br><span class="line">    b1 = np.zeros((n_h, <span class="number">1</span>))</span><br><span class="line">    W2 = np.random.randn(n_y, n_h) * <span class="number">0.01</span></span><br><span class="line">    b2 = np.zeros((n_y, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    parameters = &#123;</span><br><span class="line">        <span class="string">&#x27;W1&#x27;</span>: W1,</span><br><span class="line">        <span class="string">&#x27;b1&#x27;</span>: b1,</span><br><span class="line">        <span class="string">&#x27;W2&#x27;</span>: W2,</span><br><span class="line">        <span class="string">&#x27;b2&#x27;</span>: b2,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><ol start="4"><li><p>正向传播计算<br>该函数为正向传播计算，需要注意的是，中间层的激活函数为tanh，输出层的激活函数为sigmoid。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span>(<span class="params">X, parameters</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    forward_propagation</span></span><br><span class="line"><span class="string">    (正向传播)</span></span><br><span class="line"><span class="string">    :param X: input data of size (n_x, m)  (输入数据集X)</span></span><br><span class="line"><span class="string">    :param parameters: python dictionary containing your parameters (output of initialization function) (字典类型，权重以及偏移量参数)</span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    A2: The sigmoid output of the second activation (第2层激活函数sigmoid函数输出向量)</span></span><br><span class="line"><span class="string">    cache: a dictionary containing &quot;Z1&quot;, &quot;A1&quot;, &quot;Z2&quot; and &quot;A2&quot; (字典类型,包含&quot;Z1&quot;, &quot;A1&quot;, &quot;Z2&quot;, &quot;A2&quot;)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    W1 = parameters[<span class="string">&#x27;W1&#x27;</span>]</span><br><span class="line">    b1 = parameters[<span class="string">&#x27;b1&#x27;</span>]</span><br><span class="line">    W2 = parameters[<span class="string">&#x27;W2&#x27;</span>]</span><br><span class="line">    b2 = parameters[<span class="string">&#x27;b2&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    Z1 = np.dot(W1, X) + b1</span><br><span class="line">    A1 = np.tanh(Z1)            <span class="comment">#第1层激活函数选择tanh</span></span><br><span class="line">    Z2 = np.dot(W2, A1) + b2</span><br><span class="line">    A2 = sigmoid(Z2)            <span class="comment">#第2层激活函数选择sigmod</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> (A2.shape == (<span class="number">1</span>, X.shape[<span class="number">1</span>])) <span class="comment">#若A2的大小和((1, X.shape[1]))不同，则直接报异常</span></span><br><span class="line"></span><br><span class="line">    cache = &#123;</span><br><span class="line">        <span class="string">&#x27;Z1&#x27;</span>: Z1,</span><br><span class="line">        <span class="string">&#x27;A1&#x27;</span>: A1,</span><br><span class="line">        <span class="string">&#x27;Z2&#x27;</span>: Z2,</span><br><span class="line">        <span class="string">&#x27;A2&#x27;</span>: A2,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> A2, cache</span><br></pre></td></tr></table></figure></li><li><p>代价函数计算<br>该函数主要是为了计算代价函数，注意一个样本的期望输出和实际输出的误差的平方用来定义损失函数，在向量化的计算过程中，这里使用了代价函数。<br>交叉熵损失是分类任务中的常用损失函数，最后一层是sigmoid<br><img src="https://img-blog.csdnimg.cn/1052810a39994037a36932c20dbaa69b.png"></p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cost</span>(<span class="params">A2, Y, parameters</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    compute cost(计算成本函数)</span></span><br><span class="line"><span class="string">    :param A2: The sigmoid output of the second activation, of shape (1, number of examples) (第2层激活函数sigmoid函数输出向量)</span></span><br><span class="line"><span class="string">    :param Y: &quot;true&quot; labels vector of shape (1, number of examples) (正确标签向量)</span></span><br><span class="line"><span class="string">    :param parameters: python dictionary containing your parameters W1, b1, W2 and b2 (字典类型，权重以及偏移量参数)</span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    cost: cross-entropy cost </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    m = Y.shape[<span class="number">1</span>]  <span class="comment"># number of example</span></span><br><span class="line"></span><br><span class="line">    W1 = parameters[<span class="string">&#x27;W1&#x27;</span>]</span><br><span class="line">    W2 = parameters[<span class="string">&#x27;W2&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    logprobs = np.multiply(np.log(A2), Y)</span><br><span class="line">    cost = - np.<span class="built_in">sum</span>(np.multiply(np.log(A2), Y) + np.multiply(np.log(<span class="number">1.</span> - A2), <span class="number">1.</span> - Y)) / m</span><br><span class="line">    <span class="comment"># cost = np.sum(Y * np.log(A2) + (1 - Y) * np.log(1 - A2))/(-m)</span></span><br><span class="line"></span><br><span class="line">    cost = np.squeeze(cost) <span class="comment">#squeeze()函数的功能是：从矩阵shape中，去掉维度为1的。例如一个矩阵是的shape是（5，1），使用过这个函数后，结果为（5，）。</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> (<span class="built_in">isinstance</span>(cost, <span class="built_in">float</span>)) <span class="comment">#若cost不是float型 则直接报异常</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure><ol start="6"><li>反向传播计算<br>该函数为方向传播计算。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_propagation</span>(<span class="params">parameters, cache, X, Y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    backward propagation(反向传播)</span></span><br><span class="line"><span class="string">    :param parameters: python dictionary containing our parameters</span></span><br><span class="line"><span class="string">    :param cache: a dictionary containing &quot;Z1&quot;, &quot;A1&quot;, &quot;Z2&quot; and &quot;A2&quot;</span></span><br><span class="line"><span class="string">    :param X: input data of shape (2,number of examples)</span></span><br><span class="line"><span class="string">    :param Y: &quot;ture&quot; labels vector of shape (1, number of examples)</span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    grads: python dictionary containing your gradients with respect to different parameters (字典类型，梯度微分参数)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    m = X.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    W1 = parameters[<span class="string">&#x27;W1&#x27;</span>]</span><br><span class="line">    W2 = parameters[<span class="string">&#x27;W2&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    A1 = cache[<span class="string">&#x27;A1&#x27;</span>]</span><br><span class="line">    A2 = cache[<span class="string">&#x27;A2&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    dZ2 = A2 - Y</span><br><span class="line">    dW2 = np.dot(dZ2, A1.T) / m</span><br><span class="line">    db2 = np.<span class="built_in">sum</span>(dZ2, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>) / m</span><br><span class="line">    dZ1 = np.dot(W2.T, dZ2) * (<span class="number">1</span> - A1 ** <span class="number">2</span>)</span><br><span class="line">    dW1 = np.dot(dZ1, X.T) / m</span><br><span class="line">    db1 = np.<span class="built_in">sum</span>(dZ1, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>) / m</span><br><span class="line"></span><br><span class="line">    grads = &#123;</span><br><span class="line">        <span class="string">&#x27;dW1&#x27;</span>: dW1,</span><br><span class="line">        <span class="string">&#x27;db1&#x27;</span>: db1,</span><br><span class="line">        <span class="string">&#x27;dW2&#x27;</span>: dW2,</span><br><span class="line">        <span class="string">&#x27;db2&#x27;</span>: db2,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> grads</span><br></pre></td></tr></table></figure><ol start="7"><li>权重和偏移量参数更新<br>该函数为更新权重和偏移量参数。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_parameters</span>(<span class="params">parameters, grads, learning_rate</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    update parameters(更新权重和偏移量参数)</span></span><br><span class="line"><span class="string">    :param parameters: python dictionary containing your parameters</span></span><br><span class="line"><span class="string">    :param grads: python dictionary containing your gradients </span></span><br><span class="line"><span class="string">    :param learning_rate (学习速率)</span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    :parameters:  python dictionary containing your updated parameters </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    W1 = parameters[<span class="string">&#x27;W1&#x27;</span>]</span><br><span class="line">    b1 = parameters[<span class="string">&#x27;b1&#x27;</span>]</span><br><span class="line">    W2 = parameters[<span class="string">&#x27;W2&#x27;</span>]</span><br><span class="line">    b2 = parameters[<span class="string">&#x27;b2&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    dW1 = grads[<span class="string">&#x27;dW1&#x27;</span>]</span><br><span class="line">    db1 = grads[<span class="string">&#x27;db1&#x27;</span>]</span><br><span class="line">    dW2 = grads[<span class="string">&#x27;dW2&#x27;</span>]</span><br><span class="line">    db2 = grads[<span class="string">&#x27;db2&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    W1 = W1 - learning_rate * dW1</span><br><span class="line">    b1 = b1 - learning_rate * db1</span><br><span class="line">    W2 = W2 - learning_rate * dW2</span><br><span class="line">    b2 = b2 - learning_rate * db2</span><br><span class="line"></span><br><span class="line">    parameters = &#123;</span><br><span class="line">        <span class="string">&quot;W1&quot;</span>: W1,</span><br><span class="line">        <span class="string">&quot;b1&quot;</span>: b1,</span><br><span class="line">        <span class="string">&quot;W2&quot;</span>: W2,</span><br><span class="line">        <span class="string">&quot;b2&quot;</span>: b2,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure><ol start="8"><li>BP神经网络<br>我们将上面的几个函数组合起来，就可以得到一个两层的BP神经网络模型。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nn_model</span>(<span class="params">X, Y, n_h, num_iterations, learning_rate, print_cost=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Forward Neural Network model(前向神经网络模型)</span></span><br><span class="line"><span class="string">    :param X: input dataset of shape (input size, number of examples)  (输入数据集大小（几个属性，样本量）)</span></span><br><span class="line"><span class="string">    :param Y: labels of shape (output size, number of exmaples) (标签数据大小（标签数，样本量）)</span></span><br><span class="line"><span class="string">    :param n_h: size of the hidden layer (隐层神经元数量)</span></span><br><span class="line"><span class="string">    :param num_iterations:  Number of iterations in gradient descent loop (迭代次数)</span></span><br><span class="line"><span class="string">    :param learning_rate (学习速率)</span></span><br><span class="line"><span class="string">    :param print_cost: if True, print the cost every 1000 iterations (是否打印显示)</span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    parameters: parameters learnt by the model. They can then be used to predict (训练完成后的参数)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># np.random.seed(4)</span></span><br><span class="line">    n_x = layer_size(X, Y)[<span class="number">0</span>]</span><br><span class="line">    n_y = layer_size(X, Y)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    parameters = initialize_parameters(n_x, n_h, n_y)</span><br><span class="line">    W1 = parameters[<span class="string">&#x27;W1&#x27;</span>]</span><br><span class="line">    b1 = parameters[<span class="string">&#x27;b1&#x27;</span>]</span><br><span class="line">    W2 = parameters[<span class="string">&#x27;W2&#x27;</span>]</span><br><span class="line">    b2 = parameters[<span class="string">&#x27;b2&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    cost_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_iterations):</span><br><span class="line"></span><br><span class="line">        A2, cache = forward_propagation(X, parameters)</span><br><span class="line">        cost = compute_cost(A2, Y, parameters)</span><br><span class="line">        cost_list.append(cost)</span><br><span class="line">        grads = backward_propagation(parameters, cache, X, Y)</span><br><span class="line">        parameters = update_parameters(parameters, grads, learning_rate)</span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Cost after iteration %i: %f&quot;</span> % (i, cost))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parameters, cost_list</span><br></pre></td></tr></table></figure><ol start="9"><li>鸢尾花分类测试</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment">#from Forward_NeuralNetwork import *</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_csv</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;加载处理好存入csv格式的数据&quot;&quot;&quot;</span></span><br><span class="line">    tmp = np.loadtxt(<span class="string">&quot;iris.csv&quot;</span>,dtype=np.<span class="built_in">str</span>, delimiter=<span class="string">&quot;,&quot;</span>)</span><br><span class="line">    data = tmp[<span class="number">1</span>:, <span class="number">1</span>:<span class="number">5</span>].astype(np.<span class="built_in">float</span>)</span><br><span class="line">    label = tmp[<span class="number">1</span>:, <span class="number">5</span>]   <span class="comment">#.astype(np.float)</span></span><br><span class="line"><span class="comment">#     print(data.shape)</span></span><br><span class="line"><span class="comment">#     print(label.shape)</span></span><br><span class="line">    label = label.reshape(<span class="number">150</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> data.T, label.T</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalized</span>(<span class="params">X</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param X: 待归一化的数据 </span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    X：归一化后的数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    Xmin, Xmax = X.<span class="built_in">min</span>(), X.<span class="built_in">max</span>()</span><br><span class="line">    XN = (X - Xmin) / (Xmax - Xmin)</span><br><span class="line">    <span class="keyword">return</span> XN</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line"></span><br><span class="line">    X, Y = load_csv()</span><br><span class="line">    X = normalized(X)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">        <span class="keyword">if</span> Y[<span class="number">0</span>][i]==<span class="string">&#x27;Iris-setosa&#x27;</span>:</span><br><span class="line">            Y[<span class="number">0</span>][i] = <span class="string">&#x27;0&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> Y[<span class="number">0</span>][i]==<span class="string">&#x27;Iris-versicolor&#x27;</span>:</span><br><span class="line">            Y[<span class="number">0</span>][i] = <span class="string">&#x27;1&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> Y[<span class="number">0</span>][i]==<span class="string">&#x27;Iris-virginica&#x27;</span>:</span><br><span class="line">            Y[<span class="number">0</span>][i] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line">    Y = Y.astype(np.<span class="built_in">float</span>)</span><br><span class="line"><span class="comment">#     print(Y)</span></span><br><span class="line">    Y = normalized(Y)</span><br><span class="line">    <span class="string">&quot;&quot;&quot;训练集90个数据&quot;&quot;&quot;</span></span><br><span class="line">    train_x = np.hstack((X[:, <span class="number">0</span>:<span class="number">30</span>], X[:, <span class="number">50</span>:<span class="number">80</span>], X[:, <span class="number">100</span>:<span class="number">130</span>]))</span><br><span class="line">    train_y = np.hstack((Y[:, <span class="number">0</span>:<span class="number">30</span>], Y[:, <span class="number">50</span>:<span class="number">80</span>], Y[:, <span class="number">100</span>:<span class="number">130</span>]))</span><br><span class="line">    <span class="string">&quot;&quot;&quot;测试集60个数据&quot;&quot;&quot;</span></span><br><span class="line">    test_x = np.hstack((X[:, <span class="number">30</span>:<span class="number">50</span>], X[:, <span class="number">80</span>:<span class="number">100</span>], X[:, <span class="number">130</span>:<span class="number">150</span>]))</span><br><span class="line">    test_y = np.hstack((Y[:, <span class="number">30</span>:<span class="number">50</span>], Y[:, <span class="number">80</span>:<span class="number">100</span>], Y[:, <span class="number">130</span>:<span class="number">150</span>]))</span><br><span class="line">    <span class="string">&quot;&quot;&quot;训练，中间层10个神经元，迭代10000次，学习率0.25&quot;&quot;&quot;</span></span><br><span class="line">    n_h = <span class="number">10</span></span><br><span class="line">    parameter, cost_list = nn_model(train_x, train_y, n_h, num_iterations=<span class="number">10000</span>, learning_rate=<span class="number">0.25</span>, print_cost=<span class="literal">True</span>)</span><br><span class="line">    <span class="string">&quot;&quot;&quot;测试，代入测试集数据&quot;&quot;&quot;</span></span><br><span class="line">    A2, cache = forward_propagation(test_x, parameters=parameter)</span><br><span class="line">    TY = A2</span><br><span class="line">    TY[TY &gt; <span class="number">0.8</span>] = <span class="number">1</span></span><br><span class="line">    TY[TY &lt; <span class="number">0.2</span>] = <span class="number">0</span></span><br><span class="line">    TY[(TY &gt;= <span class="number">0.2</span>) &amp; (TY &lt;= <span class="number">0.8</span>)] = <span class="number">0.5</span></span><br><span class="line">    <span class="comment"># print(A2,TY)</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">60</span>):</span><br><span class="line">        <span class="keyword">if</span> TY[<span class="number">0</span>, i] == test_y[<span class="number">0</span>, i]:</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;准确率为：%f %%&quot;</span> %(<span class="number">100</span>*count/<span class="number">60</span>))</span><br><span class="line">    <span class="string">&quot;&quot;&quot;绘制梯度下降曲线&quot;&quot;&quot;</span></span><br><span class="line">    plt.plot(cost_list)</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>测试结果<br>测试中，将150个数划分成了90个训练数据，60个测试数据。神经网络的中间层为10个神经元，迭代次数为10000次，学习率为0.25。在训练和测试中，需要对数据进行归一化，其中包括对标签数据Y的归一化。<br>设置的三类鸢尾花的标签分别是0，1，2。通过归一化之后，获得的标签数据为0，0.5，1。对测试集获得的结果，进行归档，小于0.2的为0，大于0.8的为1，其余的均为0.5。<br>最终获得的分类结果的准确率是多少。<br><img src="https://img-blog.csdnimg.cn/13929280004e49fe98e4f15864a7c101.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_12,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/77e1012fc4c44a81bc16bf3030dc2291.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_17,color_FFFFFF,t_70,g_se,x_16"><br>sklearn包神经网络的使用可以看<a href="https://blog.csdn.net/weixin_44491423/article/details/116711606?spm=1001.2014.3001.5501">这篇博客</a>。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习(十二)——感知器算法</title>
      <link href="/2021/12/08/ML12_%E6%84%9F%E7%9F%A5%E5%99%A8%E7%AE%97%E6%B3%95/"/>
      <url>/2021/12/08/ML12_%E6%84%9F%E7%9F%A5%E5%99%A8%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<blockquote><p>感知器算法是一种可以直接得到线性判别函数的线性分类方法，它是基于样本线性可分的要求下使用的</p></blockquote><hr><h1 id="线性可分与线性不可分"><a href="#线性可分与线性不可分" class="headerlink" title="线性可分与线性不可分"></a>线性可分与线性不可分</h1><p><img src="https://img-blog.csdnimg.cn/19bb8f3cb86b4384b4ff913d3afc8167.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><span id="more"></span><p><img src="https://img-blog.csdnimg.cn/28af7a9bbd7c44e5991157cb4aceb8fc.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h1><p>感知器作为人工神经网络中最基本的单元，有多个输入和一个输出组成。虽然我们的目的是学习很多神经单元互连的网络，但是我们还是需要先对单个的神经单元进行研究。<br>感知器算法的主要流程：</p><p>　　首先得到n个输入，再将每个输入值加权，然后判断感知器输入的加权和最否达到某一阀值v，若达到，则通过sign函数输出1，否则输出-1。<br><img src="https://img-blog.csdnimg.cn/60a0c45e394d4bf8a03d5b5e56657faa.png"><br>为了统一表达式，我们将上面的阀值<code>v</code>设为<code>0</code>，新增变量x<sub>0</sub>=1,这样就可以使用w<sub>0</sub>x<sub>0</sub>+w<sub>1</sub>x<sub>1</sub>+w<sub>2</sub>x<sub>2</sub>+…+w<sub>n</sub>x<sub>n</sub>。于是有：<br><img src="https://img-blog.csdnimg.cn/266152aef90a49b2b17fa08953acd65e.png"><br>从上面的公式可知，当权值向量确定时，就可以利用感知器来做分类。</p><p>那么我们如何获得感知器的权值呢？这需要根据训练集是否可分来采用不同的方法：</p><p>1、训练集线性可分时 –&gt; 感知器训练法则</p><p>　　为了得到可接受的权值，通常从随机的权值开始，然后利用训练集反复训练权值，最后得到能够正确分类所有样例的权向量。</p><p>具体算法过程如下：</p><p>A）初始化权向量w=(w<sub>0</sub>,w<sub>1</sub>,…,w<sub>n</sub>)，将权向量的每个值赋一个随机值。<br>B）对于每个训练样例，首先计算其预测输出：<br><img src="https://img-blog.csdnimg.cn/b0547859bc654635abaea0c6bfd92321.png"><br>C）当预测值不等于真实值时则利用如下公式修改权向量：<br><img src="https://img-blog.csdnimg.cn/6d493c99f79b4235b4e98dff18751a4c.png"><br>D）重复B）和C），直到训练集中没有被错分的样例。</p><p>算法分析：</p><p>　　若某个样例被错分了，假如目标输出t为-1，结果感知器o输出为1，此时为了让感知器输出-1，需要将wx减小以输出-1，而在x的值不变的情况下只能减小w的值，这时通过在原来w后面添加(t-o)x=即可减小w的值（t-o&lt;0, x&gt;0）。</p><p>　　通过逐步调整w的值，最终感知器将会收敛到能够将所有训练集正确分类的程度，但前提条件是训练集线性可分。若训练集线性不可分，则上述过程不会收敛，将无限循环下去。</p><hr><h1 id="实现算法"><a href="#实现算法" class="headerlink" title="实现算法"></a>实现算法</h1><ol><li><strong>生成数据</strong></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line">x = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"><span class="comment"># 只做一个简单的二分类</span></span><br><span class="line">x = x[y&lt;<span class="number">2</span>, :<span class="number">2</span>]</span><br><span class="line">y = y[y&lt;<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/8b6bcbd3d36847b1a3adde932020a12b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><ol start="2"><li><strong>实现算法</strong></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check</span>(<span class="params">w, x, y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> ((w.dot(x.T)&gt;<span class="number">0</span>).astype(<span class="built_in">int</span>)==y).<span class="built_in">all</span>() </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">w, train_x, train_y, learn=<span class="number">1</span>, max_iter=<span class="number">200</span></span>):</span></span><br><span class="line">    <span class="built_in">iter</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> ~check(w, train_x, train_y) <span class="keyword">and</span> <span class="built_in">iter</span>&lt;=max_iter:</span><br><span class="line">        <span class="built_in">iter</span> += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(train_y.size):</span><br><span class="line">            predict_y = (w.dot(train_x[i].T)&gt;<span class="number">0</span>).astype(<span class="built_in">int</span>)</span><br><span class="line">            <span class="keyword">if</span> predict_y != train_y[i]:</span><br><span class="line">                w += learn*(train_y[i] - predict_y)*train_x[i]</span><br><span class="line">    <span class="keyword">return</span> w</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span>(<span class="params">x</span>):</span></span><br><span class="line">    max_x = np.<span class="built_in">max</span>(x, axis=<span class="number">0</span>)</span><br><span class="line">    min_x = np.<span class="built_in">min</span>(x, axis=<span class="number">0</span>)</span><br><span class="line">    norm_x = (max_x - x) / (max_x - min_x)</span><br><span class="line">    <span class="keyword">return</span> norm_x</span><br><span class="line"></span><br><span class="line">norm_x = normalize(x)</span><br><span class="line">train_x = np.insert(norm_x, <span class="number">0</span>, values=np.ones(<span class="number">100</span>).T, axis=<span class="number">1</span>)</span><br><span class="line">w = np.random.random(<span class="number">3</span>)</span><br><span class="line">w = train(w, train_x, y)</span><br></pre></td></tr></table></figure><ol start="3"><li><strong>绘制决策边界</strong></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_decision_boundary</span>(<span class="params">w, axis</span>):</span></span><br><span class="line">    x0, x1 = np.meshgrid(np.linspace(axis[<span class="number">0</span>], axis[<span class="number">1</span>], <span class="built_in">int</span>((axis[<span class="number">1</span>] - axis[<span class="number">0</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),</span><br><span class="line">                         np.linspace(axis[<span class="number">2</span>], axis[<span class="number">3</span>], <span class="built_in">int</span>((axis[<span class="number">3</span>] - axis[<span class="number">2</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),)</span><br><span class="line">    x_new = np.c_[x0.ravel(), x1.ravel()]</span><br><span class="line">    x_new = np.insert(x_new, <span class="number">0</span>, np.ones(x_new.shape[<span class="number">0</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    y_predict = (w.dot(x_new.T)&gt;<span class="number">0</span>).astype(<span class="built_in">int</span>)</span><br><span class="line">    zz = y_predict.reshape(x0.shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line">    custom_cmap = ListedColormap([<span class="string">&#x27;#EF9A9A&#x27;</span>, <span class="string">&#x27;#FFF59D&#x27;</span>, <span class="string">&#x27;#90CAF9&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    plt.contourf(x0, x1, zz, linewidth=<span class="number">5</span>, cmap=custom_cmap)</span><br><span class="line"></span><br><span class="line">plot_decision_boundary(w, axis=[-<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(norm_x[y==<span class="number">0</span>, <span class="number">0</span>], norm_x[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.scatter(norm_x[y==<span class="number">1</span>, <span class="number">0</span>], norm_x[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/e1c7aeb5cf924c4b909f500ce9e8c1e4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>4. <strong>使用sklearn包完成感知器算法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line"> </span><br><span class="line">x,y = make_classification(n_samples=<span class="number">1000</span>, n_features=<span class="number">2</span>,n_redundant=<span class="number">0</span>,n_informative=<span class="number">1</span>,n_clusters_per_class=<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#n_samples:生成样本的数量</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#n_features=2:生成样本的特征数，特征数=n_informative（） + n_redundant + n_repeated</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#n_informative：多信息特征的个数</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#n_redundant：冗余信息，informative特征的随机线性组合</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#n_clusters_per_class ：某一个类别是由几个cluster构成的 </span></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练数据和测试数据</span></span><br><span class="line">x_data_train = x[:<span class="number">800</span>,:]</span><br><span class="line">x_data_test = x[<span class="number">800</span>:,:]</span><br><span class="line">y_data_train = y[:<span class="number">800</span>]</span><br><span class="line">y_data_test = y[<span class="number">800</span>:]</span><br><span class="line"> </span><br><span class="line"><span class="comment">#正例和反例</span></span><br><span class="line">positive_x1 = [x[i,<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>) <span class="keyword">if</span> y[i] == <span class="number">1</span>]</span><br><span class="line">positive_x2 = [x[i,<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>) <span class="keyword">if</span> y[i] == <span class="number">1</span>]</span><br><span class="line">negetive_x1 = [x[i,<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>) <span class="keyword">if</span> y[i] == <span class="number">0</span>]</span><br><span class="line">negetive_x2 = [x[i,<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>) <span class="keyword">if</span> y[i] == <span class="number">0</span>]</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Perceptron</span><br><span class="line"><span class="comment">#定义感知机</span></span><br><span class="line">clf = Perceptron(fit_intercept=<span class="literal">False</span>,shuffle=<span class="literal">False</span>)</span><br><span class="line"><span class="comment">#使用训练数据进行训练</span></span><br><span class="line">clf.fit(x_data_train,y_data_train)</span><br><span class="line"><span class="comment">#得到训练结果，权重矩阵</span></span><br><span class="line"><span class="built_in">print</span>(clf.coef_)</span><br><span class="line"><span class="comment">#输出为：[[-0.38478876,4.41537463]]</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#超平面的截距，此处输出为：[0.]</span></span><br><span class="line"><span class="built_in">print</span>(clf.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用测试数据进行验证</span></span><br><span class="line">acc = clf.score(x_data_test,y_data_test)</span><br><span class="line"><span class="built_in">print</span>(acc)</span><br><span class="line"><span class="comment">#得到的输出结果为0.98，这个结果还不错吧。</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment">#画出正例和反例的散点图</span></span><br><span class="line">plt.scatter(positive_x1,positive_x2,c=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.scatter(negetive_x1,negetive_x2,c=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line"><span class="comment">#画出超平面（在本例中即是一条直线）</span></span><br><span class="line">line_x = np.arange(-<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">line_y = line_x * (-clf.coef_[<span class="number">0</span>][<span class="number">0</span>] / clf.coef_[<span class="number">0</span>][<span class="number">1</span>]) - clf.intercept_</span><br><span class="line">plt.plot(line_x,line_y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/68972bd785e94757948dddc2ea1cd78b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 感知器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习(十一)——集成学习</title>
      <link href="/2021/12/07/ML11_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"/>
      <url>/2021/12/07/ML11_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<blockquote><p>集成学习（ensemble learning）通过构建并结合多个学习器来完成学习任务。根据个体学习器的生成方式，目前集成学习的方法大致分为两类，即个体学习器之间存在强依赖关系，必须串行生成的序列化方法；另一类就是个体学习器之间不存在强依赖关系、可同时生成的并行化方法。前者的代表是Boosting，后者的代表室Bagging和随机森林。</p></blockquote><span id="more"></span><hr><h1 id="集成学习中的几个概念"><a href="#集成学习中的几个概念" class="headerlink" title="集成学习中的几个概念"></a>集成学习中的几个概念</h1><p>1、个体学习器：集成学习的一般结构都是先产生一组个体学习器（individual learner），在用某种策略将他们结合起来，个体学习器通常由一个现有的学习算法从训练数据中产生。</p><p>2、基学习器：如果集成中只包含同种类型的个体学习器，例如决策树集成中全都是决策树，这样的集成是‘同质’（homogeneous）的，同质集成中的个体学习器又称‘基学习器’，相应的学习算法又称基学习算法。</p><p>3、组件学习器：集成也可以是包含不同类型的个体学习器，例如决策树和神经网络，这样的集成是‘异质’（heterogenous）的，异质集成中的个体学习器称为组件学习器或者直接称为个体学习器。</p><hr><h1 id="Hard-Voting"><a href="#Hard-Voting" class="headerlink" title="Hard Voting"></a>Hard Voting</h1><p><img src="https://img-blog.csdnimg.cn/3aad696a83b64c9aaf0d4ebce3cb427a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">x, y =datasets.make_moons(n_samples=<span class="number">500</span>, noise=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/153e514ea74e41d78ec6d83cae673024.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>使用逻辑回归、决策树、svm三种算法集成，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">log_reg = LogisticRegression()</span><br><span class="line">log_reg.fit(x_train, y_train)</span><br><span class="line">log_reg.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.864</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line">svc = SVC()</span><br><span class="line">svc.fit(x_train, y_train)</span><br><span class="line">svc.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.888</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">dt_clf = DecisionTreeClassifier()</span><br><span class="line">dt_clf.fit(x_train, y_train)</span><br><span class="line">dt_clf.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.856</span></span><br><span class="line"></span><br><span class="line">y_predict1 = log_reg.predict(x_test)</span><br><span class="line">y_predict2 = svc.predict(x_test)</span><br><span class="line">y_predict3 = dt_clf.predict(x_test)</span><br><span class="line"><span class="comment"># 如果三个分类器中有两个预测为1，则最终结果就为1</span></span><br><span class="line">y_predict = np.array((y_predict1 + y_predict2 + y_predict3) &gt;= <span class="number">2</span>, dtype=<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">accuracy_score(y_test, y_predict)</span><br><span class="line"><span class="comment"># 0.896</span></span><br></pre></td></tr></table></figure><p>根据集成输出结果0.896比三种算法都高。</p><p>接下来使用sklearn中封装的votingclassifier类实现投票</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> VotingClassifier</span><br><span class="line"></span><br><span class="line">voting_clf = VotingClassifier(estimators=[</span><br><span class="line">    (<span class="string">&#x27;log_reg&#x27;</span>, LogisticRegression()),</span><br><span class="line">    (<span class="string">&#x27;svm_clf&#x27;</span>, SVC()),</span><br><span class="line">    (<span class="string">&#x27;dt_clf&#x27;</span>, DecisionTreeClassifier()),</span><br><span class="line">], voting=<span class="string">&#x27;hard&#x27;</span>)</span><br><span class="line"></span><br><span class="line">voting_clf.fit(x_train, y_train)</span><br><span class="line">voting_clf.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.896</span></span><br></pre></td></tr></table></figure><p>所谓的hard集成就是简单地根据预测为1的数量，其实就是少数服从多数。在很多情况下，少数服从多数并不是最合理的，然后更急合理的投票，应该是有权值的。由此引出soft 集成。</p><hr><h1 id="Soft-Voting"><a href="#Soft-Voting" class="headerlink" title="Soft Voting"></a>Soft Voting</h1><p><img src="https://img-blog.csdnimg.cn/0b48651fe6f64051ab1213c305e63492.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>集成学习中的soft voting要求集合的每一个模型都能估计概率。<br>（1）逻辑回归，本身就是基于概率模型的。<br><img src="https://img-blog.csdnimg.cn/44ce05684b474be6b9e38c6515f27c58.png"><br>（2）KNN，k个近邻中数量最多的那个类的数量除以k就是概率。也可以考虑权值。<br><img src="https://img-blog.csdnimg.cn/034ae80f21754ef988c34bd57bda7859.png"><br>（3）决策树。叶子节点中那个类数量最大就是那个类，概率就是数量最大的那个类除以所有叶子节点的类。<br><img src="https://img-blog.csdnimg.cn/bc21bd6a842f4f2f8ec8ec35fa3b2b93.png"><br>（4）SVC。SVC本身是没有考虑概率的，它是寻找一个margin的最大值。但是也是可以计算过，不过需要消耗大量的计算资源。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">x, y =datasets.make_moons(n_samples=<span class="number">500</span>, noise=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.scatter(x[y==0, 0], x[y==0, 1])</span></span><br><span class="line"><span class="comment"># plt.scatter(x[y==1, 0], x[y==1, 1])</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> VotingClassifier</span><br><span class="line"></span><br><span class="line">voting_clf2 = VotingClassifier(estimators=[</span><br><span class="line">    (<span class="string">&#x27;log_reg&#x27;</span>, LogisticRegression()),</span><br><span class="line">    (<span class="string">&#x27;svm_clf&#x27;</span>, SVC(probability=<span class="literal">True</span>)),</span><br><span class="line">    (<span class="string">&#x27;dt_clf&#x27;</span>, DecisionTreeClassifier(random_state=<span class="number">666</span>)),</span><br><span class="line">], voting=<span class="string">&#x27;soft&#x27;</span>)</span><br><span class="line"></span><br><span class="line">voting_clf2.fit(x_train, y_train)</span><br><span class="line">voting_clf2.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.912</span></span><br></pre></td></tr></table></figure><p>根据输出结果显然比Hrad Voting效果要好很多，但是仍然有个问题就是虽然有很多机器学习算法，但是从投票的角度看，仍然不够多。因此需要创建更多的子模型，集成更多的子模型的意见。而且子模型之间不能一致，必须要有差异性。</p><hr><h1 id="Bagging和Pasting"><a href="#Bagging和Pasting" class="headerlink" title="Bagging和Pasting"></a>Bagging和Pasting</h1><p>那么问题：如何创建差异性？每个子模型只能看数据样本的一部分。<br>例如：一共有500个样本数据，每个子模型只看100个样本数据。每个子模型不需太高的准确率。这是为什么？首先样本量减少模型的准确率降低是正常，通过集成能够提高。假如每个子模型只有51%的准确率，至少要比随机猜一个50%要高一点。提高的过程如下：</p><p><img src="https://img-blog.csdnimg.cn/15b6580af85744089edb5424715888f2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>这就是集成学习的威力。但是在实际的使用过程很难保证500个子模型的准确率都高于平均水平，甚至有些子模型可能预测错误的概率比预测正确的概率还要高，但是这样并不影响总体准确率的提升。<br>由此，如何创建差异性？每个子模型只能看数据样本的一部分，就涉及取样。<br><strong>取样：放回取样(Bagging)和不放回取样(Pasting)。在统计学，放回取样：bootstrap。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">x, y =datasets.make_moons(n_samples=<span class="number">500</span>, noise=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> BaggingClassifier</span><br><span class="line"></span><br><span class="line">bagging_clf = BaggingClassifier(DecisionTreeClassifier(),</span><br><span class="line">                               n_estimators=<span class="number">500</span>,</span><br><span class="line">                               max_samples=<span class="number">100</span>,</span><br><span class="line">                               bootstrap=<span class="literal">True</span>,)</span><br><span class="line">bagging_clf.fit(x_train, y_train)</span><br><span class="line">bagging_clf.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.904</span></span><br><span class="line">bagging_clf2 = BaggingClassifier(DecisionTreeClassifier(),</span><br><span class="line">                               n_estimators=<span class="number">5000</span>,</span><br><span class="line">                               max_samples=<span class="number">100</span>,</span><br><span class="line">                               bootstrap=<span class="literal">True</span>,)</span><br><span class="line"></span><br><span class="line">bagging_clf2.fit(x_train, y_train)</span><br><span class="line">bagging_clf2.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.912</span></span><br><span class="line"></span><br><span class="line">dt_clf = DecisionTreeClassifier()</span><br><span class="line">dt_clf.fit(x_train, y_train)</span><br><span class="line">dt_clf.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.824</span></span><br></pre></td></tr></table></figure><p>根据对比，当不适用集成学习只是用DecisionTree时，准确率只有0.824，使用500个子模型，每次有放回抽样100个样本，准确率为0.904，使用5000个样本，每次有放回抽样100个样本，准确率为0.912。</p><hr><h1 id="更多关于Bagging的讨论"><a href="#更多关于Bagging的讨论" class="headerlink" title="更多关于Bagging的讨论"></a>更多关于Bagging的讨论</h1><ol><li><strong>OOB(Out-of-Bag)</strong><br>放回取样会有一定的概率导致一部分样本很有可能没有被取到，严格地进行数据计算平均大约有37%的样本是取不到的，这部分样本就成为Out-of-Bag。因此为了解决这个问题，就不需要将数据集划分为训练集和测试集了，就使用这部分没有被取到的样本做测试或验证。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">x, y =datasets.make_moons(n_samples=<span class="number">500</span>, noise=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> BaggingClassifier</span><br><span class="line"></span><br><span class="line">bagging_clf = BaggingClassifier(DecisionTreeClassifier(),</span><br><span class="line">                               n_estimators=<span class="number">500</span>,</span><br><span class="line">                               max_samples=<span class="number">100</span>,</span><br><span class="line">                               bootstrap=<span class="literal">True</span>,</span><br><span class="line">                               oob_score=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 此时使用的数据集就是全部数据。oob_score=True的意思就使用剩下未取到的数据作为测试集。</span></span><br><span class="line">bagging_clf.fit(x, y)</span><br><span class="line">bagging_clf.oob_score_</span><br><span class="line"><span class="comment"># 0.918</span></span><br></pre></td></tr></table></figure><ol start="2"><li><strong>Bagging的思路极易并行化处理</strong></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line">bagging_clf = BaggingClassifier(DecisionTreeClassifier(),</span><br><span class="line">                               n_estimators=<span class="number">5000</span>,</span><br><span class="line">                               max_samples=<span class="number">100</span>,</span><br><span class="line">                               bootstrap=<span class="literal">True</span>,</span><br><span class="line">                               oob_score=<span class="literal">True</span>)</span><br><span class="line">bagging_clf.fit(x, y)</span><br><span class="line"><span class="comment"># Wall time: 4.13 s</span></span><br></pre></td></tr></table></figure><p>在sklearn中对于并行处理传入的参数：n_jobs，-1表示使用全部的核。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line">bagging_clf = BaggingClassifier(DecisionTreeClassifier(),</span><br><span class="line">                               n_estimators=<span class="number">5000</span>,</span><br><span class="line">                               max_samples=<span class="number">100</span>,</span><br><span class="line">                               bootstrap=<span class="literal">True</span>,</span><br><span class="line">                               oob_score=<span class="literal">True</span>,</span><br><span class="line">                               n_jobs=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">bagging_clf.fit(x, y)</span><br><span class="line"><span class="comment"># Wall time: 2.38 s</span></span><br></pre></td></tr></table></figure><ol start="3"><li><strong>使得子模型具有差异化。之前对于子模型的差异化是使用有放回的随机取样使得训练子模型的数据集有差异，</strong></li></ol><p>当然还有一种办法就是针对特征进行随机采样，Random Subspaces。</p><p>此外，还可以既针对样本，又针对特征进行随机采样。Random Patches。</p><ul><li>在特征空间随机采样bootstrap_features</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">random_subspaces_clf = BaggingClassifier(DecisionTreeClassifier(),</span><br><span class="line">                               n_estimators=<span class="number">5000</span>,</span><br><span class="line">                               max_samples=<span class="number">500</span>,</span><br><span class="line">                               bootstrap=<span class="literal">True</span>,</span><br><span class="line">                               oob_score=<span class="literal">True</span>,</span><br><span class="line">                               n_jobs=-<span class="number">1</span>,</span><br><span class="line">                               max_features=<span class="number">1</span>,</span><br><span class="line">                               bootstrap_features=<span class="literal">True</span>,)</span><br><span class="line"><span class="comment"># 在这里max_samples=500,表明所有的数据都用，并不对样本进行采样。</span></span><br><span class="line"><span class="comment"># max_features表示使用的特征数，因为生成的数据只有2维，因此在此就取1</span></span><br><span class="line"><span class="comment"># bootstrap_features表示使用随机特征抽取。</span></span><br><span class="line">random_subspaces_clf.fit(x, y)</span><br><span class="line">random_subspaces_clf.oob_score_</span><br><span class="line"><span class="comment"># 0.83</span></span><br></pre></td></tr></table></figure><ul><li>既针对样本，又针对特征进行随机采样</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">random_patches_clf = BaggingClassifier(DecisionTreeClassifier(),</span><br><span class="line">                               n_estimators=<span class="number">5000</span>,</span><br><span class="line">                               max_samples=<span class="number">100</span>,</span><br><span class="line">                               bootstrap=<span class="literal">True</span>,</span><br><span class="line">                               oob_score=<span class="literal">True</span>,</span><br><span class="line">                               n_jobs=-<span class="number">1</span>,</span><br><span class="line">                               max_features=<span class="number">1</span>,</span><br><span class="line">                               bootstrap_features=<span class="literal">True</span>,)</span><br><span class="line"><span class="comment"># max_samples=100, bootstrap=True,表示针对样本进行随机抽样</span></span><br><span class="line"><span class="comment"># max_features=1,bootstrap_features=True表示针对样本特征进行随机抽样</span></span><br><span class="line">random_patches_clf.fit(x, y)</span><br><span class="line">random_patches_clf.oob_score_</span><br><span class="line"><span class="comment"># 0.858</span></span><br></pre></td></tr></table></figure><hr><h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><p>随机森林（Random Forest，简称RF）是Bagging的一个扩展变体，RF在以决策树为基学习器构建Bagging集成的基础是，进一步在决策树的训练过程中引入随机属性选择。</p><p>决策树在节点划分上，在随机的特征子集上寻找最优的划分特征。具体来说在传统决策树在选择划分属性时是当前结点的属性结合（假设有d个属性）中随机选择一个最优属性；而在RF中，对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含k个属性的子集，然后再从这个子集中选择一个属性用于划分。一般情况下，推荐 <strong>log<sub>2</sub>d</strong>。随机森林中基学习器的多样性不仅来自样本扰动，还来自属性扰动。这就使得最终集成的泛华性能可通过个体学习器之间差异度的增加而进一步提升。</p><p>在sklearn中已经封装了随机森林这个类：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">x, y =datasets.make_moons(n_samples=<span class="number">500</span>, noise=<span class="number">0.3</span>, random_state=<span class="number">666</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">rf_clf = RandomForestClassifier(n_estimators=<span class="number">500</span>, </span><br><span class="line">                                random_state=<span class="number">666</span>, </span><br><span class="line">                                oob_score=<span class="literal">True</span>, </span><br><span class="line">                                n_jobs=-<span class="number">1</span>,)</span><br><span class="line">rf_clf.fit(x, y)</span><br><span class="line">rf_clf.oob_score_</span><br><span class="line"><span class="comment"># 0.892</span></span><br><span class="line"></span><br><span class="line">rf_clf2 = RandomForestClassifier(n_estimators=<span class="number">500</span>, </span><br><span class="line">                                 random_state=<span class="number">666</span>, </span><br><span class="line">                                 oob_score=<span class="literal">True</span>, </span><br><span class="line">                                 n_jobs=-<span class="number">1</span>,</span><br><span class="line">                                 max_leaf_nodes=<span class="number">16</span>)</span><br><span class="line">rf_clf2.fit(x, y)</span><br><span class="line">rf_clf2.oob_score_</span><br><span class="line"><span class="comment"># 0.906</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h1 id="Extra-Trees"><a href="#Extra-Trees" class="headerlink" title="Extra-Trees"></a>Extra-Trees</h1><p>极端随机树（Extremely randomized trees），决策树在节点划分上，使用随用随机的特征和随机的阈值。提供额外的随机性，抑制了过拟合，但是也一定程度地增大了bias。从偏差-方差分解的角度看，更加关注于降低方差。由于这种随机性使得能够更加快速地训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> ExtraTreesClassifier</span><br><span class="line"></span><br><span class="line">et_clf = ExtraTreesClassifier(n_estimators=<span class="number">500</span>, bootstrap=<span class="literal">True</span>, oob_score=<span class="literal">True</span>,</span><br><span class="line">                             random_state=<span class="number">666</span>)</span><br><span class="line">et_clf.fit(x, y)</span><br><span class="line">et_clf.oob_score_</span><br><span class="line"><span class="comment"># 0.892</span></span><br></pre></td></tr></table></figure><p>ET与RF的区别：</p><p>1、RF应用了Bagging进行随机抽样，而ET的每棵决策树应用的是相同的样本。</p><p>2、RF在一个随机子集内基于信息熵和基尼指数寻找最优属性，而ET完全随机寻找一个特征值进行划分。</p><p>其实，集成学习除了可以解决分类问题，对于回归问题也是可以的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> BaggingRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> ExtraTreesRegressor</span><br></pre></td></tr></table></figure><hr><h1 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h1><p>集成多个模型，每个模型都在尝试增强整体效果。具体来说：就是先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前学习器做的训练样本在后续受到更多的关注，然后基于调整后的样本分布来训练下一个学习器，如此重读进行，直至学习器数目达到预先指定的值。<br><img src="https://img-blog.csdnimg.cn/054a70d56db8436399a22de9be8947ac.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>根据上面这张图来看，经过第一个学习器的学习后给预测错误样本呈现为更深的蓝色的点，训练正确的为浅色的蓝色的点，赋予错误的训练样本以更高的权重，对于经过调整的训练样本再次训练一个学习器，同理一直迭代下去。</p><p>Boosting族算法最著名的代表室AdaBoost[Freund and Schapire, 1997], AdaBoos算法有多种推导方式，比较容易的理解是基于加性模型，即学习器的线性组合。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">x, y =datasets.make_moons(n_samples=<span class="number">500</span>, noise=<span class="number">0.3</span>, random_state=<span class="number">666</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 这里由于不在采用随机抽样，因此需要分割数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="comment"># 这里根据决策树的调参方式进行调参。</span></span><br><span class="line">ada_clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=<span class="number">2</span>),</span><br><span class="line">                            n_estimators=<span class="number">500</span>,)</span><br><span class="line">ada_clf.fit(x_train, y_train)</span><br><span class="line">ada_clf.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.848</span></span><br></pre></td></tr></table></figure><p>Boosting算法要求基学习器能够对特定的数据分布进行学习，这可通过“重赋权法”实施，即在训练的过程的每一轮中，根据样本的分布为每个训练样本赋予一个权重，对无法接受带权样本的基学习算法可通过重采样对基学习器进行训练。</p><p>从偏差-方差分解的角度看，Boosting主要关注降低偏差。</p><hr><h1 id="Gradient-Boosting-Decision-Tree"><a href="#Gradient-Boosting-Decision-Tree" class="headerlink" title="Gradient Boosting Decision Tree"></a>Gradient Boosting Decision Tree</h1><p>（1）GBDT为什么这么优秀？一是效果确实挺不错。二是即可以用于分类也可以用于回归。三是可以筛选特征。</p><p>（2）什么是GBDT？GBDT 是通过采用加法模型（即基函数的线性组合），以及不断减小训练过程产生的残差来达到将数据分类或者回归的算法。</p><p>（3）GBDT的训练过程？</p><p>训练一个模型m1,产生错误e1，针对e1训练第二个模型m2，产生错误e2，针对e2训练第三个模型m3，产生错误e3…，最终的预测结果是m1+m2+m3+…。</p><p>（4）在sklearn中梯度提升回归树有四种可选的损失函数，分别为’ls：平方损失’，’lad:绝对损失’，’huber：huber损失’，’quantile：分位数损失’；</p><p>而在sklearn中梯度提升分类树有两种可选的损失函数，一种是‘exponential：指数损失’，一种是‘deviance：对数损失’。</p><p>接下来，使用sklearn简单实现梯度提升分类树。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"></span><br><span class="line">gb_clf = GradientBoostingClassifier(max_depth=<span class="number">2</span>, n_estimators=<span class="number">30</span>)</span><br><span class="line">gb_clf.fit(x_train, y_train)</span><br><span class="line">gb_clf.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.904</span></span><br></pre></td></tr></table></figure><hr><h1 id="结合策略"><a href="#结合策略" class="headerlink" title="结合策略"></a>结合策略</h1><p>学习器结合可能会从三个方面带来好处：1、单个学习器可能因误选而导致泛化性能不佳；2、学习算法往往会陷入局部最小，而多次运行之后进行结合，可降低陷入局部最小的风险，3、结合多个学习器可以扩大假设的样本空间，提高模型的泛化能力。</p><ol><li><strong>平均法</strong></li></ol><ul><li>简单平均法</li><li>加权平均法</li></ul><ol start="2"><li><strong>投票法</strong></li></ol><ul><li>绝对多数投票法，即若某标记得票超过半数，则预测为该标记，否则拒绝。</li><li>相对多数投票法，即预测为得票最多的标记，若同时有多个标记获得最高票，则随机从中选一个。</li><li>加权投票法</li></ul><ol start="3"><li><strong>学习法（Stacking：Blending）</strong><br>Stacking是学习法的典型代表。把个体学习器称为初级学习器，用于结合的学习器称为次级学习器。其实逻辑回归之所以能解决分类问题，我的个人理解就是初级学习器为线性回归，次级学习器为是一个分类器。但略微存在不同，原因如下：<br><img src="https://img-blog.csdnimg.cn/a3a4dd9e939242cc95bde89797f72761.png"><br><img src="https://img-blog.csdnimg.cn/fc7ee5afbd544363b4c62e104bd54b73.png"></li></ol><p>Stacking的策略是把训练样本集分为两部分，一部分用来训练初级学习器，通过初级分类器预测的结果和另外一部分样本一起用来训练次级学习器。由此得到最终的的预测结果。</p><p>如果将其更加复杂化一些，将训练样本分为三部分，第一部分训练layer1的三个学习器，第二部分训练layer2的学习器，第三部分跟layer2的学习器的预测结果一起训练得到layer3的学习器，这样得到最终的学习结果。此时这样的网络跟人工神经网络就有点类似了。</p><p><img src="https://img-blog.csdnimg.cn/91840d3c45d849a3a7516e1ede66fb8e.png" alt="在这里插入图片描述"><br>每个模型本身就有很多的超参数，需要有几层，又加上每一层使用的学习器的数量又是一个超参数，因此stacking就会复杂很多，也正是因为这种复杂性导致其容易产生过拟合。因此很不幸的是sklearn中并没有封装这样的函数，因为其灵活性和多样性导致其变化及其复杂，因此，往往比这种更加复杂的网络的时候就会使用神经网络，涉及深度学习的内容。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 集成学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习(十)——支持向量机</title>
      <link href="/2021/12/06/ML10_SVM/"/>
      <url>/2021/12/06/ML10_SVM/</url>
      
        <content type="html"><![CDATA[<blockquote><p>支持向量机（Support Vector Machine, SVM）是一类按监督学习（supervised learning）方式对数据进行广义线性分类，其决策边界是对学习样本求解的最大边距超平面（maximum-margin hyperplane）。SVM可以通过核函数进行非线性分类，是常见的核学习（kernel learning）方法之一。</p></blockquote><span id="more"></span><h1 id="什么是支持向量机"><a href="#什么是支持向量机" class="headerlink" title="什么是支持向量机"></a>什么是支持向量机</h1><p>支持向量机（support vector machines）是寻找一个超平面来对样本进行分割，分割的原则是间隔最大化，最终转化为一个凸二次规划问题来求解。它既能解决线性可分又能解决线性不可能，既能解决分类问题又能完成回归问题。</p><p>当训练样本线性可分时使用硬间隔最大化（Hard Margin SVM）或者近似线性可分时使用软件最大化（Soft Margin SVM）。当训练样本线性不可分时使用核函数和软间隔最大化。<br><img src="https://img-blog.csdnimg.cn/7f56a4ee6b2847c5931644f8fb2410fa.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_12,color_FFFFFF,t_70,g_se,x_16"><br>在实际问题中往往都存在着决策边界不唯一的情况，这就是不适定问题。给定训练样本集 <strong>D={(x<sub>1</sub>,y<sub>1</sub>),(x<sub>2</sub>,y<sub>2</sub>),…,(x<sub>m</sub>,y<sub>m</sub>)},y<sub>i</sub>∈{-1,1}</strong> 分类算法的基本思想就是基于训练集在样本空间中找到一个划分超平面，但是能将训练样本分开的划分超平面可能有很多，所以，应该努力地去找哪一个？<br><img src="https://img-blog.csdnimg.cn/49c26d0d7b3e4f319ec8b31e82944c86.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_12,color_FFFFFF,t_70,g_se,x_16"><br>而svm找到的这条直线希望距离最近的红色的点和蓝色的点，距离决策边界尽可能的远，这样就能保证模型的泛化能力。svm尝试寻找一个最优的决策边界，距离两个类别最近的样本最远，图中3个点到决策边界距离相同。这三个点就叫做**支持向量(support vector)**。而平行于决策边界的两条直线之间的距离就是 <strong>margin</strong>，svm就是要最大化 <strong>margin</strong> ，这样就把这个问题转化称为最优化问题。</p><hr><h1 id="支持向量机背后的最优化问题"><a href="#支持向量机背后的最优化问题" class="headerlink" title="支持向量机背后的最优化问题"></a>支持向量机背后的最优化问题</h1><p><img src="https://img-blog.csdnimg.cn/a7092c3b67fd49fdb0864bb8476ae6d9.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/33dd3644299d4141bec851aee8cb05c8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16"><br>中间那根直线就是决策边界 <strong>w<sup>T</sup>x+b=0</strong> ,而上下两根直线意味着距离一定大于 <strong>d</strong>，从而<br><img src="https://img-blog.csdnimg.cn/97fc8548efd344a4ad82652010e7c47a.png"><br>此时，假设两类样本分别为1和-1。然后将上述式子的左右两侧同时除以 <strong>d</strong> ，得到<br><img src="https://img-blog.csdnimg.cn/4bb75754962f40818fe4193412aae1e8.png"><br>其中 <strong>||w||</strong> 和 <strong>d</strong> 都是一个数，此时消去分母，得到<br><img src="https://img-blog.csdnimg.cn/89f6d06b78df4bdc95c84995cfcf6402.png"><br><img src="https://img-blog.csdnimg.cn/867b52b73f6244c79b934262584fcc9d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="Soft-Margin和SVM正则化"><a href="#Soft-Margin和SVM正则化" class="headerlink" title="Soft Margin和SVM正则化"></a>Soft Margin和SVM正则化</h1><p>如果在实际应用过程中有一个蓝色的点出现在红色的点附近，即两类相对较为接近，但整体跟蓝色的点差异明显，可以看做是一个特殊点或者错误的奇点，此时就会误导，导致最终的hard margin分类边界是直线1，此时模型的泛化能力就值得怀疑。正常来说应该像直线2一样忽略那个极度特殊的蓝点，保证大多数的数据到直线的距离最远，可能这才是最好的分类边界，也就是泛化能力更高。这也能间接地说明如果模型的准确率过高可能会导致模型的过拟合。<br><img src="https://img-blog.csdnimg.cn/775f6387e7f947a487ad8f237da6644f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_11,color_FFFFFF,t_70,g_se,x_16"><br>还有一种更一般的例子，那就是如果有一个蓝色的点混进了红色的点当中，这就导致数据集根本就是线性不可分的情况，根本找不出一条直线能够将这两类分开，在这种情况下Hard margin就不再是泛化能力强不强的问题，而是根本找不出一条直线将其分开。<br><img src="https://img-blog.csdnimg.cn/597cc2a38f92430c8720b1e53cc4af8c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_11,color_FFFFFF,t_70,g_se,x_16"><br>因此不管才以上两种情况的哪个角度出发，都应该考虑给予svm模型部分容错能力。由此引出<strong>Soft Margin SVM</strong>。<br><img src="https://img-blog.csdnimg.cn/1b2100ad36234b71872c68567cba0165.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/19c0ccf5b4ac48338d990ec8796f61de.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="sklearn中的SVM"><a href="#sklearn中的SVM" class="headerlink" title="sklearn中的SVM"></a>sklearn中的SVM</h1><p>在实际使用SVM的时候和KNN一样需要对数据进行标准化处理，因为这两者都涉及距离。因为当数据尺度相差过大的话，比如下图横轴0-1，纵轴0-10000。所以先进行标准化是必要的。<br><img src="https://img-blog.csdnimg.cn/446c269305c54291b29377e3715b85c8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_11,color_FFFFFF,t_70,g_se,x_16"><br><strong>第一步</strong>，准备一个简单二分类数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line">x = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"><span class="comment"># 只做一个简单的二分类</span></span><br><span class="line">x = x[y&lt;<span class="number">2</span>, :<span class="number">2</span>]</span><br><span class="line">y = y[y&lt;<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/5743d3a452c149f3a6c39166ebeca9d1.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"><br><strong>第二步</strong>，实现svm，先使用一个比较大的C。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标准化数据</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</span><br><span class="line"></span><br><span class="line">standardscaler = StandardScaler()</span><br><span class="line">standardscaler.fit(x)</span><br><span class="line">x_standard = standardscaler.transform(x)</span><br><span class="line"></span><br><span class="line">svc = LinearSVC(C=<span class="number">1e9</span>)</span><br><span class="line">svc.fit(x_standard, y)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_decision_boundary</span>(<span class="params">model, axis</span>):</span></span><br><span class="line">    x0, x1 = np.meshgrid(np.linspace(axis[<span class="number">0</span>], axis[<span class="number">1</span>], <span class="built_in">int</span>((axis[<span class="number">1</span>] - axis[<span class="number">0</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),</span><br><span class="line">                         np.linspace(axis[<span class="number">2</span>], axis[<span class="number">3</span>], <span class="built_in">int</span>((axis[<span class="number">3</span>] - axis[<span class="number">2</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),)</span><br><span class="line">    x_new = np.c_[x0.ravel(), x1.ravel()]</span><br><span class="line">    y_predict = model.predict(x_new)</span><br><span class="line">    zz = y_predict.reshape(x0.shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line">    custom_cmap = ListedColormap([<span class="string">&#x27;#EF9A9A&#x27;</span>, <span class="string">&#x27;#FFF59D&#x27;</span>, <span class="string">&#x27;#90CAF9&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    plt.contourf(x0, x1, zz, linewidth=<span class="number">5</span>, cmap=custom_cmap)</span><br><span class="line"></span><br><span class="line">plot_decision_boundary(svc, axis=[-<span class="number">3</span>, <span class="number">3</span>, -<span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">plt.scatter(x_standard[y==<span class="number">0</span>, <span class="number">0</span>], x_standard[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.scatter(x_standard[y==<span class="number">1</span>, <span class="number">0</span>], x_standard[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/888155ad92e24310ba938f74b73a699a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><strong>第三步</strong>：使用一个比较小的C，对比C取不同值的效果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">svc2 = LinearSVC(C=<span class="number">0.01</span>)</span><br><span class="line">svc2.fit(x_standard, y)</span><br><span class="line"></span><br><span class="line">plot_decision_boundary(svc2, axis=[-<span class="number">3</span>, <span class="number">3</span>, -<span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">plt.scatter(x_standard[y==<span class="number">0</span>, <span class="number">0</span>], x_standard[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.scatter(x_standard[y==<span class="number">1</span>, <span class="number">0</span>], x_standard[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/5d4aa9626e6849fc90b0f402cbe8cd6b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>对比两幅图可以发现，当C较小时，误将一个红色的点分到蓝色当中，这也再次验证了当C越小，就意味着有更大的容错空间。<br><strong>第四步</strong>：查看线性SVM的截距和系数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">svc.coef_</span><br><span class="line"><span class="comment"># array([[ 4.03236227, -2.50699771]])</span></span><br><span class="line">svc.intercept_</span><br><span class="line"><span class="comment"># array([0.92736176])</span></span><br></pre></td></tr></table></figure><p><strong>第五步</strong>：画出除了决策边界以外的两条跟支持向量相关的直线</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_svc_decision_boundary</span>(<span class="params">model, axis</span>):</span></span><br><span class="line">    x0, x1 = np.meshgrid(np.linspace(axis[<span class="number">0</span>], axis[<span class="number">1</span>], <span class="built_in">int</span>((axis[<span class="number">1</span>] - axis[<span class="number">0</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),</span><br><span class="line">                         np.linspace(axis[<span class="number">2</span>], axis[<span class="number">3</span>], <span class="built_in">int</span>((axis[<span class="number">3</span>] - axis[<span class="number">2</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),)</span><br><span class="line">    x_new = np.c_[x0.ravel(), x1.ravel()]</span><br><span class="line">    y_predict = model.predict(x_new)</span><br><span class="line">    zz = y_predict.reshape(x0.shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line">    custom_cmap = ListedColormap([<span class="string">&#x27;#EF9A9A&#x27;</span>, <span class="string">&#x27;#FFF59D&#x27;</span>, <span class="string">&#x27;#90CAF9&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    plt.contourf(x0, x1, zz, linewidth=<span class="number">5</span>, cmap=custom_cmap)</span><br><span class="line">    </span><br><span class="line">    w = model.coef_[<span class="number">0</span>]</span><br><span class="line">    b = model.intercept_[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># w0*x0 + w1*x1 + b = 0</span></span><br><span class="line">    <span class="comment"># x1 = -w0/w1 * x0 - b/w1</span></span><br><span class="line">    plot_x = np.linspace(axis[<span class="number">0</span>], axis[<span class="number">1</span>], <span class="number">200</span>)</span><br><span class="line">    up_y = -w[<span class="number">0</span>]/w[<span class="number">1</span>] * plot_x - b/w[<span class="number">1</span>] + <span class="number">1</span>/w[<span class="number">1</span>]</span><br><span class="line">    down_y = -w[<span class="number">0</span>]/w[<span class="number">1</span>] * plot_x - b/w[<span class="number">1</span>] - <span class="number">1</span>/w[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    up_index = (up_y &gt;= axis[<span class="number">2</span>]) &amp; (up_y &lt;= axis[<span class="number">3</span>])</span><br><span class="line">    down_index = (down_y &gt;= axis[<span class="number">2</span>]) &amp; (down_y &lt;= axis[<span class="number">3</span>])</span><br><span class="line">    </span><br><span class="line">    plt.plot(plot_x[up_index], up_y[up_index], color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">    plt.plot(plot_x[down_index], down_y[down_index], color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plot_svc_decision_boundary(svc, axis=[-<span class="number">3</span>, <span class="number">3</span>, -<span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">plt.scatter(x_standard[y==<span class="number">0</span>, <span class="number">0</span>], x_standard[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.scatter(x_standard[y==<span class="number">1</span>, <span class="number">0</span>], x_standard[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/e2b43a934e1241ddb32036c438f8af0b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plot_svc_decision_boundary(svc2, axis=[-<span class="number">3</span>, <span class="number">3</span>, -<span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">plt.scatter(x_standard[y==<span class="number">0</span>, <span class="number">0</span>], x_standard[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.scatter(x_standard[y==<span class="number">1</span>, <span class="number">0</span>], x_standard[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/9c2ece29e48e48af87b0db4771597192.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">svc3 = LinearSVC(C=<span class="number">0.1</span>)</span><br><span class="line">svc3.fit(x_standard, y)</span><br><span class="line"><span class="comment"># LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,</span></span><br><span class="line"><span class="comment">#      intercept_scaling=1, loss=&#x27;squared_hinge&#x27;, max_iter=1000,</span></span><br><span class="line"><span class="comment">#      multi_class=&#x27;ovr&#x27;, penalty=&#x27;l2&#x27;, random_state=None, tol=0.0001,</span></span><br><span class="line"><span class="comment">#      verbose=0)</span></span><br><span class="line"><span class="comment"># 从上述结果可以看出sklearn中对于svm封装的linearSVC默认对于多分类使用ovr，L2正则。</span></span><br><span class="line">plot_svc_decision_boundary(svc3, axis=[-<span class="number">3</span>, <span class="number">3</span>, -<span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">plt.scatter(x_standard[y==<span class="number">0</span>, <span class="number">0</span>], x_standard[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.scatter(x_standard[y==<span class="number">1</span>, <span class="number">0</span>], x_standard[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/d54e9f64cc554a1baa373f84b2f50baa.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="SVM中使用多项式特征"><a href="#SVM中使用多项式特征" class="headerlink" title="SVM中使用多项式特征"></a>SVM中使用多项式特征</h1><p>前面一直都在讲的是线性的svm，对于svm来说也可以解决非线性问题，类比线性回归到非线性回归的思想，首先使用多项式特征。</p><p>首先生成数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">x, y = datasets.make_moons()</span><br><span class="line">x.shape</span><br><span class="line"><span class="comment"># (100, 2)</span></span><br><span class="line">y.shape</span><br><span class="line"><span class="comment"># (100,)</span></span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/7e86fb08f31746918dadb8cc1df31229.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>接下来给数据添加一些随机噪声：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x, y = datasets.make_moons(noise=<span class="number">0.15</span>, random_state=<span class="number">666</span>)</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/d119d117c54e4cefbb2a19385d44294e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures, StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PolynomiaSVC</span>(<span class="params">degree, C=<span class="number">1.0</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> Pipeline([</span><br><span class="line">        (<span class="string">&#x27;poly&#x27;</span>, PolynomialFeatures(degree=degree)),</span><br><span class="line">        (<span class="string">&#x27;std_scale&#x27;</span>, StandardScaler()),</span><br><span class="line">        (<span class="string">&#x27;linear_svc&#x27;</span>, LinearSVC(C=C))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">poly_svc = PolynomiaSVC(degree=<span class="number">3</span>)</span><br><span class="line">poly_svc.fit(x, y)</span><br><span class="line"><span class="comment"># Pipeline(memory=None,</span></span><br><span class="line"><span class="comment">#      steps=[(&#x27;poly&#x27;, PolynomialFeatures(degree=3, include_bias=True, interaction_only=False)),</span></span><br><span class="line"><span class="comment"># (&#x27;std_scale&#x27;, StandardScaler(copy=True, with_mean=True, with_std=True)), </span></span><br><span class="line"><span class="comment"># (&#x27;linear_svc&#x27;, LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,</span></span><br><span class="line"><span class="comment">#      intercept_scaling=1, loss=&#x27;squared_hinge&#x27;, max_iter=1000,</span></span><br><span class="line"><span class="comment">#      multi_class=&#x27;ovr&#x27;, penalty=&#x27;l2&#x27;, random_state=None, tol=0.0001,</span></span><br><span class="line"><span class="comment">#     verbose=0))])</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_decision_boundary</span>(<span class="params">model, axis</span>):</span></span><br><span class="line">    x0, x1 = np.meshgrid(np.linspace(axis[<span class="number">0</span>], axis[<span class="number">1</span>], <span class="built_in">int</span>((axis[<span class="number">1</span>] - axis[<span class="number">0</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),</span><br><span class="line">                         np.linspace(axis[<span class="number">2</span>], axis[<span class="number">3</span>], <span class="built_in">int</span>((axis[<span class="number">3</span>] - axis[<span class="number">2</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),)</span><br><span class="line">    x_new = np.c_[x0.ravel(), x1.ravel()]</span><br><span class="line">    y_predict = model.predict(x_new)</span><br><span class="line">    zz = y_predict.reshape(x0.shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line">    custom_cmap = ListedColormap([<span class="string">&#x27;#EF9A9A&#x27;</span>, <span class="string">&#x27;#FFF59D&#x27;</span>, <span class="string">&#x27;#90CAF9&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    plt.contourf(x0, x1, zz, linewidth=<span class="number">5</span>, cmap=custom_cmap)</span><br><span class="line"></span><br><span class="line">plot_decision_boundary(poly_svc, axis=[-<span class="number">1.5</span>, <span class="number">2.5</span>, -<span class="number">1.0</span>, <span class="number">1.5</span>])</span><br><span class="line">plt.scatter(x1[y1==<span class="number">0</span>, <span class="number">0</span>], x1[y1==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x1[y1==<span class="number">1</span>, <span class="number">0</span>], x1[y1==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/959f1b2abb7340ee95d6a24afaf8eb94.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>除了使用这种增加多项式特征之后再给入线性svc中之外，还有一种方法可以实现类似的功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这种方法训练的过程并不完全是先将数据进行标准化，再使用linearSVC这么一个过程</span></span><br><span class="line"><span class="comment"># SVC中默认的C=0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PolynomiaKernelSVC</span>(<span class="params">degree, C=<span class="number">1.0</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> Pipeline([</span><br><span class="line">        (<span class="string">&#x27;std_scale&#x27;</span>, StandardScaler()),</span><br><span class="line">        (<span class="string">&#x27;kernel_svc&#x27;</span>, SVC(kernel=<span class="string">&#x27;poly&#x27;</span>, degree=degree, C=C))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">poly_kernel_svc = PolynomiaKernelSVC(degree=<span class="number">3</span>)</span><br><span class="line">poly_kernel_svc.fit(x, y)</span><br><span class="line"><span class="comment"># Pipeline(memory=None,</span></span><br><span class="line"><span class="comment">#     steps=[(&#x27;std_scale&#x27;, StandardScaler(copy=True, with_mean=True, with_std=True)),</span></span><br><span class="line"><span class="comment">#  (&#x27;kernel_svc&#x27;, SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,</span></span><br><span class="line"><span class="comment">#   decision_function_shape=&#x27;ovr&#x27;, degree=3, gamma=&#x27;auto_deprecated&#x27;,</span></span><br><span class="line"><span class="comment">#   kernel=&#x27;poly&#x27;, max_iter=-1, probability=False, random_state=None,</span></span><br><span class="line"><span class="comment">#   shrinking=True, tol=0.001, verbose=False))])</span></span><br><span class="line"></span><br><span class="line">plot_decision_boundary(poly_svc, axis=[-<span class="number">1.5</span>, <span class="number">2.5</span>, -<span class="number">1.0</span>, <span class="number">1.5</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/e8caf49f18e64a8b917415e8d52fbb4f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>这种方法就是svm中kernel函数。接下来具体说明核函数。</p><hr><h1 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h1><p>在现实任务中，原始的样本空间也许并不存在一个能正确划分两类的超平面，对于这样一个问题，可将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分。因此核函数的作用就是使得原本线性不可分的数据变得线性可分。下面是一个使用多项式核映射的过程。<br><img src="https://img-blog.csdnimg.cn/de7c33039269403d90d37be8e23a1876.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><strong>第一步：向高维空间映射</strong><br><img src="https://img-blog.csdnimg.cn/d996bdfabffe420fae3225dec260c039.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><strong>第二步：对偶问题的证明过程</strong><br><img src="https://img-blog.csdnimg.cn/8003e664f60346a3af3b8fbf70f78f62.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><strong>第三步：经过对偶问题的求解后即可得到，</strong><br><img src="https://img-blog.csdnimg.cn/52d4179c3e7a41dda5cf90b23d470600.png"><br>常用核函数：<br><img src="https://img-blog.csdnimg.cn/d5f0079556fe42f4b2227b4bd01b8f4b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>接下里重点介绍高斯核函数。</p><hr><h1 id="高斯核函数"><a href="#高斯核函数" class="headerlink" title="高斯核函数"></a>高斯核函数</h1><p>高斯核函数的目的就是将每一个样本点映射到一个无穷维的特征空间。实质上就是把一个m*n维的数据映射成了m*m的数据。由于理论上数据量可以是无穷维，所以说是映射到一个无穷维空间中。<br><img src="https://img-blog.csdnimg.cn/fe4a1e04b8a54f9dab2326bf7ae38101.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>接下来通过高斯核函数映射来更加直观地理解整个映射的过程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x = np.arange(-<span class="number">4</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># array([-4, -3, -2, -1,  0,  1,  2,  3,  4])</span></span><br><span class="line">y = np.array((x &gt;= -<span class="number">2</span>) &amp; (x &lt;= <span class="number">2</span>), dtype=<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line"><span class="comment"># array([0, 0, 1, 1, 1, 1, 1, 0, 0])</span></span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>], [<span class="number">0</span>] * <span class="built_in">len</span>(x[y==<span class="number">0</span>]))</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>], [<span class="number">0</span>] * <span class="built_in">len</span>(x[y==<span class="number">1</span>]))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/2397adf28d304b5094442f72bc307d9d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gaussian</span>(<span class="params">x, l</span>):</span></span><br><span class="line">    gamma = <span class="number">1.0</span></span><br><span class="line">    <span class="keyword">return</span> np.exp(-gamma *(x-l)**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">l1, l2 = -<span class="number">1</span>, <span class="number">1</span></span><br><span class="line"></span><br><span class="line">x_new = np.empty((<span class="built_in">len</span>(x), <span class="number">2</span>))</span><br><span class="line"><span class="keyword">for</span> i,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(x):</span><br><span class="line">    x_new[i, <span class="number">0</span>] = gaussian(data, l1)</span><br><span class="line">    x_new[i, <span class="number">1</span>] = gaussian(data, l2)</span><br><span class="line"></span><br><span class="line">plt.scatter(x_new[y==<span class="number">0</span>, <span class="number">0</span>], x_new[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x_new[y==<span class="number">1</span>, <span class="number">0</span>], x_new[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/24edc5169bab4a929127fd7c2a2d791f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>其实，真正的高斯核函数实现的过程中并不是固定的landmark，而是对于每一个数据点都是landmark。<br><img src="https://img-blog.csdnimg.cn/b49f97194cd14eca9437620526eba629.png"><br><img src="https://img-blog.csdnimg.cn/97d04505d445461e81cb351f5fb6586f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>接下来，使用sklearn中封装的高斯核函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">x, y = datasets.make_moons(noise=<span class="number">0.15</span>, random_state=<span class="number">666</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">RBFKernelSVC</span>(<span class="params">gamma=<span class="number">1.0</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> Pipeline([</span><br><span class="line">        (<span class="string">&#x27;std_scale&#x27;</span>, StandardScaler()),</span><br><span class="line">        (<span class="string">&#x27;svc&#x27;</span>, SVC(kernel=<span class="string">&#x27;rbf&#x27;</span>, gamma=gamma))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">svc = RBFKernelSVC(gamma=<span class="number">1.0</span>)</span><br><span class="line">svc.fit(x, y)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_decision_boundary</span>(<span class="params">model, axis</span>):</span></span><br><span class="line">    x0, x1 = np.meshgrid(np.linspace(axis[<span class="number">0</span>], axis[<span class="number">1</span>], <span class="built_in">int</span>((axis[<span class="number">1</span>] - axis[<span class="number">0</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),</span><br><span class="line">                         np.linspace(axis[<span class="number">2</span>], axis[<span class="number">3</span>], <span class="built_in">int</span>((axis[<span class="number">3</span>] - axis[<span class="number">2</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),)</span><br><span class="line">    x_new = np.c_[x0.ravel(), x1.ravel()]</span><br><span class="line">    y_predict = model.predict(x_new)</span><br><span class="line">    zz = y_predict.reshape(x0.shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line">    custom_cmap = ListedColormap([<span class="string">&#x27;#EF9A9A&#x27;</span>, <span class="string">&#x27;#FFF59D&#x27;</span>, <span class="string">&#x27;#90CAF9&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    plt.contourf(x0, x1, zz, linewidth=<span class="number">5</span>, cmap=custom_cmap)</span><br><span class="line"></span><br><span class="line">plot_decision_boundary(svc, axis=[-<span class="number">1.5</span>, <span class="number">2.5</span>, -<span class="number">1.0</span>, <span class="number">1.5</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/774ef0cad19f43cda1a65373638cc7a3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">svc_gamma100 = RBFKernelSVC(gamma=<span class="number">100</span>)</span><br><span class="line">svc_gamma100.fit(x, y)</span><br><span class="line"></span><br><span class="line">plot_decision_boundary(svc_gamma100, axis=[-<span class="number">1.5</span>, <span class="number">2.5</span>, -<span class="number">1.0</span>, <span class="number">1.5</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/f4af93b3739f49d7ba7d12950a86c2c8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">svc_gamma10 = RBFKernelSVC(gamma=<span class="number">10</span>)</span><br><span class="line">svc_gamma10.fit(x, y)</span><br><span class="line"></span><br><span class="line">plot_decision_boundary(svc_gamma10, axis=[-<span class="number">1.5</span>, <span class="number">2.5</span>, -<span class="number">1.0</span>, <span class="number">1.5</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/8c17627fc089499985bcfdc47de3420a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">svc_gamma01 = RBFKernelSVC(gamma=<span class="number">0.1</span>)</span><br><span class="line">svc_gamma01.fit(x, y)</span><br><span class="line"></span><br><span class="line">plot_decision_boundary(svc_gamma01, axis=[-<span class="number">1.5</span>, <span class="number">2.5</span>, -<span class="number">1.0</span>, <span class="number">1.5</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/998b5e976bc341dca1c8e83d1f685a0b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>gamma相当于是在调节模型的复杂度，gammma越小模型复杂度越低，gamma越高模型复杂度越高。因此需要调节超参数gamma平衡过拟合和欠拟合。</p><hr><h1 id="SVM解决回归问题"><a href="#SVM解决回归问题" class="headerlink" title="SVM解决回归问题"></a>SVM解决回归问题</h1><p>svm解决回归问题的思路：在margin区域内的点越多越好。<br><img src="https://img-blog.csdnimg.cn/7c500f4412d54573be39477bb829a0b3.png"><br>在sklearn中实现SVM解决回归问题：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">boston = datasets.load_boston()</span><br><span class="line">x = boston.data</span><br><span class="line">y = boston.target</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">666</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVR</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVR</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">StandardLinearSVR</span>(<span class="params">epsilon=<span class="number">0.1</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> Pipeline([</span><br><span class="line">        (<span class="string">&#x27;std_scale&#x27;</span>, StandardScaler()),</span><br><span class="line">        <span class="comment"># C, kernel, 等超参需要调节</span></span><br><span class="line">        (<span class="string">&#x27;linear_svr&#x27;</span>, LinearSVR(epsilon=epsilon))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">svr = StandardLinearSVR()</span><br><span class="line">svr.fit(x_train, y_train)</span><br><span class="line">svr.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.6357154352424855</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习(九)——Kmeans聚类</title>
      <link href="/2021/12/06/ML9_Kmeans%E8%81%9A%E7%B1%BB/"/>
      <url>/2021/12/06/ML9_Kmeans%E8%81%9A%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<blockquote><p>k均值聚类算法（k-means clustering algorithm）是一种迭代求解的聚类分析算法，其步骤是随机选取K个对象作为初始的聚类中心，然后计算每个对象与各个种子聚类中心之间的距离，把每个对象分配给距离它最近的聚类中心。</p></blockquote><span id="more"></span><h1 id="Kmeans介绍"><a href="#Kmeans介绍" class="headerlink" title="Kmeans介绍"></a>Kmeans介绍</h1><p>算法接受参数k，然后将事先输入的n个数据划分为k个聚类以便使得所获得的聚类满足同一聚类中的对象相似度高，而不同聚类中的相似度低。以空间中k个中心进行聚类，对最靠近他们的对象归类，通过迭代的方法，逐次更新聚类中心的值，直至得到最好的聚类结果。<br><img src="https://img-blog.csdnimg.cn/e478925d83784843aaa33c7df0d1d2c8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><ul><li>算法描述：<br>（1）适当选择c个类的初始中心；<br>（2）在k次迭代中，对任意一个样本，求其到c各中心的距离，将该样本归到距离更短的中心所在的类；<br>（3）利用均值等方法更新该类的中心值；<br>（4）对于所有的c个聚类中心，如果利用（2）（3）的迭代法更新后，值保持不变，则迭代结束，否则继续迭代。 </li></ul><hr><h1 id="相似度的度量"><a href="#相似度的度量" class="headerlink" title="相似度的度量"></a>相似度的度量</h1><p><img src="https://img-blog.csdnimg.cn/393def5beff04434ac6e336f82480401.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="有序距离属性"><br><img src="https://img-blog.csdnimg.cn/1a411aa3921d4a2d86233403d9c65c83.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="无序距离属性"><br><img src="https://img-blog.csdnimg.cn/647cfd64a7ee4c45b37989cdeb389a71.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="混合属性"></p><hr><h1 id="Kmeans的计算过程"><a href="#Kmeans的计算过程" class="headerlink" title="Kmeans的计算过程"></a>Kmeans的计算过程</h1><p><img src="https://img-blog.csdnimg.cn/08c66c36551c4b71aacda1af6d69822a.png"><br>现在有4组数据，每组数据有2个维度，对其进行聚类分为2类，将其可视化一下。 A=(1,1),B=(2,1),C=(4,3),D=(5,4)<br><img src="https://img-blog.csdnimg.cn/d532bd8c9d194d63a41fae65311fb2ae.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_11,color_FFFFFF,t_70,g_se,x_16"><br>假设选取两个星的位置为初始中心 c1=(1,1),c2=(2,1) ，计算每个点到初始中心的距离，使用欧式距离得到4个点分别距离两个初始中心的距离，归于最近的类：<br><img src="https://img-blog.csdnimg.cn/4beb9f0ad4d84e9fb8672e7521471a6b.png"><br>通过比较，将其进行归类。并使用平均法更新中心位置。<br><img src="https://img-blog.csdnimg.cn/78f3042bdc0b41ab9d4fd6c8f6b6cbf0.png"><br>由于归于group1的只有一个点，一次更新后的中心位置 c1=(1,1)，而 c2=(11/3, 8/3)<br><img src="https://img-blog.csdnimg.cn/f12632fd94ae4afeb77f43c611bf21df.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_16,color_FFFFFF,t_70,g_se,x_16"><br>再次计算每个点与更新后的位置中心的距离<br><img src="https://img-blog.csdnimg.cn/32229f457c054dfdb10d9b66af4a1426.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_15,color_FFFFFF,t_70,g_se,x_16"><br>继续迭代下去，<br><img src="https://img-blog.csdnimg.cn/891772ef038f4adda1009f2e5da2aa3a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>此时，与上一次的类别标记无变化，即可停止。</p><hr><h1 id="Kmeans的编程实现"><a href="#Kmeans的编程实现" class="headerlink" title="Kmeans的编程实现"></a>Kmeans的编程实现</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kmeans</span>(<span class="params">X, k, maxIt</span>):</span></span><br><span class="line">    </span><br><span class="line">    numPoints, numDim = X.shape</span><br><span class="line">    <span class="comment"># 给数据标签留个位置</span></span><br><span class="line">    dataSet = np.zeros((numPoints, numDim + <span class="number">1</span>))</span><br><span class="line">    dataSet[:, :-<span class="number">1</span>] = X</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 随机初始化位置中心</span></span><br><span class="line">    centroids = dataSet[np.random.randint(numPoints, size = k), :]</span><br><span class="line">    centroids = dataSet[<span class="number">0</span>:<span class="number">2</span>, :]</span><br><span class="line">    <span class="comment"># 随机给初始位置中心赋予类别标记</span></span><br><span class="line">    centroids[:, -<span class="number">1</span>] = <span class="built_in">range</span>(<span class="number">1</span>, k +<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    iterations = <span class="number">0</span></span><br><span class="line">    oldCentroids = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Run the main k-means algorithm</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> shouldStop(oldCentroids, centroids, iterations, maxIt):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;iteration: \n&quot;</span>, iterations)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;dataSet: \n&quot;</span>, dataSet)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;centroids: \n&quot;</span>, centroids)</span><br><span class="line">        <span class="comment"># Save old centroids for convergence test. Book keeping.</span></span><br><span class="line">        oldCentroids = np.copy(centroids)</span><br><span class="line">        iterations += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Assign labels to each datapoint based on centroids</span></span><br><span class="line">        updateLabels(dataSet, centroids)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Assign centroids based on datapoint labels</span></span><br><span class="line">        centroids = getCentroids(dataSet, k)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># We can get the labels too by calling getLabels(dataSet, centroids)</span></span><br><span class="line">    <span class="keyword">return</span> dataSet</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shouldStop</span>(<span class="params">oldCentroids, centroids, iterations, maxIt</span>):</span></span><br><span class="line">    <span class="keyword">if</span> iterations &gt; maxIt:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> np.array_equal(oldCentroids, centroids)  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateLabels</span>(<span class="params">dataSet, centroids</span>):</span></span><br><span class="line">    <span class="comment"># For each element in the dataset, chose the closest centroid. </span></span><br><span class="line">    <span class="comment"># Make that centroid the element&#x27;s label.</span></span><br><span class="line">    numPoints, numDim = dataSet.shape</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, numPoints):</span><br><span class="line">        dataSet[i, -<span class="number">1</span>] = getLabelFromClosestCentroid(dataSet[i, :-<span class="number">1</span>], centroids)</span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLabelFromClosestCentroid</span>(<span class="params">dataSetRow, centroids</span>):</span></span><br><span class="line">    label = centroids[<span class="number">0</span>, -<span class="number">1</span>];</span><br><span class="line">    minDist = np.linalg.norm(dataSetRow - centroids[<span class="number">0</span>, :-<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span> , centroids.shape[<span class="number">0</span>]):</span><br><span class="line">        dist = np.linalg.norm(dataSetRow - centroids[i, :-<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span> dist &lt; minDist:</span><br><span class="line">            minDist = dist</span><br><span class="line">            label = centroids[i, -<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;minDist:&quot;</span>, minDist)</span><br><span class="line">    <span class="keyword">return</span> label</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getCentroids</span>(<span class="params">dataSet, k</span>):</span></span><br><span class="line">    <span class="comment"># Each centroid is the geometric mean of the points that</span></span><br><span class="line">    <span class="comment"># have that centroid&#x27;s label. Important: If a centroid is empty (no points have</span></span><br><span class="line">    <span class="comment"># that centroid&#x27;s label) you should randomly re-initialize it.</span></span><br><span class="line">    result = np.zeros((k, dataSet.shape[<span class="number">1</span>]))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, k + <span class="number">1</span>):</span><br><span class="line">        oneCluster = dataSet[dataSet[:, -<span class="number">1</span>] == i, :-<span class="number">1</span>]</span><br><span class="line">        result[i - <span class="number">1</span>, :-<span class="number">1</span>] = np.mean(oneCluster, axis = <span class="number">0</span>)</span><br><span class="line">        result[i - <span class="number">1</span>, -<span class="number">1</span>] = i</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">x1 = np.array([<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">x2 = np.array([<span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">x3 = np.array([<span class="number">4</span>, <span class="number">3</span>])</span><br><span class="line">x4 = np.array([<span class="number">5</span>, <span class="number">4</span>])</span><br><span class="line">testX = np.vstack((x1, x2, x3, x4))</span><br><span class="line"></span><br><span class="line">result = kmeans(testX, <span class="number">2</span>, <span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;final result:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="comment"># final result:</span></span><br><span class="line"><span class="comment"># [[1. 1. 1.]</span></span><br><span class="line"><span class="comment">#  [2. 1. 1.]</span></span><br><span class="line"><span class="comment">#  [4. 3. 2.]</span></span><br><span class="line"><span class="comment">#  [5. 4. 2.]]</span></span><br></pre></td></tr></table></figure><p>sklearn包的Kmeans聚类</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">KMeans(n_clusters=<span class="number">8</span>,init=<span class="string">&#x27;k-means++&#x27;</span>,n_init=<span class="number">10</span>,max_iter=<span class="number">300</span>,tol=<span class="number">0.0001</span>, </span><br><span class="line">       verbose=<span class="number">0</span>,random_state=<span class="literal">None</span>,</span><br><span class="line">       copy_x=<span class="literal">True</span>,algorithm=<span class="string">&#x27;auto&#x27;</span>)</span><br></pre></td></tr></table></figure><p><strong>参数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">n_clusters：</span><br><span class="line">整形，默认=<span class="number">8</span> 【生成的聚类数，即产生的质心（centroids）数</span><br><span class="line"></span><br><span class="line">init：</span><br><span class="line">有三个可选值：<span class="string">&#x27;k-means++&#x27;</span>， <span class="string">&#x27;random&#x27;</span>，或者传递一个ndarray向量。</span><br><span class="line">此参数指定初始化方法，默认值为 <span class="string">&#x27;k-means++&#x27;</span>。</span><br><span class="line">（１）<span class="string">&#x27;k-means++&#x27;</span> 用一种特殊的方法选定初始质心从而能加速迭代过程的收敛</span><br><span class="line">（２）<span class="string">&#x27;random&#x27;</span> 随机从训练数据中选取初始质心。</span><br><span class="line">（３）如果传递的是一个ndarray，则应该形如 (n_clusters, n_features) 并给出初始质心</span><br><span class="line"></span><br><span class="line">n_init：</span><br><span class="line">整形，默认=<span class="number">10</span>用不同的质心初始化值运行算法的次数，最终解是在inertia意义下选出的最优结果</span><br><span class="line"></span><br><span class="line">max_iter：</span><br><span class="line">整形，默认=<span class="number">300</span>执行一次k-means算法所进行的最大迭代数</span><br><span class="line"></span><br><span class="line">tol：</span><br><span class="line"><span class="built_in">float</span>形，默认值= <span class="number">1e-4</span>　与inertia结合来确定收敛条件</span><br><span class="line"></span><br><span class="line">precompute_distances：</span><br><span class="line">三个可选值，<span class="string">&#x27;auto&#x27;</span>，<span class="literal">True</span> 或者 <span class="literal">False</span>。预计算距离，计算速度更快但占用更多内存。</span><br><span class="line">（１）<span class="string">&#x27;auto&#x27;</span>：如果 样本数乘以聚类数大于 12million 的话则不预计算距离</span><br><span class="line">（２）<span class="literal">True</span>：总是预先计算距离</span><br><span class="line">（３）<span class="literal">False</span>：永远不预先计算距离</span><br><span class="line">自版本<span class="number">0.23</span>起已弃用： <span class="string">&#x27;precompute_distances&#x27;</span>在版本<span class="number">0.22</span>中已弃用，并将在<span class="number">0.25</span>中删除。没有作用</span><br><span class="line"></span><br><span class="line">verbose：</span><br><span class="line"><span class="built_in">int</span> 默认为<span class="number">0</span>，Verbosity mode</span><br><span class="line"></span><br><span class="line">random_state：</span><br><span class="line">整形或 numpy.RandomState 类型，可选用于初始化质心的生成器（generator）</span><br><span class="line">如果值为一个整数，则确定一个seed。此参数默认值为numpy的随机数生成器</span><br><span class="line"></span><br><span class="line">copy_x：</span><br><span class="line">布尔型，默认值=<span class="literal">True</span></span><br><span class="line">当我们precomputing distances时，将数据中心化会得到更准确的结果</span><br><span class="line">如果把此参数值设为<span class="literal">True</span>，则原始数据不会被改变</span><br><span class="line">如果是<span class="literal">False</span>，则会直接在原始数据上做修改并在函数返回值时将其还原</span><br><span class="line">但是在计算过程中由于有对数据均值的加减运算，所以数据返回后，原始数据和计算前可能会有细小差别</span><br><span class="line"></span><br><span class="line">n_jobs：</span><br><span class="line">整形数。　指定计算所用的进程数。内部原理是同时进行n_init指定次数的计算。</span><br><span class="line">（１）若值为 -<span class="number">1</span>，则用所有的CPU进行运算</span><br><span class="line">（<span class="number">2</span>）若值为<span class="number">1</span>，则不进行并行运算，这样的话方便调试</span><br><span class="line">（<span class="number">3</span>）若值小于-<span class="number">1</span>，则用到的CPU数为(n_cpus + <span class="number">1</span> + n_jobs)</span><br><span class="line">         如果 n_jobs值为-<span class="number">2</span>，则用到的CPU数为总CPU数减<span class="number">1</span></span><br><span class="line">  从<span class="number">0.23</span>版n_jobs开始不推荐使用：从<span class="number">0.23</span>版开始不推荐使用，并将在<span class="number">0.25</span>版中删除。 </span><br><span class="line">  </span><br><span class="line">algorithm：</span><br><span class="line">三种可选“auto”, “full”, “elkan”, default=”auto”</span><br><span class="line"> 使用K均值算法。经典的EM风格算法是“full”的</span><br><span class="line"> 通过使用三角形不等式，“ elkan”算法对于定义良好的聚类的数据更有效</span><br><span class="line"> 但是，由于分配了额外的形状数组（n_samples，n_clusters），因此需要更多的内存。</span><br><span class="line">目前，“ auto”（保持向后兼容性）选择“ elkan”</span><br><span class="line">在版本<span class="number">0.18</span>中更改：添加了Elkan算法</span><br></pre></td></tr></table></figure><p><strong>实例</strong><br>首先我们随机创建一些二维数据作为训练集，观察在不同的k值下聚类算法的区别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="comment"># X为样本特征，Y为样本簇类别， 共1000个样本，</span></span><br><span class="line"><span class="comment"># 每个样本4个特征，共4个簇，簇中心在[-1,-1], [0,0],[1,1],[2,2]， 簇方差分别为[0.4, 0.2, 0.2，0.2]</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">1000</span>, n_features=<span class="number">2</span>,centers=[[-<span class="number">1</span>,-<span class="number">1</span>], [<span class="number">0</span>,<span class="number">0</span>], [<span class="number">1</span>,<span class="number">1</span>], [<span class="number">2</span>,<span class="number">2</span>]],</span><br><span class="line">cluster_std=[<span class="number">0.4</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>],random_state =<span class="number">9</span>)</span><br><span class="line">y_pred = KMeans(n_clusters=<span class="number">2</span>, random_state=<span class="number">9</span>)</span><br><span class="line">y_pred = y_pred.fit_predict(X)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y_pred)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>利用KMeans函数新建一个聚类算法，这里设置为2分类</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = KMeans(n_clusters=<span class="number">2</span>, random_state=<span class="number">9</span>)</span><br></pre></td></tr></table></figure><p>然后进行分类</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">y_pred = y_pred.fit_predict(X)</span><br><span class="line"> 新建对象后，常用的方法包括fit、predict、cluster_centers_和labels。</span><br><span class="line"> fit（X）函数对数据X进行聚类，</span><br><span class="line"> 使用predict方法进行新数据类别的预测，</span><br><span class="line"> 使用cluster_centers_获取聚类中心，</span><br><span class="line"> 使用labels_获取训练数据所属的类别，</span><br><span class="line"> inertia_获取每个点到聚类中心的距离和</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/9eada08cccfa49e7b6510a6175fe2168.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16" alt="二分类"><br>当然3分类，4分类我们只需要修改一下KMeans函数中的n_clusters参数即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = KMeans(n_clusters=<span class="number">3</span>, random_state=<span class="number">9</span>)</span><br><span class="line">y_pred = KMeans(n_clusters=<span class="number">4</span>, random_state=<span class="number">9</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/e56bba3be0564abc900166516ec9d86f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16" alt="三分类"><br><img src="https://img-blog.csdnimg.cn/75a90f400885409fa9f9b1295e8ca17c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16" alt="四分类"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 聚类 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> Kmeans </tag>
            
            <tag> 聚类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习(八)——决策树</title>
      <link href="/2021/12/05/ML8_%E5%86%B3%E7%AD%96%E6%A0%91/"/>
      <url>/2021/12/05/ML8_%E5%86%B3%E7%AD%96%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<blockquote><p>决策树是基于树结构进行决策的。决策树(Decision Tree）是在已知各种情况发生概率的基础上，通过构成决策树来求取净现值的期望值大于等于零的概率。它是一种非参数学习算法，既可以解决分类问题，也可以解决回归问题。</p></blockquote><p>在学习决策树前需要先对熵的概念进行了解。</p><span id="more"></span><h1 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h1><p>熵：用来描述事物的混乱程度，是对平均不确定性的度量。<br><img src="https://img-blog.csdnimg.cn/d5bd9398a97049a6bf79a5a078a1ebb0.png"><br>信息熵：由香农提出，。是度量样本集合纯度的最常用的指标。熵在信息论中代表随机变量不确定度的度量。一条信息大小和它的不确定性有直接关系，要搞清楚一件非常不确定的事情，或者是我们一无所知的事情，需要了解大量信息==&gt;信息的度量就等于不确定的多少。</p><p>熵越大，数据不确定性越高，熵越低，数据的不确定性越低。假定当前样本集合D中k类样本所占比例为 p<sub>i</sub>，则信息熵的定义：<br><img src="https://img-blog.csdnimg.cn/1606fd967c4342d5a7d8957648ea5085.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">entropy</span>(<span class="params">p</span>):</span></span><br><span class="line">    <span class="keyword">return</span> -p * np.log(p) - (<span class="number">1</span>-p) * np.log(<span class="number">1</span>-p)</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0.01</span>, <span class="number">0.99</span>, <span class="number">200</span>)</span><br><span class="line">plt.plot(x, entropy(x))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/639728b181044f3f8d33492b8bc51743.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="基于信息熵的决策树"><a href="#基于信息熵的决策树" class="headerlink" title="基于信息熵的决策树"></a>基于信息熵的决策树</h1><p>决策树的生成是一个递归过程，在决策树基本算法中有三种形式会导致递归结束并返回：<br>（1）当前结点包含所有的样本属于同一级别，无需划分；<br>（2）当前属性及为空，或是所有样本在所有属性上取值相同，无法划分；<br>（3）当前结点包含的样本集合为空，不能划分。<br>模拟信息熵进行划分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">x = iris.data[:, <span class="number">2</span>:]</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split</span>(<span class="params">x, y, d, value</span>):</span></span><br><span class="line">    index_a = (x[:, d] &lt;= value)</span><br><span class="line">    index_b = (x[:, d] &gt; value)</span><br><span class="line">    <span class="keyword">return</span> x[index_a], x[index_b], y[index_a], y[index_b]</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">entropy</span>(<span class="params">y</span>):</span></span><br><span class="line">    counter = Counter(y)</span><br><span class="line">    res = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> counter.values():</span><br><span class="line">        p = num / <span class="built_in">len</span>(y)</span><br><span class="line">        res += -p * log(p)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">try_split</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    </span><br><span class="line">    best_entropy = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    best_d, best_v = -<span class="number">1</span>, -<span class="number">1</span></span><br><span class="line">    <span class="comment"># 在使用的鸢尾花数据中只用了后两维，x.shape=(150, 2)</span></span><br><span class="line">    <span class="comment"># 首先将数据进行排序</span></span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(x.shape[<span class="number">1</span>]):</span><br><span class="line">        sorted_index = np.argsort(x[:,d])</span><br><span class="line">        <span class="comment"># 经过排序后，遍历每个划分点，比较划分后的信息熵，从而选择信息增益最大的那个节点</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(x)):</span><br><span class="line">            <span class="keyword">if</span> x[sorted_index[i-<span class="number">1</span>], d] != x[sorted_index[i], d]:</span><br><span class="line">                v = (x[sorted_index[i-<span class="number">1</span>], d] + x[sorted_index[i], d]) / <span class="number">2</span></span><br><span class="line">                x_l, x_r, y_l, y_r = split(x, y, d, v)</span><br><span class="line">                e = entropy(y_l) + entropy(y_r)</span><br><span class="line">                <span class="keyword">if</span> e &lt; best_entropy:</span><br><span class="line">                    best_entropy, best_d, best_v = e, d, v</span><br><span class="line">                    </span><br><span class="line">    <span class="keyword">return</span> best_entropy, best_d, best_v</span><br><span class="line"></span><br><span class="line">best_entropy, best_d, best_v = try_split(x, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best_entropy=&#x27;</span>, best_entropy)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best_d=&#x27;</span>, best_d)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best_v2&#x27;</span>,best_v)</span><br><span class="line"><span class="comment"># best_entropy= 0.6931471805599453</span></span><br><span class="line"><span class="comment"># best_d= 0</span></span><br><span class="line"><span class="comment"># best_v2 2.45</span></span><br><span class="line">x1_l, x1_r, y1_l, y1_r = split(x, y, best_d, best_v)</span><br><span class="line">entropy(y1_l)</span><br><span class="line"><span class="comment"># 0.0</span></span><br><span class="line">entropy(y1_r)</span><br><span class="line"><span class="comment"># 0.6931471805599453</span></span><br><span class="line">best_entropy2, best_d2, best_v2 = try_split(x1_r, y1_r)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best_entropy2=&#x27;</span>, best_entropy2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best_d2=&#x27;</span>, best_d2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best_v2=&#x27;</span>,best_v2)</span><br><span class="line"><span class="comment"># best_entropy2= 0.4132278899361904</span></span><br><span class="line"><span class="comment"># best_d2= 1</span></span><br><span class="line"><span class="comment"># best_v2= 1.75</span></span><br><span class="line"></span><br><span class="line">x2_l, x2_r, y2_l, y2_r = split(x1_r, y1_r, best_d2, best_v2)</span><br><span class="line">entropy(y2_l)</span><br><span class="line"><span class="comment"># 0.30849545083110386</span></span><br><span class="line">entropy(y2_r)</span><br><span class="line"><span class="comment"># 0.10473243910508653</span></span><br></pre></td></tr></table></figure><p>根据输出结果，第一次分割节点在（d=0）第一个维度的2.45处。第二次分割节点（d2=1）在第二个维度的1.75处。<br>基于信息熵的划分有有两种：<br><img src="https://img-blog.csdnimg.cn/3ff16e75b737464bac668382e75b0601.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="基尼指数"><a href="#基尼指数" class="headerlink" title="基尼指数"></a>基尼指数</h1><p><code>CART（Classification and Regression Tree）</code> 决策树使用基尼指数来选择划分属性，数据集D的纯度可以使用基尼值来度量：<br><img src="https://img-blog.csdnimg.cn/28d96171936749349056d1f5d86021cf.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0.01</span>, <span class="number">0.99</span>, <span class="number">200</span>)</span><br><span class="line">y = -<span class="number">2</span> * x**<span class="number">2</span> + <span class="number">2</span>*x </span><br><span class="line"></span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/8fc5cf130cc04a579904676b5475cb87.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16"><br>接下来模拟gini指数进行划分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split</span>(<span class="params">x, y, d, value</span>):</span></span><br><span class="line">    index_a = (x[:, d] &lt;= value)</span><br><span class="line">    index_b = (x[:, d] &gt; value)</span><br><span class="line">    <span class="keyword">return</span> x[index_a], x[index_b], y[index_a], y[index_b]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gini</span>(<span class="params">y</span>):</span></span><br><span class="line">    counter = Counter(y)</span><br><span class="line">    res = <span class="number">1.0</span></span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> counter.values():</span><br><span class="line">        p = num / <span class="built_in">len</span>(y)</span><br><span class="line">        res += -p ** <span class="number">2</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">try_split</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    </span><br><span class="line">    best_g = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    best_d, best_v = -<span class="number">1</span>, -<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(x.shape[<span class="number">1</span>]):</span><br><span class="line">        sorted_index = np.argsort(x[:,d])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(x)):</span><br><span class="line">            <span class="keyword">if</span> x[sorted_index[i-<span class="number">1</span>], d] != x[sorted_index[i], d]:</span><br><span class="line">                v = (x[sorted_index[i-<span class="number">1</span>], d] + x[sorted_index[i], d]) / <span class="number">2</span></span><br><span class="line">                x_l, x_r, y_l, y_r = split(x, y, d, v)</span><br><span class="line">                g = gini(y_l) + gini(y_r)</span><br><span class="line">                <span class="keyword">if</span> g &lt; best_g:</span><br><span class="line">                    best_g, best_d, best_v = g, d, v</span><br><span class="line">                    </span><br><span class="line">    <span class="keyword">return</span> best_g, best_d, best_v</span><br><span class="line"></span><br><span class="line">best_g, best_d, best_v = try_split(x, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best_g=&#x27;</span>, best_g)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best_d=&#x27;</span>, best_d)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best_v=&#x27;</span>, best_v)</span><br><span class="line"><span class="comment"># best_g= 0.5</span></span><br><span class="line"><span class="comment"># best_d= 0</span></span><br><span class="line"><span class="comment"># best_v= 2.45</span></span><br><span class="line"></span><br><span class="line">x1_l, x1_r, y1_l, y1_r = split(x, y, best_d, best_v)</span><br><span class="line">gini(y1_l)</span><br><span class="line"><span class="comment"># 0.0</span></span><br><span class="line">gini(y1_r)</span><br><span class="line"><span class="comment"># 0.5</span></span><br><span class="line">best_g2, best_d2, best_v2 = try_split(x1_r, y1_r)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best_g2=&#x27;</span>, best_g2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best_d2=&#x27;</span>, best_d2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best_v2=&#x27;</span>, best_v2)</span><br><span class="line"><span class="comment"># best_g2= 0.2105714900645938</span></span><br><span class="line"><span class="comment"># best_d2= 1</span></span><br><span class="line"><span class="comment"># best_v2= 1.75</span></span><br><span class="line"></span><br><span class="line">x2_l, x2_r, y2_l, y2_r = split(x1_r, y1_r, best_d2, best_v2)</span><br><span class="line">gini(y2_l)</span><br><span class="line"><span class="comment"># 0.1680384087791495</span></span><br><span class="line">gini(y2_r)</span><br><span class="line"><span class="comment"># 0.04253308128544431</span></span><br></pre></td></tr></table></figure><p>在实际使用的过程中信息熵的计算比基尼系数稍微慢，所以 <code>sklearn</code> 中默认为基尼系数。对比前面的内容也能发现，大多数情况这二者并没有特别的效果优劣。</p><hr><h1 id="sklearn中的决策树"><a href="#sklearn中的决策树" class="headerlink" title="sklearn中的决策树"></a>sklearn中的决策树</h1><p>使用鸢尾花数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">x = iris.data[:, <span class="number">2</span>:]</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">2</span>, <span class="number">0</span>], x[y==<span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/35ebace0c3cf4e11b2cfc9cbd4fb6466.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"><br>使用基于信息熵的决策树</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">dt_clf = DecisionTreeClassifier(max_depth=<span class="number">2</span>, criterion=<span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">dt_clf.fit(x, y)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_decision_boundary</span>(<span class="params">model, axis</span>):</span></span><br><span class="line">    x0, x1 = np.meshgrid(np.linspace(axis[<span class="number">0</span>], axis[<span class="number">1</span>], <span class="built_in">int</span>((axis[<span class="number">1</span>] - axis[<span class="number">0</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),</span><br><span class="line">                         np.linspace(axis[<span class="number">2</span>], axis[<span class="number">3</span>], <span class="built_in">int</span>((axis[<span class="number">3</span>] - axis[<span class="number">2</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),)</span><br><span class="line">    x_new = np.c_[x0.ravel(), x1.ravel()]</span><br><span class="line">    y_predict = model.predict(x_new)</span><br><span class="line">    zz = y_predict.reshape(x0.shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line">    custom_cmap = ListedColormap([<span class="string">&#x27;#EF9A9A&#x27;</span>, <span class="string">&#x27;#FFF59D&#x27;</span>, <span class="string">&#x27;#90CAF9&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    plt.contourf(x0, x1, zz, linewidth=<span class="number">5</span>, cmap=custom_cmap)</span><br><span class="line"></span><br><span class="line">plot_decision_boundary(dt_clf, axis=[<span class="number">0.5</span>, <span class="number">7.5</span>, <span class="number">0</span>, <span class="number">3</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">2</span>, <span class="number">0</span>], x[y==<span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/ebfd6c79e8134f92a45cc2dc67a3e0d2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"><br>使用基于基尼指数的决策树</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">x = iris.data[:, <span class="number">2</span>:]</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">dt_clf = DecisionTreeClassifier(max_depth=<span class="number">2</span>, criterion=<span class="string">&#x27;gini&#x27;</span>)</span><br><span class="line">dt_clf.fit(x, y)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_decision_boundary</span>(<span class="params">model, axis</span>):</span></span><br><span class="line">    x0, x1 = np.meshgrid(np.linspace(axis[<span class="number">0</span>], axis[<span class="number">1</span>], <span class="built_in">int</span>((axis[<span class="number">1</span>] - axis[<span class="number">0</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),</span><br><span class="line">                         np.linspace(axis[<span class="number">2</span>], axis[<span class="number">3</span>], <span class="built_in">int</span>((axis[<span class="number">3</span>] - axis[<span class="number">2</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),)</span><br><span class="line">    x_new = np.c_[x0.ravel(), x1.ravel()]</span><br><span class="line">    y_predict = model.predict(x_new)</span><br><span class="line">    zz = y_predict.reshape(x0.shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line">    custom_cmap = ListedColormap([<span class="string">&#x27;#EF9A9A&#x27;</span>, <span class="string">&#x27;#FFF59D&#x27;</span>, <span class="string">&#x27;#90CAF9&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    plt.contourf(x0, x1, zz, linewidth=<span class="number">5</span>, cmap=custom_cmap)</span><br><span class="line"></span><br><span class="line">plot_decision_boundary(dt_clf, axis=[<span class="number">0.5</span>, <span class="number">7.5</span>, <span class="number">0</span>, <span class="number">3</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">2</span>, <span class="number">0</span>], x[y==<span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/cd83a1c2d50c4c3e9579f9671f068760.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="决策树解决回归问题"><a href="#决策树解决回归问题" class="headerlink" title="决策树解决回归问题"></a>决策树解决回归问题</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">boston = datasets.load_boston()</span><br><span class="line">x = boston.data</span><br><span class="line">y = boston.target</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">666</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"></span><br><span class="line">dt_reg = DecisionTreeRegressor()</span><br><span class="line">dt_reg.fit(x_train, y_train)</span><br><span class="line">dt_reg.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.6074066452266129</span></span><br><span class="line">dt_reg.score(x_train, y_train)</span><br><span class="line"><span class="comment"># 1.0</span></span><br></pre></td></tr></table></figure><p>训练分数很高，测试分数比较低，明显是发生了过拟合。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">param_grid = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;max_depth&#x27;</span>:[i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>)],</span><br><span class="line">        <span class="string">&#x27;min_samples_leaf&#x27;</span>:[i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">20</span>)],</span><br><span class="line">        <span class="string">&#x27;min_samples_split&#x27;</span>:[i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>, <span class="number">30</span>)],</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"></span><br><span class="line">dt_reg3 = DecisionTreeRegressor()</span><br><span class="line">grid_search = GridSearchCV(dt_reg3, param_grid)</span><br><span class="line">grid_search.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">grid_search.best_params_</span><br><span class="line"><span class="comment"># &#123;&#x27;max_depth&#x27;: 9, &#x27;min_samples_leaf&#x27;: 1, &#x27;min_samples_split&#x27;: 23&#125;</span></span><br><span class="line">dt_reg4 = DecisionTreeRegressor(max_depth=<span class="number">9</span>, min_samples_leaf=<span class="number">1</span>, min_samples_split=<span class="number">23</span>)</span><br><span class="line">dt_reg4.fit(x_train, y_train)</span><br><span class="line">dt_reg4.score(x_train, y_train)</span><br><span class="line"><span class="comment"># 0.9095986627498869</span></span><br><span class="line">dt_reg4.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.7748706184452597</span></span><br></pre></td></tr></table></figure><p>透过学习曲线了解模型过拟合情况：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_learning_curve</span>(<span class="params">algo, x_train, x_test, y_train, y_test</span>):</span></span><br><span class="line"></span><br><span class="line">    train_score = []</span><br><span class="line">    test_score = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(x_train)+<span class="number">1</span>):</span><br><span class="line">        algo.fit(x_train[:i], y_train[:i])</span><br><span class="line"></span><br><span class="line">        y_train_predict = algo.predict(x_train[:i])</span><br><span class="line">        train_score.append(mean_squared_error(y_train[:i], y_train_predict))</span><br><span class="line"></span><br><span class="line">        y_test_predict = algo.predict(x_test)</span><br><span class="line">        test_score.append(mean_squared_error(y_test, y_test_predict))</span><br><span class="line"></span><br><span class="line">    plt.plot([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(x_train)+<span class="number">1</span>)], np.sqrt(train_score), label=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">    plt.plot([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(x_train)+<span class="number">1</span>)], np.sqrt(test_score), label=<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    <span class="comment"># plt.axis([0, len(x_train)+1, 0, 4])</span></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot_learning_curve(DecisionTreeRegressor(max_depth=<span class="number">9</span>, min_samples_leaf=<span class="number">1</span>, min_samples_split=<span class="number">23</span>), x_train, x_test, y_train, y_test)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/e4e286d02d284f7480b9d83cc0510922.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16"><br>绘制模型复杂度曲线：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"></span><br><span class="line">maxSampleLeaf = <span class="number">506</span></span><br><span class="line">train_scores = []</span><br><span class="line">test_scores = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, maxSampleLeaf+<span class="number">1</span>):</span><br><span class="line">    dt_reg = DecisionTreeRegressor(min_samples_leaf=i)</span><br><span class="line">    dt_reg.fit(x_train, y_train)</span><br><span class="line">    y_train_predict = dt_reg.predict(x_train)</span><br><span class="line">    train_scores.append(r2_score(y_train, y_train_predict))</span><br><span class="line">    test_scores.append(dt_reg.score(x_test, y_test))</span><br><span class="line">    </span><br><span class="line">plt.plot([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, maxSampleLeaf+<span class="number">1</span>)], train_scores, label=<span class="string">&quot;train&quot;</span>)</span><br><span class="line">plt.plot([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, maxSampleLeaf+<span class="number">1</span>)], test_scores, label=<span class="string">&quot;test&quot;</span>)</span><br><span class="line">plt.xlim(<span class="number">506</span>, <span class="number">1</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/b13158e88bc34ca28bf93ec02fbe8f24.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">maxSampleLeaf = <span class="number">100</span></span><br><span class="line">train_scores = []</span><br><span class="line">test_scores = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, maxSampleLeaf+<span class="number">1</span>):</span><br><span class="line">    dt_reg = DecisionTreeRegressor(min_samples_leaf=i)</span><br><span class="line">    dt_reg.fit(x_train, y_train)</span><br><span class="line">    y_train_predict = dt_reg.predict(x_train)</span><br><span class="line">    train_scores.append(r2_score(y_train, y_train_predict))</span><br><span class="line">    test_scores.append(dt_reg.score(x_test, y_test))</span><br><span class="line">    </span><br><span class="line">plt.plot([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, maxSampleLeaf+<span class="number">1</span>)], train_scores, label=<span class="string">&quot;train&quot;</span>)</span><br><span class="line">plt.plot([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, maxSampleLeaf+<span class="number">1</span>)], test_scores, label=<span class="string">&quot;test&quot;</span>)</span><br><span class="line">plt.xlim(maxSampleLeaf, <span class="number">1</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/972e3f862eb14fb89021a698ae78e5d2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="决策树的局限性"><a href="#决策树的局限性" class="headerlink" title="决策树的局限性"></a>决策树的局限性</h1><p>局限性1：横平竖直的直线划分，并不是能使用斜线。因此并不是最好的划分方式。<br><img src="https://img-blog.csdnimg.cn/100ab5b6270c4dff8ba83b86f6a8c53a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>局限性2：对个别数据敏感。这也是非参数学习的一个共性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">x = iris.data[:, <span class="number">2</span>:]</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">dt_clf = DecisionTreeClassifier(max_depth=<span class="number">2</span>, criterion=<span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">dt_clf.fit(x, y)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_decision_boundary</span>(<span class="params">model, axis</span>):</span></span><br><span class="line">    x0, x1 = np.meshgrid(np.linspace(axis[<span class="number">0</span>], axis[<span class="number">1</span>], <span class="built_in">int</span>((axis[<span class="number">1</span>] - axis[<span class="number">0</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),</span><br><span class="line">                         np.linspace(axis[<span class="number">2</span>], axis[<span class="number">3</span>], <span class="built_in">int</span>((axis[<span class="number">3</span>] - axis[<span class="number">2</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),)</span><br><span class="line">    x_new = np.c_[x0.ravel(), x1.ravel()]</span><br><span class="line">    y_predict = model.predict(x_new)</span><br><span class="line">    zz = y_predict.reshape(x0.shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line">    custom_cmap = ListedColormap([<span class="string">&#x27;#EF9A9A&#x27;</span>, <span class="string">&#x27;#FFF59D&#x27;</span>, <span class="string">&#x27;#90CAF9&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    plt.contourf(x0, x1, zz, linewidth=<span class="number">5</span>, cmap=custom_cmap)</span><br><span class="line"></span><br><span class="line">plot_decision_boundary(dt_clf, axis=[<span class="number">0.5</span>, <span class="number">7.5</span>, <span class="number">0</span>, <span class="number">3</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">2</span>, <span class="number">0</span>], x[y==<span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/dce88b7de3a348d89e42388b5119957e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x_new = np.delete(x, <span class="number">138</span>, axis=<span class="number">0</span>)</span><br><span class="line">y_new = np.delete(y, <span class="number">138</span>)</span><br><span class="line"></span><br><span class="line">dt_clf2 = DecisionTreeClassifier(max_depth=<span class="number">2</span>, criterion=<span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">dt_clf2.fit(x_new, y_new)</span><br><span class="line"></span><br><span class="line">plot_decision_boundary(dt_clf2, axis=[<span class="number">0.5</span>, <span class="number">7.5</span>, <span class="number">0</span>, <span class="number">3</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">2</span>, <span class="number">0</span>], x[y==<span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/f9327c8d7cc94add9e647c52c589b66a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"><br>删除了x中的一个数据，最终的到模型就大不相同，这是因为对于非参数学习来说对于个别数据十分敏感，而且非常依赖于调参才能得到一个比较好的模型。因此一般不会单独使用决策树建立模型。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 决策树 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习(七)——分类算法的评价</title>
      <link href="/2021/12/04/ML7_%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E8%AF%84%E4%BB%B7/"/>
      <url>/2021/12/04/ML7_%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E8%AF%84%E4%BB%B7/</url>
      
        <content type="html"><![CDATA[<h1 id="分类准确度存在的问题"><a href="#分类准确度存在的问题" class="headerlink" title="分类准确度存在的问题"></a>分类准确度存在的问题</h1><p>如果现在有一个癌症预测系统，输入患者的信息，可以判断是否有癌症。如果只使用分类准确度来评价模型的好坏是否合理？假如此时模型的预测准确度是99.9%，那么是否能认为模型是好的呢？如果癌症产生的概率只有0.1%，那就意味着这个癌症预测系统只有预测所有人都是健康，即可达到99.9%的准确率。那么此时还认为模型是好的嘛？假如更加极端一点，如果癌症产生的概率只有0.01%，那就意味着这个癌症预测系统只有预测所有人都是健康，即可达到99.99%的准确率。到这里，就能大概理解分类准确度评价模型存在的问题。什么时候才会出现这样的问题呢？这就是对于<strong>极度偏斜的数据（Skewed Data）</strong>，也就样本数据极度不平衡的情况下，只使用分类准确度是远远不够的。因此需要引进更多的指标。<br>首先使用<strong>混淆矩阵（Confusion Matrix）</strong> 做进一步的分析。首先针对二分类问题，进行混淆矩阵分析。我们通过样本的采集，能够直接知道真实情况下，哪些数据结果是 <strong>positive</strong>，哪些结果是 <strong>negative</strong>。</p><span id="more"></span><blockquote><p>混淆矩阵也称误差矩阵，是表示精度评价的一种标准格式，用n行n列的矩阵形式来表示。</p></blockquote><p>介绍几个概念：<br><img src="https://img-blog.csdnimg.cn/a78f3721e4b2426f8359de1b6a0324cb.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="混淆矩阵"></p><blockquote><p>TN（True Negative）：真实值Negative，预测Negative<br>FP（False Positive）： 真实值Negative，预测Positive<br>FN（False Negative）：真实值Positive，预测Negative<br>TP（True Positive）： 真实值Positive，预测Positive</p></blockquote><p>其实，就是希望右斜对角线越多越好就，即TN和TP的数量越多越好，也由此会延伸出更多的二级指标。<br>假设还是癌症预测，先测试了10000个人，预测结果如下：<br><img src="https://img-blog.csdnimg.cn/18529f726fa24bc7968631b1837ec2d4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>TN：9978个人真实没有癌症，预测没有癌症；FP：12个人真实没有癌症，预测有癌症；FN：2个人真实有癌症，预测没有癌症；TP：8个人真实有癌症，预测也有癌症。</p><hr><h1 id="精准率和召回率"><a href="#精准率和召回率" class="headerlink" title="精准率和召回率"></a>精准率和召回率</h1><p>首先介绍由混淆矩阵延伸出来的两个二级指标：</p><h2 id="精准率（precision）"><a href="#精准率（precision）" class="headerlink" title="精准率（precision）"></a>精准率（precision）</h2><p><img src="https://img-blog.csdnimg.cn/cba4bd8bd02a46f4bfe7c189dba2b95a.png"><br>由第一节中的实际案例，精准率=8/（8+12）=40%，这是因为通常在有偏的样本集中更加关注重点。精准率就是对更加关注的事件进行一个评判，比如例子中我们把预测有癌症作为关注的重点，就是在预测患有癌症的患者中真实患有癌症的概率。</p><h2 id="召回率-（recall）"><a href="#召回率-（recall）" class="headerlink" title="召回率 （recall）"></a>召回率 （recall）</h2><p><img src="https://img-blog.csdnimg.cn/1a27f2fd66ac42029ed62e82a7e44dc7.png"><br>由第一节中的实际案例，召回率=8/（8+2）=80%，就是在10个癌症患者中预测出了8个，80%就是召回率。</p><h2 id="编程实现精准率和召回率"><a href="#编程实现精准率和召回率" class="headerlink" title="编程实现精准率和召回率"></a>编程实现精准率和召回率</h2><p>首先生成样本不均衡的数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">​</span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line">x = digits.data</span><br><span class="line">y = digits.target.copy()</span><br><span class="line"><span class="comment"># 生成不平衡的数据</span></span><br><span class="line">y[digits.target==<span class="number">9</span>] = <span class="number">1</span></span><br><span class="line">y[digits.target!=<span class="number">9</span>] = <span class="number">0</span></span><br><span class="line">​</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">666</span>)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">​</span><br><span class="line">log_reg = LogisticRegression()</span><br><span class="line">log_reg.fit(x_train, y_train)</span><br><span class="line">log_reg.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.9755555555555555</span></span><br><span class="line">log_reg_predict = log_reg.predict(x_test)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">TN</span>(<span class="params">y_true, y_predict</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(y_true) == <span class="built_in">len</span>(y_predict)</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>((y_true == <span class="number">0</span>) &amp; (y_predict == <span class="number">0</span>))</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">FP</span>(<span class="params">y_true, y_predict</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(y_true) == <span class="built_in">len</span>(y_predict)</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>((y_true == <span class="number">0</span>) &amp; (y_predict == <span class="number">1</span>))</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">FN</span>(<span class="params">y_true, y_predict</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(y_true) == <span class="built_in">len</span>(y_predict)</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>((y_true == <span class="number">1</span>) &amp; (y_predict == <span class="number">0</span>))</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">TP</span>(<span class="params">y_true, y_predict</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(y_true) == <span class="built_in">len</span>(y_predict)</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>((y_true == <span class="number">1</span>) &amp; (y_predict == <span class="number">1</span>))</span><br><span class="line">​</span><br><span class="line">TN(y_test, log_reg_predict)</span><br><span class="line"><span class="comment"># 403</span></span><br><span class="line">FP(y_test, log_reg_predict)</span><br><span class="line"><span class="comment"># 2</span></span><br><span class="line">FN(y_test, log_reg_predict)</span><br><span class="line"><span class="comment"># 9</span></span><br><span class="line">TP(y_test, log_reg_predict)</span><br><span class="line"><span class="comment"># 36</span></span><br><span class="line"><span class="comment"># 混淆矩阵的实现</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">confusion_matrix</span>(<span class="params">y_true, y_predict</span>):</span></span><br><span class="line">    <span class="keyword">return</span> np.array([</span><br><span class="line">        [TN(y_test, log_reg_predict), FP(y_test, log_reg_predict)],</span><br><span class="line">        [FN(y_test, log_reg_predict), TP(y_test, log_reg_predict)],</span><br><span class="line">    ])</span><br><span class="line">confusion_matrix(y_test, log_reg_predict)</span><br><span class="line"><span class="comment"># array([[403,   2],</span></span><br><span class="line"><span class="comment">#       [  9,  36]])</span></span><br><span class="line"><span class="comment"># 精准率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">precison_score</span>(<span class="params">y_true, y_predict</span>):</span></span><br><span class="line">    tp = TP(y_test, log_reg_predict)</span><br><span class="line">    fp = FP(y_test, log_reg_predict)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> tp/(tp+fp)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line">​</span><br><span class="line"><span class="comment"># 召回率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recall_score</span>(<span class="params">y_true, y_predict</span>):</span></span><br><span class="line">    tp = TP(y_test, log_reg_predict)</span><br><span class="line">    fn = FN(y_test, log_reg_predict)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> tp/(tp+fn)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line">​</span><br><span class="line">precison_score(y_test, log_reg_predict)</span><br><span class="line"><span class="comment"># 0.9473684210526315</span></span><br><span class="line">recall_score(y_test, log_reg_predict)</span><br><span class="line"><span class="comment"># 0.8</span></span><br></pre></td></tr></table></figure><h2 id="sklearn中精准率和召回率的实现"><a href="#sklearn中精准率和召回率的实现" class="headerlink" title="sklearn中精准率和召回率的实现"></a>sklearn中精准率和召回率的实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score</span><br><span class="line">​</span><br><span class="line">confusion_matrix(y_test, log_reg_predict)</span><br><span class="line"><span class="comment"># array([[403,   2],</span></span><br><span class="line"><span class="comment">#        [  9,  36]], dtype=int64)</span></span><br><span class="line">precision_score(y_test, log_reg_predict)</span><br><span class="line"><span class="comment"># 0.9473684210526315</span></span><br><span class="line">recall_score(y_test, log_reg_predict)</span><br><span class="line"><span class="comment"># 0.8</span></span><br></pre></td></tr></table></figure><p>在现实的使用过程中，这两个评价指标可能会出现一些矛盾，比如有些时候使用这种方法精准率高但召回率低，使用另外一种方法精准率低召回率高，那么如何权衡两种指标呢？<br><img src="https://img-blog.csdnimg.cn/651f8a10ec664e9fa4822ab3812ba23f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>有时候比较注重精准率，比如股票预测，有时候更加注重召回率，比如病人诊断。对于不同的应用场景，偏好不同的指标。而往往有些时候可能并不是这么的极端，既需要保证精准率又需要保证召回率？由此引出一个新的指标：<strong>F1-score</strong>。</p><hr><h1 id="F1-score"><a href="#F1-score" class="headerlink" title="F1-score"></a>F1-score</h1><blockquote><p>F1分数（F1 Score），是统计学中用来衡量二分类模型精确度的一种指标。它同时兼顾了分类模型的精确率和召回率。F1分数可以看作是模型精确率和召回率的一种调和平均，它的最大值是1，最小值是0。</p></blockquote><p><img src="https://img-blog.csdnimg.cn/980d5ddc0dac454b8d134c7c334709fa.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>编程实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score</span><br><span class="line">​</span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line">x = digits.data</span><br><span class="line">y = digits.target.copy()</span><br><span class="line"><span class="comment"># 生成不平衡的数据</span></span><br><span class="line">y[digits.target==<span class="number">9</span>] = <span class="number">1</span></span><br><span class="line">y[digits.target!=<span class="number">9</span>] = <span class="number">0</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">666</span>)</span><br><span class="line">​</span><br><span class="line">log_reg = LogisticRegression()</span><br><span class="line">log_reg.fit(x_train, y_train)</span><br><span class="line">log_reg.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.9755555555555555</span></span><br><span class="line">log_reg_predict = log_reg.predict(x_test)</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f1_score</span>(<span class="params">precision, recall</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span> * precision * recall / (precision + recall)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line">​</span><br><span class="line">precision_score(y_test, log_reg_predict)</span><br><span class="line"><span class="comment"># 0.9473684210526315</span></span><br><span class="line">recall_score(y_test, log_reg_predict)</span><br><span class="line"><span class="comment"># 0.8</span></span><br><span class="line">f1_score(precision_score(y_test, log_reg_predict), recall_score(y_test, log_reg_predict))</span><br><span class="line"><span class="comment"># 0.8674698795180723</span></span><br></pre></td></tr></table></figure><p>sklearn中的实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line">​</span><br><span class="line">f1_score(y_test, log_reg_predict)</span><br><span class="line"><span class="comment"># 0.8674698795180723</span></span><br></pre></td></tr></table></figure><p>通过上述例子进行一个对比：准确度：0.9755555555555555，精准率：0.9473684210526315，召回率：0.8，调和平均值f1-score：0.8674698795180723。精准率和召回率任何一个值比较低就会拉低整体分数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f1_score</span>(<span class="params">precision, recall</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span> * precision * recall / (precision + recall)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span> </span><br><span class="line">    </span><br><span class="line">precision = <span class="number">0.5</span></span><br><span class="line">recall = <span class="number">0.5</span></span><br><span class="line">f1_score(precision, recall)</span><br><span class="line"><span class="comment"># 0.5</span></span><br><span class="line">precision = <span class="number">0.1</span></span><br><span class="line">recall = <span class="number">0.9</span></span><br><span class="line">f1_score(precision, recall)</span><br><span class="line"><span class="comment"># 0.18000000000000002</span></span><br></pre></td></tr></table></figure><hr><h1 id="精准率与召回率的平衡"><a href="#精准率与召回率的平衡" class="headerlink" title="精准率与召回率的平衡"></a>精准率与召回率的平衡</h1><p>其实这是一对矛盾的指标，精准率高召回率就低，精准率低召回率就高，那么如何平衡呢？首先回顾一下逻辑回归算法<br><img src="https://img-blog.csdnimg.cn/c364d174588147bda66d054ef6f0ef78.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_16,color_FFFFFF,t_70,g_se,x_16"><br>决策边界：<br><img src="https://img-blog.csdnimg.cn/a77c6d578bff4886887babd1d1b3220a.png"><br>解析几何中，其实这就是一条直线，这条直线就是分类中的决策边界，在直线的一侧为0，另一侧为1，那么为什么要取0呢？如果取任意值呢？<br>决策边界：<br><img src="https://img-blog.csdnimg.cn/b523aa38f4fc45819469d25bbbec8352.png"><br>此时就是相当于平移决策边界，从而影响分类结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score</span><br><span class="line">​</span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line">x = digits.data</span><br><span class="line">y = digits.target.copy()</span><br><span class="line"><span class="comment"># 生成不平衡的数据</span></span><br><span class="line">y[digits.target==<span class="number">9</span>] = <span class="number">1</span></span><br><span class="line">y[digits.target!=<span class="number">9</span>] = <span class="number">0</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">666</span>)</span><br><span class="line">​</span><br><span class="line">log_reg = LogisticRegression()</span><br><span class="line">log_reg.fit(x_train, y_train)</span><br><span class="line"><span class="comment"># 默认使用0作为决策边界。那如何对决策边界进行平移呢？</span></span><br><span class="line">y_predict = log_reg.predict(x_test)</span><br><span class="line">​</span><br><span class="line">confusion_matrix(y_test, y_predict)</span><br><span class="line"><span class="comment"># array([[403,   2],</span></span><br><span class="line"><span class="comment">#       [  9,  36]], dtype=int64)</span></span><br><span class="line">precision_score(y_test, y_predict)</span><br><span class="line"><span class="comment"># 0.9473684210526315</span></span><br><span class="line">recall_score(y_test, y_predict)</span><br><span class="line"><span class="comment"># 0.8</span></span><br></pre></td></tr></table></figure><p>首先我们要知道预测结果中的最大值最小值。然后就可以根据自己的需求选择合适的threshold，对数据进行预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">log_reg.decision_function(x_test)</span><br><span class="line"><span class="comment"># 太多了，显示前10个</span></span><br><span class="line">log_reg.decision_function(x_test)[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">array([-<span class="number">22.05700117</span>, -<span class="number">33.02940957</span>, -<span class="number">16.21334087</span>, -<span class="number">80.3791447</span> ,</span><br><span class="line">       -<span class="number">48.25125396</span>, -<span class="number">24.54005629</span>, -<span class="number">44.39168773</span>, -<span class="number">25.04292757</span>,</span><br><span class="line">        -<span class="number">0.97829292</span>, -<span class="number">19.7174399</span> ])</span><br><span class="line">log_reg.predict(x_test)[:<span class="number">10</span>]</span><br><span class="line"><span class="comment"># array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])</span></span><br></pre></td></tr></table></figure><p>通过前10个可以发现都是负数，预测结果都是0，这是因为predict默认使用0作为分类边界，小于0的都为0，大于0的为1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">decision_score =  log_reg.decision_function(x_test)</span><br><span class="line">np.<span class="built_in">min</span>(decision_score)</span><br><span class="line"><span class="comment"># -85.68608522646575</span></span><br><span class="line">np.<span class="built_in">max</span>(decision_score)</span><br><span class="line"><span class="comment"># 19.8895858799022</span></span><br></pre></td></tr></table></figure><p>首先选择threshold=5，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">y_predict2 = np.array(decision_score &gt;= <span class="number">5</span>, dtype=<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line">confusion_matrix(y_test, y_predict2)</span><br><span class="line"><span class="comment"># array([[404,   1],</span></span><br><span class="line"><span class="comment">#        [ 21,  24]], dtype=int64)</span></span><br><span class="line">precision_score(y_test, y_predict2)</span><br><span class="line"><span class="comment"># 0.96</span></span><br><span class="line">recall_score(y_test, y_predict2)</span><br><span class="line"><span class="comment"># 0.5333333333333333</span></span><br></pre></td></tr></table></figure><p>如果选择threshold=-5呢？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">y_predict3 = np.array(decision_score &gt;= -<span class="number">5</span>, dtype=<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line">confusion_matrix(y_test, y_predict3)</span><br><span class="line"><span class="comment"># array([[390,  15],</span></span><br><span class="line"><span class="comment">#        [  5,  40]], dtype=int64)</span></span><br><span class="line">precision_score(y_test, y_predict3)</span><br><span class="line"><span class="comment"># 0.7272727272727273</span></span><br><span class="line">recall_score(y_test, y_predict3)</span><br><span class="line"><span class="comment"># 0.8888888888888888</span></span><br></pre></td></tr></table></figure><p>至此，使用decision_function这个函数改变了逻辑回归分类的阈值，相应的可以对比不同阈值情况下精准率和召回率的制约关系，那么具体做一个分类算法的时候，如何选取这个threshold去平衡精准率和召回率呢？由此引出精准率与召回率曲线。</p><hr><h1 id="精准率与召回率曲线（P-R曲线）"><a href="#精准率与召回率曲线（P-R曲线）" class="headerlink" title="精准率与召回率曲线（P-R曲线）"></a>精准率与召回率曲线（P-R曲线）</h1><p>PR曲线的两个指标都聚焦于正例。</p><h2 id="编程实现PR曲线"><a href="#编程实现PR曲线" class="headerlink" title="编程实现PR曲线"></a>编程实现PR曲线</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">​</span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line">x = digits.data</span><br><span class="line">y = digits.target.copy()</span><br><span class="line"><span class="comment"># 生成不平衡的数据</span></span><br><span class="line">y[digits.target==<span class="number">9</span>] = <span class="number">1</span></span><br><span class="line">y[digits.target!=<span class="number">9</span>] = <span class="number">0</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">666</span>)</span><br><span class="line">log_reg = LogisticRegression()</span><br><span class="line">log_reg.fit(x_train, y_train)</span><br><span class="line">​</span><br><span class="line">decision_scores = log_reg.decision_function(x_test)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score</span><br><span class="line">​</span><br><span class="line">precisions = []</span><br><span class="line">recalls = []</span><br><span class="line">thresholds = np.arange(np.<span class="built_in">min</span>(decision_scores), np.<span class="built_in">max</span>(decision_scores))</span><br><span class="line">​</span><br><span class="line"><span class="keyword">for</span> threshold <span class="keyword">in</span> thresholds:</span><br><span class="line">    y_predict = np.array(decision_scores &gt;= threshold, dtype=<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line">    precisions.append(precision_score(y_test, y_predict))</span><br><span class="line">    recalls.append(recall_score(y_test, y_predict)) </span><br><span class="line">    </span><br><span class="line">plt.plot(thresholds, precisions, label=<span class="string">&#x27;precision&#x27;</span>)</span><br><span class="line">plt.plot(thresholds, recalls, label=<span class="string">&#x27;recall&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/de6ca5b5d660424bb1af71edd913fe5e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>那么现在有了这个图，就可以去选择合适的阈值去平衡精准率和召回率。如果需要保持准确率为90%以上，能有多少召回率？从而确定合适的阈值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(precisions, recalls)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/bf8735cc60024ee5a92d44012bb91852.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16"><br>通过图中的趋势很显然随着精准率的提高，召回率在不断的下降。这也再一次印证了精准流程和召回率是互相制约互相平衡的，而在图中急剧下降的点大概就是精准率和召回率平衡的最佳点。</p><h2 id="sklearn中实现P-R曲线"><a href="#sklearn中实现P-R曲线" class="headerlink" title="sklearn中实现P-R曲线"></a>sklearn中实现P-R曲线</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_curve</span><br><span class="line">​</span><br><span class="line">precisions, recalls, thresholds = precision_recall_curve(y_test, decision_scores)</span><br><span class="line">precisions.shape</span><br><span class="line"><span class="comment"># (145,)</span></span><br><span class="line">recalls.shape</span><br><span class="line"><span class="comment"># (145,)</span></span><br><span class="line">thresholds.shape</span><br><span class="line"><span class="comment"># (144,)</span></span><br></pre></td></tr></table></figure><p>通过上面程序输出结果可以发现返回的精准率和召回率与阈值的长度不一致，这是因为在sklearn中会自动取合适的阈值范围内计算准确率和召回率，而且默认的最大值为1和最小值为0，没有对应的threshold，因此这就是为什么thresholds比precisions和recalls长度少1，因此在绘图的时候需要注意。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(thresholds, precisions[:-<span class="number">1</span>])</span><br><span class="line">plt.plot(thresholds, recalls[:-<span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/c191376990d34ff6b6d0d6a98180ed1b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16"><br>通过这两条曲线对比自己编程实现的精准率和召回率曲线大致相同，有着略微的差异，这是因为sklearn中对阈值进行了处理,会自动选取最重要的那部分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(precisions, recalls)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/09e8527ab00f4578bde0318bb318c51b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过精准率和召回率曲线，可以确定合理的阈值去平衡精准率与召回率他们之间的变化关系。而PR曲线中急剧下降的点大概就是最佳平衡点。最后假如使用两种不同的算法绘制出的PR曲线如下图所示，那么哪种算法更优呢？<br><img src="https://img-blog.csdnimg.cn/8bf21d5556004e19bd6cae32eb429a44.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>很显然，外面那根曲线上的每一个点都比里面那根曲线的precisions和recalls大，所以整体来说如果PR曲线更靠外，也就更好，因此也可以作为选择算法选择超参数的一种指标。其实就是PR曲线下的面积，来衡量模型的优劣，但是一般情况下都会使用另外一种曲线下的面积。由曲线的下的面积，引出下一个知识点ROC曲线。</p><hr><h1 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h1><blockquote><p>ROC曲线(Receiver Operation Characteristic<br>Curve)，描述TPR和FPR之间的关系。接受者操作特性曲线是指在特定刺激条件下，以被试在不同判断标准下所得的虚报概率P（y/N）为横坐标，以击中概率P（y/SN）为纵坐标，画得的各点的连线。</p></blockquote><p><img src="https://img-blog.csdnimg.cn/725dc72dc7c742f18a957155ac7363df.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>编程实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">TN</span>(<span class="params">y_true, y_predict</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(y_true) == <span class="built_in">len</span>(y_predict)</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>((y_true == <span class="number">0</span>) &amp; (y_predict == <span class="number">0</span>))</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">FP</span>(<span class="params">y_true, y_predict</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(y_true) == <span class="built_in">len</span>(y_predict)</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>((y_true == <span class="number">0</span>) &amp; (y_predict == <span class="number">1</span>))</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">FN</span>(<span class="params">y_true, y_predict</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(y_true) == <span class="built_in">len</span>(y_predict)</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>((y_true == <span class="number">1</span>) &amp; (y_predict == <span class="number">0</span>))</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">TP</span>(<span class="params">y_true, y_predict</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(y_true) == <span class="built_in">len</span>(y_predict)</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>((y_true == <span class="number">1</span>) &amp; (y_predict == <span class="number">1</span>))</span><br><span class="line">​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">TPR</span>(<span class="params">y_true, y_predict</span>):</span></span><br><span class="line">    tp = TP(y_true, y_predict)</span><br><span class="line">    fn = FN(y_true, y_predict)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> tp / (tp + fn)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">FPR</span>(<span class="params">y_true, y_predict</span>):</span></span><br><span class="line">    fp = FP(y_true, y_predict)</span><br><span class="line">    tn = TN(y_true, y_predict)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> fp / (fp + tn)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">​</span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line">x = digits.data</span><br><span class="line">y = digits.target.copy()</span><br><span class="line"><span class="comment"># 生成不平衡的数据</span></span><br><span class="line">y[digits.target==<span class="number">9</span>] = <span class="number">1</span></span><br><span class="line">y[digits.target!=<span class="number">9</span>] = <span class="number">0</span></span><br><span class="line">​</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">666</span>)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">​</span><br><span class="line">log_reg = LogisticRegression()</span><br><span class="line">log_reg.fit(x_train, y_train)</span><br><span class="line">log_reg.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.9755555555555555</span></span><br><span class="line">log_reg_predict = log_reg.predict(x_test)</span><br><span class="line">​</span><br><span class="line">decision_scores = log_reg.decision_function(x_test)</span><br><span class="line">​</span><br><span class="line">fprs = []</span><br><span class="line">tprs = []</span><br><span class="line">thresholds = np.arange(np.<span class="built_in">min</span>(decision_scores), np.<span class="built_in">max</span>(decision_scores))</span><br><span class="line">​</span><br><span class="line"><span class="keyword">for</span> threshold <span class="keyword">in</span> thresholds:</span><br><span class="line">    y_predict = np.array(decision_scores &gt;= threshold, dtype=<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line">    fprs.append(FPR(y_test, y_predict))</span><br><span class="line">    tprs.append(TPR(y_test, y_predict))</span><br><span class="line">    </span><br><span class="line">plt.plot(fprs, tprs)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/c1c4df2a3b0d4e729a0a878e99cbf60e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"><br>sklearn中ROC曲线的实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">​</span><br><span class="line">fprs, tprs, thresholds = roc_curve(y_test, decision_scores)</span><br><span class="line">plt.plot(fprs, tprs)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/ccebedf514ea4baebb32d89f06f623e7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"><br>ROC曲线随着fpr的增大，tpr也在增大，通常更加关注的是曲线下的面积，如何计算曲线下的面积呢？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="comment"># area under curve</span></span><br><span class="line">roc_auc_score(y_test, decision_scores)</span><br><span class="line"><span class="comment"># 0.9830452674897119</span></span><br></pre></td></tr></table></figure><p>曲线下的面积越大，说明模型的分类效果越好，这是因为在ROC曲线刚开始，fpr较低（预测为1的错误越低）的时候，tpr越大（预测为1正确的越多），曲线下的面积越大，分类算法的模型也就更好。 由输出结果可以发现ROC的AUC值对不均衡样本不是那么敏感，因此对于极度有偏的数据集查看模型的精准率和召回率曲线还是很有必要的，ROC的AUC的主要应用是比较模型或者算法的优劣。<br><img src="https://img-blog.csdnimg.cn/772937056a694267bbd2710d8f1bbd6f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="多分类问题中的混淆矩阵"><a href="#多分类问题中的混淆矩阵" class="headerlink" title="多分类问题中的混淆矩阵"></a>多分类问题中的混淆矩阵</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line">x = digits.data</span><br><span class="line">y = digits.target</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.8</span>, random_state=<span class="number">666</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">log_reg = LogisticRegression()</span><br><span class="line">log_reg.fit(x_train, y_train)</span><br><span class="line">log_reg.score(x_test, y_test)</span><br><span class="line"></span><br><span class="line">y_predict = log_reg.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score</span><br><span class="line">precision_score(y_test, y_predict, average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line"><span class="comment"># 可以尝试一下precision_score(y_test, y_predict)，默认情况下是不支持多分类准确率预测的，但是可以通过传入超参数解决</span></span><br><span class="line"><span class="comment"># 0.93115438108484</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">confusion_matrix(y_test, y_predict)</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">array([[<span class="number">147</span>,   <span class="number">0</span>,   <span class="number">1</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">1</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>],</span><br><span class="line">       [  <span class="number">0</span>, <span class="number">123</span>,   <span class="number">1</span>,   <span class="number">2</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">3</span>,   <span class="number">4</span>,  <span class="number">10</span>],</span><br><span class="line">       [  <span class="number">0</span>,   <span class="number">0</span>, <span class="number">134</span>,   <span class="number">1</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">1</span>,   <span class="number">0</span>],</span><br><span class="line">       [  <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>, <span class="number">138</span>,   <span class="number">0</span>,   <span class="number">5</span>,   <span class="number">0</span>,   <span class="number">1</span>,   <span class="number">5</span>,   <span class="number">0</span>],</span><br><span class="line">       [  <span class="number">2</span>,   <span class="number">5</span>,   <span class="number">0</span>,   <span class="number">0</span>, <span class="number">139</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">3</span>,   <span class="number">0</span>,   <span class="number">1</span>],</span><br><span class="line">       [  <span class="number">1</span>,   <span class="number">3</span>,   <span class="number">1</span>,   <span class="number">0</span>,   <span class="number">0</span>, <span class="number">146</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">1</span>,   <span class="number">0</span>],</span><br><span class="line">       [  <span class="number">0</span>,   <span class="number">2</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">1</span>, <span class="number">131</span>,   <span class="number">0</span>,   <span class="number">2</span>,   <span class="number">0</span>],</span><br><span class="line">       [  <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">1</span>,   <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>, <span class="number">132</span>,   <span class="number">1</span>,   <span class="number">2</span>],</span><br><span class="line">       [  <span class="number">1</span>,   <span class="number">9</span>,   <span class="number">2</span>,   <span class="number">3</span>,   <span class="number">2</span>,   <span class="number">4</span>,   <span class="number">0</span>,   <span class="number">0</span>, <span class="number">115</span>,   <span class="number">4</span>],</span><br><span class="line">       [  <span class="number">0</span>,   <span class="number">1</span>,   <span class="number">0</span>,   <span class="number">5</span>,   <span class="number">0</span>,   <span class="number">3</span>,   <span class="number">0</span>,   <span class="number">2</span>,   <span class="number">2</span>, <span class="number">134</span>]], dtype=int64)</span><br></pre></td></tr></table></figure><p>这样看上去并不直观，绘制一下混淆矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">cfm = confusion_matrix(y_test, y_predict)</span><br><span class="line">plt.matshow(cfm, cmap=plt.cm.gray)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/9a34b363d4a94ebcbdfef2af17b7bb17.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_14,color_FFFFFF,t_70,g_se,x_16"><br>图中白色方框越亮说明预测正确率越高，但是如果只是显示正确率对于混淆矩阵并能说明什么，是没有意义的，其实我们是想看看预测错误部分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算每一行有多少个样本</span></span><br><span class="line">row_sums = np.<span class="built_in">sum</span>(cfm, axis=<span class="number">1</span>)</span><br><span class="line">err_matrix = cfm / row_sums</span><br><span class="line"><span class="comment"># 不关注预测正确的那部分</span></span><br><span class="line">np.fill_diagonal(err_matrix, <span class="number">0</span>)</span><br><span class="line">err_matrix</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">array([[<span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.00735294</span>, <span class="number">0.</span>        , <span class="number">0.</span>        ,</span><br><span class="line">        <span class="number">0.00657895</span>, <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.</span>        ],</span><br><span class="line">       [<span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.00735294</span>, <span class="number">0.01342282</span>, <span class="number">0.</span>        ,</span><br><span class="line">        <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.02205882</span>, <span class="number">0.02857143</span>, <span class="number">0.06802721</span>],</span><br><span class="line">       [<span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.00671141</span>, <span class="number">0.</span>        ,</span><br><span class="line">        <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.00714286</span>, <span class="number">0.</span>        ],</span><br><span class="line">       [<span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.</span>        ,</span><br><span class="line">        <span class="number">0.03289474</span>, <span class="number">0.</span>        , <span class="number">0.00735294</span>, <span class="number">0.03571429</span>, <span class="number">0.</span>        ],</span><br><span class="line">       [<span class="number">0.01342282</span>, <span class="number">0.03496503</span>, <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.</span>        ,</span><br><span class="line">        <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.02205882</span>, <span class="number">0.</span>        , <span class="number">0.00680272</span>],</span><br><span class="line">       [<span class="number">0.00671141</span>, <span class="number">0.02097902</span>, <span class="number">0.00735294</span>, <span class="number">0.</span>        , <span class="number">0.</span>        ,</span><br><span class="line">        <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.00714286</span>, <span class="number">0.</span>        ],</span><br><span class="line">       [<span class="number">0.</span>        , <span class="number">0.01398601</span>, <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.</span>        ,</span><br><span class="line">        <span class="number">0.00657895</span>, <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.01428571</span>, <span class="number">0.</span>        ],</span><br><span class="line">       [<span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.00671141</span>, <span class="number">0.</span>        ,</span><br><span class="line">        <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.00714286</span>, <span class="number">0.01360544</span>],</span><br><span class="line">       [<span class="number">0.00671141</span>, <span class="number">0.06293706</span>, <span class="number">0.01470588</span>, <span class="number">0.02013423</span>, <span class="number">0.01333333</span>,</span><br><span class="line">        <span class="number">0.02631579</span>, <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.</span>        , <span class="number">0.02721088</span>],</span><br><span class="line">       [<span class="number">0.</span>        , <span class="number">0.00699301</span>, <span class="number">0.</span>        , <span class="number">0.03355705</span>, <span class="number">0.</span>        ,</span><br><span class="line">        <span class="number">0.01973684</span>, <span class="number">0.</span>        , <span class="number">0.01470588</span>, <span class="number">0.01428571</span>, <span class="number">0.</span>        ]])</span><br></pre></td></tr></table></figure><p>这个输出就是预测错误部分，整体看上去还是挺费劲的，然后绘制一下这个矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.matshow(err_matrix, cmap=plt.cm.gray)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/ac4c154f91fa497f8f90474fb60692c4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_13,color_FFFFFF,t_70,g_se,x_16"><br>这个图中整体来说就是越亮的部分就是预测错误越多的地方，比如真值为1却预测成了9，比如真值为8预测成了1，这样就能整体看出犯错的地方在哪里，更加重要的是还能看到犯错的主要原因是什么，比如这个手写数字的识别问题其实就在于数字8和数字1的预测，容易混淆1和9,1和8，其实可以通过调整这些个二分类的阈值来提升多分类任务的准确率，这个微调的过程还是有一定的难度的。通过这样一个混淆矩阵的可视化，进一步分析出问题所在，进而对分类算法进行改进。<br>其实，一直都在讨论的是如何从算法层面去解决问题，做出改进，但是在机器学习这个领域，很有可能问题并不是出在算法层面，而是有可能处在样本数据层面上，比如数据集的层面上去研究一下数字1、8、9等，从数据的角度去理解为什么机器学习算法或者模型预测错误的原因，很有可能能够总结出新的特征。这也就是特征工程。总之，数据是机器学习的基础，如果没有一个好的数据还谈什么训练模型。对于数据的清理和处理是很关键的！</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> ROC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习(六)——逻辑回归</title>
      <link href="/2021/12/03/ML6_LogisticRegression/"/>
      <url>/2021/12/03/ML6_LogisticRegression/</url>
      
        <content type="html"><![CDATA[<blockquote><p>逻辑回归（Logistics Regression），逻辑回归虽然叫回归，但实际上属于分类算法，常用于二分类的任务。当然逻辑回归也可以用于多分类，这就需要加上其它的方法。至于逻辑回归是怎么解决分类问题，实质上是把样本特征和样本发生的概率联系起来。</p></blockquote><span id="more"></span><h1 id="认识逻辑回归"><a href="#认识逻辑回归" class="headerlink" title="认识逻辑回归"></a>认识逻辑回归</h1><p>逻辑回归，通常作为分类算法，只可以解决二分类问题。最终得出的结果是一个概率值。<br>首先给出逻辑回归的公式：<br><img src="https://img-blog.csdnimg.cn/04ee9f65315a4039a007f847a887fcbe.png"><br>如何得到 $\widehat{p}$ 的函数表达式呢？既然叫逻辑回归，那就说明跟回归还是有关系的，先回顾一下回归问题：<br><img src="https://img-blog.csdnimg.cn/a86f933d81f3420082b2bff0d1c7dc75.png"><br>通常线性方程的值域为 (-$\infty$, +$\infty$) ，而概率的值域为[0, 1]，因此我们在这个基础上做一个变形，完成从 (-$\infty$, +$\infty$)  到[0,1]的转换。<br><img src="https://img-blog.csdnimg.cn/f8751cb3670d43e6b931a9f339fe8c09.png"><br>这个转换函数就叫做 <code>Sigmoid</code> 函数，函数的表达式：<br><img src="https://img-blog.csdnimg.cn/3a890ff179d2412a816db75fb0895618.png"><br>用 <code>matplotlib</code> 绘制一下函数图像：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span>(<span class="params">t</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-t))</span><br><span class="line"></span><br><span class="line">x = np.linspace(-<span class="number">10</span>, <span class="number">10</span>, <span class="number">500</span>)</span><br><span class="line">y = sigmoid(x)</span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/f190604e5e104c2aacbf9dcdf398300a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16" alt="Sigmoid函数图像"><br>相当于把一条直线强行掰弯，使其值域在(0, 1)之间。这样就完成从直线回归到逻辑回归的转变。<br>接下来再了解一下这个转换函数：<br><img src="https://img-blog.csdnimg.cn/67de5cbc3946410080734e9577401b46.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>现在的问题就是如何对于给定的样本数据集 <code>x</code> <code>y</code> 如何找到最优的 <code>θ</code> ？</p><hr><h1 id="逻辑回归的损失函数"><a href="#逻辑回归的损失函数" class="headerlink" title="逻辑回归的损失函数"></a>逻辑回归的损失函数</h1><p>通过前面的分析已经成功地把线性预测转换成了一个概率，那如何定义损失函数呢？<br><img src="https://img-blog.csdnimg.cn/ee56565154d04d58b4511c8dd0190dde.png"><br>把上面的描述转换为数学公式：<br><img src="https://img-blog.csdnimg.cn/1b822c09182a480682c0aa13edfa28ba.png"><br>下面是这个函数的图像：<br><img src="https://img-blog.csdnimg.cn/8513f0ff88f346d2af51fdfea0c7b141.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>上面的 <code>cost</code> 是一个分段函数，我们将其整合起来：<br><img src="https://img-blog.csdnimg.cn/5bc3ff17f9134707a490356fbd9a7896.png"><br>到此，就可以总结出逻辑回归的损失函数：<br><img src="https://img-blog.csdnimg.cn/21df842f616f45b29af938d2b7584d0e.png"><br>这个函数是一个凸函数，他没有公式解，只能使用梯度下降法求解。</p><hr><h1 id="损失函数的梯度"><a href="#损失函数的梯度" class="headerlink" title="损失函数的梯度"></a>损失函数的梯度</h1><p><img src="https://img-blog.csdnimg.cn/1a9bfdfb04e6417596030fa5c722643f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>对于这种复杂的损失函数，我们首先来看一个sigmoid函数的求导。<br><img src="https://img-blog.csdnimg.cn/e82ff7540c344bd49fb46fe917e0b027.png"><br>接下来看看一下 log(σ(t)) 函数的求导：<br><img src="https://img-blog.csdnimg.cn/eb2d49a688524dcb84c42494f3acf939.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>进一步求导：<br><img src="https://img-blog.csdnimg.cn/1854b70ff7a546b4bc6335f1f0f6ef59.png"><br>将两项合并(1)+(2)：<br><img src="https://img-blog.csdnimg.cn/4575274788d44d13bf2cd49a4dfbbe17.png"><br>再代入损失函数：<br><img src="https://img-blog.csdnimg.cn/9080b13250a0409782d16e741b22d357.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>梯度的向量化过程，其实这个推导过程跟线性回归中的推导很类似。<br><img src="https://img-blog.csdnimg.cn/b29c1c0dc518442a89d5d2b751477337.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="编码实现逻辑回归"><a href="#编码实现逻辑回归" class="headerlink" title="编码实现逻辑回归"></a>编码实现逻辑回归</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogisticRegression</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;初始化logistic回归模型&quot;</span></span><br><span class="line">        self.coef_ = <span class="literal">None</span></span><br><span class="line">        self.interception_ = <span class="literal">None</span></span><br><span class="line">        self._theta = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_sigmoid</span>(<span class="params">self, t</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.</span> / (<span class="number">1.</span> + np.exp(-t))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, x_train, y_train, eta=<span class="number">0.01</span>, n_iters=<span class="number">1e4</span></span>):</span></span><br><span class="line">        <span class="keyword">assert</span> x_train.shape[<span class="number">0</span>] == y_train.shape[<span class="number">0</span>], <span class="string">&quot;the size of x_train must be equal to the size of y_train&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">J</span>(<span class="params">theta, X_b, y</span>):</span></span><br><span class="line">            y_hat = self._sigmoid(X_b.dot(theta))</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">return</span> -np.<span class="built_in">sum</span>(y*np.log(y_hat) + (<span class="number">1</span>-y)*np.log(<span class="number">1</span>-y_hat)) / <span class="built_in">len</span>(y)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">dj</span>(<span class="params">theta, X_b, y</span>):</span></span><br><span class="line">            <span class="keyword">return</span> X_b.T.dot(self._sigmoid(X_b.dot(theta)) - y) / <span class="built_in">len</span>(X_b)</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">gradient_descent</span>(<span class="params">X_b, y, init_theta, eta, n_iters=<span class="number">1e4</span>, epsilon=<span class="number">1e-8</span></span>):</span></span><br><span class="line"></span><br><span class="line">            theta = init_theta</span><br><span class="line">            i_iter = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> i_iter &lt; n_iters:</span><br><span class="line">                gradient = dj(theta, X_b, y)</span><br><span class="line">                last_theta = theta</span><br><span class="line">                theta = last_theta - eta * gradient</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (<span class="built_in">abs</span>(J(theta, X_b, y) - J(last_theta, X_b, y)) &lt; epsilon):</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">                i_iter += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> theta</span><br><span class="line"></span><br><span class="line">        X_b = np.hstack([np.ones((<span class="built_in">len</span>(x_train), <span class="number">1</span>)), x_train])</span><br><span class="line">        init_theta = np.zeros(X_b.shape[<span class="number">1</span>])</span><br><span class="line">        self._theta = gradient_descent(X_b, y_train, init_theta, eta, n_iters=<span class="number">1e4</span>)</span><br><span class="line">        self.interception_ = self._theta[<span class="number">0</span>]</span><br><span class="line">        self.coef_ = self._theta[<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict_prob</span>(<span class="params">self, x_predict</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> self.interception_ <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> self.coef_ <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>, <span class="string">&quot;must fit before predict&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> x_predict.shape[<span class="number">1</span>] == <span class="built_in">len</span>(self.coef_), <span class="string">&quot;the feature number must be equal to x_train&quot;</span></span><br><span class="line"></span><br><span class="line">        X = np.hstack([np.ones((<span class="built_in">len</span>(x_predict), <span class="number">1</span>)), x_predict])</span><br><span class="line">        <span class="keyword">return</span> self._sigmoid(X.dot(self._theta))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, x_predict</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> self.interception_ <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> self.coef_ <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>, <span class="string">&quot;must fit before predict&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> x_predict.shape[<span class="number">1</span>] == <span class="built_in">len</span>(self.coef_), <span class="string">&quot;the feature number must be equal to x_train&quot;</span></span><br><span class="line"></span><br><span class="line">        prob = self.predict_prob(x_predict)</span><br><span class="line">        <span class="keyword">return</span> np.array(prob &gt;= <span class="number">0.5</span>, dtype=<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span>(<span class="params">self, x_test, y_test</span>):</span></span><br><span class="line">        y_predict = self.predict(x_test)</span><br><span class="line">        <span class="keyword">assert</span> y_test.shape[<span class="number">0</span>] == y_predict.shape[<span class="number">0</span>], \</span><br><span class="line">            <span class="string">&quot;the size of y_true must be equal to the size of y_predict&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(y_test == y_predict) / <span class="built_in">len</span>(y_test)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Logistic Regression&quot;</span></span><br></pre></td></tr></table></figure><p>测试一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">x = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line">x = x[y&lt;<span class="number">2</span>, :<span class="number">2</span>]</span><br><span class="line">y = y[y&lt;<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">666</span>)</span><br><span class="line">log_reg = LogisticRegression()</span><br><span class="line">log_reg.fit(x_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(log_reg.score(x_test, y_test))</span><br><span class="line"><span class="built_in">print</span>(log_reg.predict_prob(x_test))</span><br><span class="line"><span class="built_in">print</span>(y_test)</span><br><span class="line"><span class="built_in">print</span>(log_reg.coef_)</span><br><span class="line"><span class="built_in">print</span>(log_reg.interception_)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/69e23b14a73c48e48b495f01712fc7f4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="决策边界"><a href="#决策边界" class="headerlink" title="决策边界"></a>决策边界</h1><h2 id="逻辑回归的决策边界"><a href="#逻辑回归的决策边界" class="headerlink" title="逻辑回归的决策边界"></a>逻辑回归的决策边界</h2><p>首先回顾一下Logistic Regression进行分类的原理：<br><img src="https://img-blog.csdnimg.cn/ca879ffe42024be4b3286d32414effb1.png"><br>接下来再看一下Sigmoid这个函数:<br><img src="https://img-blog.csdnimg.cn/4327a7c146664baabd550ace33e23787.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/b87b02b0fad54d9186eda5a02b8e4be6.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">x2</span>(<span class="params">x1</span>):</span>     </span><br><span class="line">    <span class="keyword">return</span> (-log_reg.coef_[<span class="number">0</span>] * x1 - log_reg.interception_) / log_reg.coef_[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">x1_plot = np.linspace(<span class="number">4</span>, <span class="number">8</span>, <span class="number">1000</span>)</span><br><span class="line">x2_plot= x2(x1_plot)</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.plot(x1_plot, x2_plot)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/a8733b26d7a74173a99347bb1ff21ac1.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16"><br>第四节预测明明是100%的准确率为什么还会有个红点在决策边界下方呢？因为这里绘图用的是全部数据。而测试时用的是测试集（说明训练集不是100%正确率）。<br>把绘制决策边界封装为一个函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_decision_boundary</span>(<span class="params">model, axis</span>):</span></span><br><span class="line">    x0, x1 = np.meshgrid(np.linspace(axis[<span class="number">0</span>], axis[<span class="number">1</span>], <span class="built_in">int</span>((axis[<span class="number">1</span>] - axis[<span class="number">0</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),</span><br><span class="line">                         np.linspace(axis[<span class="number">2</span>], axis[<span class="number">3</span>], <span class="built_in">int</span>((axis[<span class="number">3</span>] - axis[<span class="number">2</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),)</span><br><span class="line">    x_new = np.c_[x0.ravel(), x1.ravel()]</span><br><span class="line">    y_predict = model.predict(x_new)</span><br><span class="line">    zz = y_predict.reshape(x0.shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line">    custom_cmap = ListedColormap([<span class="string">&#x27;#EF9A9A&#x27;</span>, <span class="string">&#x27;#FFF59D&#x27;</span>, <span class="string">&#x27;#90CAF9&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    plt.contourf(x0, x1, zz, linewidth=<span class="number">5</span>, cmap=custom_cmap)</span><br><span class="line">plot_decision_boundary(log_reg, axis=[<span class="number">4</span>, <span class="number">7.5</span>, <span class="number">1.5</span>, <span class="number">4.5</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/e9ef80178089454399b82845e0cc2e3e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="KNN的决策边界"><a href="#KNN的决策边界" class="headerlink" title="KNN的决策边界"></a>KNN的决策边界</h2><ul><li>第一种情况，knn作用在两个类别上：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">knn_clf = KNeighborsClassifier()</span><br><span class="line">knn_clf.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">knn_clf.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 1.0</span></span><br><span class="line">plot_decision_boundary(knn_clf, axis=[<span class="number">4</span>, <span class="number">7.5</span>, <span class="number">1.5</span>, <span class="number">4.5</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/84bd03dce3264566884c241acac073b0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p><ul><li>第二种情况，knn作用在三个类别上：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">knn_clf_all = KNeighborsClassifier()</span><br><span class="line">knn_clf_all.fit(iris.data[:,:<span class="number">2</span>], iris.target)</span><br><span class="line"><span class="comment">#KNeighborsClassifier(algorithm=&#x27;auto&#x27;, leaf_size=30, metric=&#x27;minkowski&#x27;,</span></span><br><span class="line"><span class="comment">#          metric_params=None, n_jobs=None, n_neighbors=5, p=2,</span></span><br><span class="line"><span class="comment">#          weights=&#x27;uniform&#x27;)</span></span><br><span class="line"></span><br><span class="line">plot_decision_boundary(knn_clf_all, axis=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">1.5</span>, <span class="number">4.5</span>])</span><br><span class="line">plt.scatter(iris.data[iris.target==<span class="number">0</span>, <span class="number">0</span>], iris.data[iris.target==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(iris.data[iris.target==<span class="number">1</span>, <span class="number">0</span>], iris.data[iris.target==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(iris.data[iris.target==<span class="number">2</span>, <span class="number">0</span>], iris.data[iris.target==<span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/0c4410e79a53468582d357cfe0423183.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="逻辑回归中使用多项式特征"><a href="#逻辑回归中使用多项式特征" class="headerlink" title="逻辑回归中使用多项式特征"></a>逻辑回归中使用多项式特征</h1><p>​ 逻辑回归中如果使用直线分类方式就只能针对二分类了，如果像下图中不可能使用一根直线完成分割，但是很显然可以使用圆形或者椭圆形完整这个分类任务。其实在线性回归到多项式回归我们思想就是给训练数据集添加多项式项。同理我们把这个东西用到逻辑回归中。<br><img src="https://img-blog.csdnimg.cn/4bf42a91df224ba39468ccc5c003cbf3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>首先生成需要的数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">666</span>)</span><br><span class="line">x = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, size=(<span class="number">200</span>, <span class="number">2</span>))</span><br><span class="line">y = np.array(x[:,<span class="number">0</span>] ** <span class="number">2</span> + x[:,<span class="number">1</span>] ** <span class="number">2</span> &lt; <span class="number">1.5</span>, dtype=<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/657cf95c4cc4409c9dfe91af9e778273.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>对于这样一个样本集首先使用没有多项式特征逻辑回归试一下效果如何？<br><img src="https://img-blog.csdnimg.cn/249f51c1500549f697c05ff3aa3db474.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16"><br>显然有很多错误的分类，那接下来给逻辑回归添加多项式特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PolynomiaLogisticRegression</span>(<span class="params">degree</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Pipeline([</span><br><span class="line">        (<span class="string">&#x27;poly&#x27;</span>, PolynomialFeatures(degree=degree)),</span><br><span class="line">        (<span class="string">&#x27;std_scale&#x27;</span>, StandardScaler()),</span><br><span class="line">        (<span class="string">&#x27;log_reg&#x27;</span>, LogisticRegression())</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">poly_log_reg = PolynomiaLogisticRegression(degree=<span class="number">2</span>)</span><br><span class="line">poly_log_reg.fit(x, y)</span><br><span class="line">poly_log_reg.score(x, y)</span><br><span class="line"><span class="comment"># 0.94999999999999996</span></span><br><span class="line">plot_decision_boundary(poly_log_reg, axis=[-<span class="number">4</span>, <span class="number">4</span>, -<span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/3294703dbe924942aabd1d010767d8ea.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"><br>接下来把degree调大，试一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">poly_log_reg2 = PolynomiaLogisticRegression(degree=<span class="number">20</span>)</span><br><span class="line">poly_log_reg2.fit(x, y)</span><br><span class="line"></span><br><span class="line">plot_decision_boundary(poly_log_reg2, axis=[-<span class="number">4</span>, <span class="number">4</span>, -<span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>出现这样的边界形状是因为发生了过拟合现象，degree越来模型越复杂，也就越容易发生过拟合。接下来我们就来解决这个过拟合问题。这里使用模型正则化。出现这样的边界形状是因为发生了过拟合现象，degree越来模型越复杂，也就越容易发生过拟合。接下来我们就来解决这个过拟合问题。这里使用模型正则化。</p><hr><h1 id="逻辑回归中使用正则化"><a href="#逻辑回归中使用正则化" class="headerlink" title="逻辑回归中使用正则化"></a>逻辑回归中使用正则化</h1><p> 在实际的应用过程中，很少有问题直接用直线就能完成分类或者回归任务，因此正则化必不可少。之前学过模型泛化的时候提到的L1正则、L2正则化的方式：<br><img src="https://img-blog.csdnimg.cn/98b43ba031b4433faaac04711c00902a.png"><br>但是在sklearn中对逻辑回归中的正则化：<br><img src="https://img-blog.csdnimg.cn/24e0a95460ea41278251794c759df067.png"></p><ul><li><strong>先使用直线逻辑回归</strong><br>接下来看看sklearn中的逻辑回归是如何加入正则化的。还是先生成样本数据：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">666</span>)</span><br><span class="line">x = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, size=(<span class="number">200</span>, <span class="number">2</span>))</span><br><span class="line">y = np.array(x[:,<span class="number">0</span>] ** <span class="number">2</span> + x[:,<span class="number">1</span>] &lt; <span class="number">1.5</span>, dtype=<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加一些噪音。</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">    y[np.random.randint(<span class="number">200</span>)] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/8784061ea90b4c15a7c94b0f6d1ddb05.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y)</span><br><span class="line">log_reg = LogisticRegression()</span><br><span class="line">log_reg.fit(x, y)</span><br><span class="line"><span class="comment"># LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,</span></span><br><span class="line"><span class="comment">#          intercept_scaling=1, max_iter=100, multi_class=&#x27;warn&#x27;,</span></span><br><span class="line"><span class="comment">#         n_jobs=None, penalty=&#x27;l2&#x27;, random_state=None, solver=&#x27;warn&#x27;,</span></span><br><span class="line"><span class="comment">#          tol=0.0001, verbose=0, warm_start=False)</span></span><br></pre></td></tr></table></figure><p>通过输出结果我们可以发现默认C=1.0，这个C就是最开始提到的逻辑回归中正则中的C，penalty=’l2’说明sklearn默认使用L2正则来进行模型正则化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">log_reg.score(x_train, y_train)</span><br><span class="line"><span class="comment"># 0.7933333333333333</span></span><br><span class="line">log_reg.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.7933333333333333</span></span><br><span class="line">plot_decision_boundary(log_reg, axis=[-<span class="number">4</span>, <span class="number">4</span>, -<span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/40cd3174570b4ddf8fca0c22b6b61c42.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16"></p><ul><li><strong>使用多项式Logistic Regression</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PolynomiaLogisticRegression</span>(<span class="params">degree</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Pipeline([</span><br><span class="line">        (<span class="string">&#x27;poly&#x27;</span>, PolynomialFeatures(degree=degree)),</span><br><span class="line">        (<span class="string">&#x27;std_scale&#x27;</span>, StandardScaler()),</span><br><span class="line">        (<span class="string">&#x27;log_reg&#x27;</span>, LogisticRegression())</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">poly_log_reg = PolynomiaLogisticRegression(degree=<span class="number">2</span>)</span><br><span class="line">poly_log_reg.fit(x_train, y_train)</span><br><span class="line">poly_log_reg.score(x_train, y_train)</span><br><span class="line"><span class="comment"># 0.9133333333333333</span></span><br><span class="line">poly_log_reg.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.94</span></span><br><span class="line">plot_decision_boundary(poly_log_reg, axis=[-<span class="number">4</span>, <span class="number">4</span>, -<span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/bc05e18e62a24069aae345f2c35a7d54.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">poly_log_reg2 = PolynomiaLogisticRegression(degree=<span class="number">20</span>)</span><br><span class="line">poly_log_reg2.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">poly_log_reg2.score(x_train, y_train)</span><br><span class="line"><span class="comment"># 0.94</span></span><br><span class="line">poly_log_reg2.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.92</span></span><br><span class="line">plot_decision_boundary(poly_log_reg2, axis=[-<span class="number">4</span>, <span class="number">4</span>, -<span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/40e1a07b45414f878bed9c8c31014aa2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p><ul><li><strong>调整参数C</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 传入一个新的参数C</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PolynomiaLogisticRegression</span>(<span class="params">degree, C</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Pipeline([</span><br><span class="line">        (<span class="string">&#x27;poly&#x27;</span>, PolynomialFeatures(degree=degree)),</span><br><span class="line">        (<span class="string">&#x27;std_scale&#x27;</span>, StandardScaler()),</span><br><span class="line">        (<span class="string">&#x27;log_reg&#x27;</span>, LogisticRegression(C=C))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">poly_log_reg3 = PolynomiaLogisticRegression(degree=<span class="number">20</span>, C=<span class="number">0.1</span>)</span><br><span class="line">poly_log_reg3.fit(x, y)</span><br><span class="line"></span><br><span class="line">poly_log_reg3.score(x_train, y_train)</span><br><span class="line"><span class="comment"># 0.8533333333333334</span></span><br><span class="line">poly_log_reg3.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.92</span></span><br><span class="line">plot_decision_boundary(poly_log_reg3, axis=[-<span class="number">4</span>, <span class="number">4</span>, -<span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/e798bda7e8ac40cf9a8d0d860de222b6.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="逻辑回归解决多分类问题"><a href="#逻辑回归解决多分类问题" class="headerlink" title="逻辑回归解决多分类问题"></a>逻辑回归解决多分类问题</h1><p> 在开始之初，说逻辑回归只可以解决二分类问题， 其实可以稍加改造使其能够解决多分类问题。当然这个改造方式并不是只针对逻辑回归这一种算法，这是一种通用的近乎于可以改造所有的二分类。</p><h2 id="OvR"><a href="#OvR" class="headerlink" title="OvR"></a>OvR</h2><p> （One vs Rest）一对剩余，有些说法也叫（One vs All，OVA）。比如下图中的这个四分类问题，显然如果使用逻辑回归一条直线分出4类是不现实的，但是如果我们取出其中任意一种，将剩下的作为另一种，这种就是一个2分类问题，同理将每一个类别分别做一次这样的2分类，如果有n个类别就进行n次分类，选择分类得分最高的。就类似于下图这种，进行C（n，1）中分类。从而完成多分类。<br> <img src="https://img-blog.csdnimg.cn/1f7fc283a6f24641a3f9774578332445.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="OvO"><a href="#OvO" class="headerlink" title="OvO"></a>OvO</h2><p>（One vs One）一对一，就是在多个类别中，先挑出2个来进行2分类，然后逐个进行，也就是C（n，2）中情况进行2分类，选择赢数最高的分类。比如一个手写数字的识别任务来说就要进行C（10,2）=45次分类，才能完成任务。很显然它相比OvR（n级别）来说，OvO这是一个n<sup>2</sup>级别的，要比耗时更多，但是它分类的结果更加准确。这是因为每次都是在用两个真实的类别再进行2分类，而没有混淆其他的类别信息。<br><img src="https://img-blog.csdnimg.cn/98282af1d03247fe97ed5bab9ee14f5f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="Logistic-Regression的OvR和OvO的编程实现"><a href="#Logistic-Regression的OvR和OvO的编程实现" class="headerlink" title="Logistic Regression的OvR和OvO的编程实现"></a>Logistic Regression的OvR和OvO的编程实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_decision_boundary</span>(<span class="params">model, axis</span>):</span></span><br><span class="line">    x0, x1 = np.meshgrid(np.linspace(axis[<span class="number">0</span>], axis[<span class="number">1</span>], <span class="built_in">int</span>((axis[<span class="number">1</span>] - axis[<span class="number">0</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),</span><br><span class="line">                         np.linspace(axis[<span class="number">2</span>], axis[<span class="number">3</span>], <span class="built_in">int</span>((axis[<span class="number">3</span>] - axis[<span class="number">2</span>])*<span class="number">100</span>)).reshape(<span class="number">1</span>, -<span class="number">1</span>),)</span><br><span class="line">    x_new = np.c_[x0.ravel(), x1.ravel()]</span><br><span class="line">    y_predict = model.predict(x_new)</span><br><span class="line">    zz = y_predict.reshape(x0.shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line">    custom_cmap = ListedColormap([<span class="string">&#x27;#EF9A9A&#x27;</span>, <span class="string">&#x27;#FFF59D&#x27;</span>, <span class="string">&#x27;#90CAF9&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    plt.contourf(x0, x1, zz, linewidth=<span class="number">5</span>, cmap=custom_cmap)</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">x = iris.data[:, :<span class="number">2</span>]</span><br><span class="line">y = iris.target</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">666</span>)</span><br><span class="line"></span><br><span class="line">log_reg = LogisticRegression()</span><br><span class="line">log_reg.fit(x_train, y_train)</span><br><span class="line"><span class="comment"># LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,</span></span><br><span class="line"><span class="comment">#          intercept_scaling=1, max_iter=100, multi_class=&#x27;warn&#x27;,</span></span><br><span class="line"><span class="comment">#          n_jobs=None, penalty=&#x27;l2&#x27;, random_state=None, solver=&#x27;warn&#x27;,</span></span><br><span class="line"><span class="comment">#          tol=0.0001, verbose=0, warm_start=False)</span></span><br></pre></td></tr></table></figure><p>从输出结果来看，这个multi_class=’warn’,这个multi_class就是多分类的意思，从官方文档来看默认是OvR，solver这个参数是因为在sklearn中并不是简单地使用梯度下降，因此我们需要给不同的方法传入不同的解决办法。</p><ul><li>OvR</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">log_reg = LogisticRegression(multi_class=<span class="string">&#x27;ovr&#x27;</span>,solver=<span class="string">&#x27;liblinear&#x27;</span>)</span><br><span class="line">log_reg.fit(x_train, y_train)</span><br><span class="line">log_reg.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.6578947368421053</span></span><br><span class="line">plot_decision_boundary(log_reg, axis=[<span class="number">4</span>, <span class="number">8.5</span>, <span class="number">1.5</span>, <span class="number">4.5</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">2</span>, <span class="number">0</span>], x[y==<span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/c15e174b3ab346f8b65bf37dbc9f6288.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><ul><li>OvO</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">log_reg2 = LogisticRegression(multi_class=<span class="string">&#x27;multinomial&#x27;</span>, solver=<span class="string">&#x27;newton-cg&#x27;</span>)</span><br><span class="line">log_reg2.fit(x_train, y_train)</span><br><span class="line"><span class="comment"># 0.7894736842105263</span></span><br><span class="line">plot_decision_boundary(log_reg2, axis=[<span class="number">4</span>, <span class="number">8.5</span>, <span class="number">1.5</span>, <span class="number">4.5</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">0</span>, <span class="number">0</span>], x[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">1</span>, <span class="number">0</span>], x[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(x[y==<span class="number">2</span>, <span class="number">0</span>], x[y==<span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/8a1d173ac2474aaa81f1fe14013ea0da.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16">通过上面这两个示例发现准确率并不高，这是因为鸢尾花数据集共有4个特征，而只用了前两个,为了方便可视化，下面就是使用所有数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">iris = datasets.load_iris()</span><br><span class="line">x = iris.data[:, :]</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">666</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># OvR</span></span><br><span class="line">log_reg3 = LogisticRegression(multi_class=<span class="string">&#x27;ovr&#x27;</span>, solver=<span class="string">&#x27;liblinear&#x27;</span>)</span><br><span class="line">log_reg3.fit(x_train, y_train)</span><br><span class="line">log_reg3.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.9473684210526315</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># OvO</span></span><br><span class="line">log_reg4 = LogisticRegression(multi_class=<span class="string">&#x27;multinomial&#x27;</span>, solver=<span class="string">&#x27;newton-cg&#x27;</span>)</span><br><span class="line">log_reg4.fit(x_train, y_train)</span><br><span class="line">log_reg4.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 1.0</span></span><br></pre></td></tr></table></figure><h2 id="sklearn中的OvR和OvO"><a href="#sklearn中的OvR和OvO" class="headerlink" title="sklearn中的OvR和OvO"></a>sklearn中的OvR和OvO</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">log_reg = LogisticRegression()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.multiclass <span class="keyword">import</span> OneVsRestClassifier</span><br><span class="line"></span><br><span class="line">ovr = OneVsRestClassifier(log_reg)</span><br><span class="line">ovr.fit(x_train, y_train)</span><br><span class="line"><span class="comment"># OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, </span></span><br><span class="line"><span class="comment"># dual=False, fit_intercept=True,</span></span><br><span class="line"><span class="comment">#          intercept_scaling=1, max_iter=100, multi_class=&#x27;ovr&#x27;,</span></span><br><span class="line"><span class="comment">#          n_jobs=None, penalty=&#x27;l2&#x27;, random_state=None, solver=&#x27;liblinear&#x27;,</span></span><br><span class="line"><span class="comment">#          tol=0.0001, verbose=0, warm_start=False),</span></span><br><span class="line"><span class="comment">#          n_jobs=None)</span></span><br><span class="line">ovr.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 0.9473684210526315</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.multiclass <span class="keyword">import</span> OneVsOneClassifier</span><br><span class="line"></span><br><span class="line">ovo = OneVsOneClassifier(log_reg)</span><br><span class="line">ovo.fit(x_train, y_train)</span><br><span class="line"><span class="comment"># OneVsOneClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, </span></span><br><span class="line"><span class="comment"># dual=False, fit_intercept=True,</span></span><br><span class="line"><span class="comment">#          intercept_scaling=1, max_iter=100, multi_class=&#x27;multinomial&#x27;,</span></span><br><span class="line"><span class="comment">#          n_jobs=None, penalty=&#x27;l2&#x27;, random_state=None, solver=&#x27;newton-cg&#x27;,</span></span><br><span class="line"><span class="comment">#          tol=0.0001, verbose=0, warm_start=False),</span></span><br><span class="line"><span class="comment">#          n_jobs=None)</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 逻辑回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习(五)——模型泛化</title>
      <link href="/2021/12/02/ML5_%E6%A8%A1%E5%9E%8B%E6%B3%9B%E5%8C%96/"/>
      <url>/2021/12/02/ML5_%E6%A8%A1%E5%9E%8B%E6%B3%9B%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>众所周知，考试前会刷题。但是考试大部分又不是原题，那考前刷题有什么用？我们考前做的题目的当然不是为了赌考试有一模一样的题（有可能也是。。。），我们是为了从题目中学到一般的知识，这样我们在遇到新题目的时候也可以根据知识来做出题目。其实在机器学习中，考前刷的题就是训练集，考试中的题就是我们模型之后遇到的新样本，而泛化就是我们的模型遇到新样本的表现（也就对应着考试的分数）。</p><span id="more"></span><hr><h1 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h1><p>在我们训练完模型之后，我们肯定是想看模型的泛化是怎么样的。一般的做法就是把数据集分为训练集和测试集，我们用训练集训练模型，用测试集测试模型的泛化能力。我们还会根据测试集的准确率来调整模型。<br><img src="https://img-blog.csdnimg.cn/88e2b96315a948728c1be45da5eac9c9.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>但这样又遇到一个问题，那就是如果根据测试集来调整模型，那么模型很可能就会在测试集上过拟合，或者说这样做的话，就无法体现模型的泛化能力了。<br>所以更多的做法，是将数据集分为训练集、验证集、测试集。通过训练集训练模型，验证集调整模型，测试集测试模型的泛化能力。<br><img src="https://img-blog.csdnimg.cn/a789149c47dc4593a40024f096ab13bc.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>但是验证集也有随机性，很可能因为这一份验证集而产生过拟合，所以又产生了交叉验证。<br><img src="https://img-blog.csdnimg.cn/e6cb60c50a274fc6bb6484b31389ff9d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="交叉验证"><br> 我们将训练数据随机分为k份，上图中分为k=3份，将任意两种组合作为训练集，剩下的一组作为验证集，这样就得到k个模型，然后在将k个模型的均值作为结果调参。显然这种方式要比随机只用一份数据集作为验证集要靠谱的多。<br>下面用实际的例子，来了解一下如何使用交叉验证调参：</p><ul><li>第一种情况：只使用训练集测试集测试：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line">x = digits.data</span><br><span class="line">y = digits.target</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.4</span>, random_state=<span class="number">666</span>)</span><br><span class="line"></span><br><span class="line">best_score, best_p, best_k = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span> </span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">11</span>):</span><br><span class="line">    <span class="keyword">for</span>  p <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>):</span><br><span class="line">        knn_clf = KNeighborsClassifier(weights=<span class="string">&quot;distance&quot;</span>, n_neighbors=k, p=p)</span><br><span class="line">        knn_clf.fit(x_train, y_train)</span><br><span class="line">        score = knn_clf.score(x_test, y_test)</span><br><span class="line">        <span class="keyword">if</span> score &gt; best_score:</span><br><span class="line">            best_score, best_p, best_k = score, p, k</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best K=&quot;</span>, best_k)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best P=&quot;</span>, best_p)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best score=&quot;</span>, best_score)</span><br></pre></td></tr></table></figure><p>输出结果</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Best K= 3</span><br><span class="line">Best P= 2</span><br><span class="line">Best score= 0.9860917941585535</span><br></pre></td></tr></table></figure><ul><li>第二种情况：使用交叉验证</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"></span><br><span class="line">knn_clf = KNeighborsClassifier()</span><br><span class="line">cross_val_score(knn_clf, x_train, y_train)</span><br><span class="line"><span class="comment"># array([0.99537037, 0.98148148, 0.97685185, 0.97674419, 0.97209302])</span></span><br></pre></td></tr></table></figure><p>根据输出结果，默认情况下 <code>sklearn</code> 包的交叉验证是分为 <code>5</code> 份，也可以通过 <code>cv</code> 参数修改。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">best_score, best_p, best_k = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span> </span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">11</span>):</span><br><span class="line">    <span class="keyword">for</span>  p <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>):</span><br><span class="line">        knn_clf = KNeighborsClassifier(weights=<span class="string">&quot;distance&quot;</span>, n_neighbors=k, p=p)</span><br><span class="line">        scores = cross_val_score(knn_clf, x_train, y_train)</span><br><span class="line">        score = np.mean(scores)</span><br><span class="line">        <span class="keyword">if</span> score &gt; best_score:</span><br><span class="line">            best_score, best_p, best_k = score, p, k</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best K=&quot;</span>, best_k)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best P=&quot;</span>, best_p)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best score=&quot;</span>, best_score)</span><br></pre></td></tr></table></figure><p>输出结果</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Best K= 2</span><br><span class="line">Best P= 2</span><br><span class="line">Best score= 0.9851507321274763</span><br></pre></td></tr></table></figure><p>从输出结果可以看出，选择的参数和之前不一样了，虽然分数下降了点，但使用交叉验证的更可靠。当然这里不是模型的测试分数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">best_knn_clf = KNeighborsClassifier(weights=<span class="string">&#x27;distance&#x27;</span>, n_neighbors=<span class="number">2</span>, p=<span class="number">2</span>)</span><br><span class="line">best_knn_clf.fit(x_train, y_train)</span><br><span class="line">best_knn_clf.score(x_test, y_test)</span><br></pre></td></tr></table></figure><p>输出结果 <code>0.980528511821975</code> 才是测试分数。</p><hr><h1 id="偏差方差权衡"><a href="#偏差方差权衡" class="headerlink" title="偏差方差权衡"></a>偏差方差权衡</h1><blockquote><p>偏差方差权衡（Bias Variance Trade off），当我们的模型表现不佳时，通常是出现两种问题，一种是 高偏差 问题，另一种是<br>高方差 问题。识别它们有助于选择正确的优化方式，所以我们先来看下 偏差 与 方差 的意义。</p></blockquote><ul><li><strong>偏差</strong>: 描述模型输出结果的期望与样本真实结果的差距。</li><li><strong>方差</strong>: 描述模型对于给定值的输出稳定性。 方差越大模型的泛华能力越弱。</li></ul><p><img src="https://img-blog.csdnimg.cn/023f2f98afb54e7f924dbf4f65c10411.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>就像打靶一样，偏差描述了我们的射击总体是否偏离了我们的目标，而方差描述了射击准不准。左一是方差跟偏差都很小，都比较靠近中心且集中，右一分散在中心附近，但比较散，因此方差较大。这样结合下面这两幅图就可以大概理解，偏差描述的是描述模型输出结果的期望与样本真实结果的差距。而方差则是对于输出结果是否集中，描述模型对于给定值的输出稳定性。</p><p><strong>模型误差 = 偏差 + 方差 + 不可避免的误差</strong></p><ul><li>导致偏差大的原因：对问题本身的假设不正确！如非线性数据使用线性回归。或者特征对应标记高度不相关也会导致高偏差，不过这是对应着特征选择，跟算法没有关系，对于算法而言基本属于欠拟合问题<code>underfitting</code>。</li><li>导致方差大的原因：数据的一点点扰动都会极大地影响模型。通常原因就是使用的模型太复杂，如高阶多项式回归。这就是所说的过拟合（<code>overfitting</code>）</li><li>总结：有些算法天生就是高方差的算法，如KNN，非参数学习的算法通常都是高方差的，因为不对数据进行任何假设。还有一些算法天生就是高偏差的，如线性回归。参数学习通常都是高偏差算法，因为对数据具有极强的假设。大多数算法具有相应的算法可以调整偏差和方差，如KNN中的k，如线性回归中使用多项式回归中的degree，偏差和方差通常是矛盾的，降低偏差，会提高方差，降低方差，会提高偏差，因此在实际应用中需要进行权衡。机器学习的主要挑战，在于方差。这句话只针对算法，并不针对实际问题。因为大多数机器学习需要解决过拟合问题。</li></ul><p><strong>解决手段</strong>：</p><ul><li>降低模型复杂度</li><li>减少数据维度；降噪</li><li>增加样本数量</li><li>使用验证集</li><li><strong>模型正则化</strong></li></ul><hr><h1 id="模型正则化"><a href="#模型正则化" class="headerlink" title="模型正则化"></a>模型正则化</h1><p>模型正则化（<code>Regularization</code>）：限制参数的大小。常常用来解决过拟合问题。<br>先看一下多项式回归过拟合的情况：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PolynomiaRegression</span>(<span class="params">degree</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Pipeline([</span><br><span class="line">        (<span class="string">&#x27;poly&#x27;</span>, PolynomialFeatures(degree=degree)),</span><br><span class="line">        (<span class="string">&#x27;std_scale&#x27;</span>, StandardScaler()),</span><br><span class="line">        (<span class="string">&#x27;lin_reg&#x27;</span>, LinearRegression()),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">666</span>)</span><br><span class="line">x = np.random.uniform(-<span class="number">3.0</span>, <span class="number">3.0</span>, size=<span class="number">100</span>)</span><br><span class="line">X = x.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = <span class="number">0.5</span> * x**<span class="number">2</span> + x + <span class="number">2</span> + np.random.normal(<span class="number">0</span>, <span class="number">1</span>, size=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">poly100_reg = PolynomiaRegression(degree=<span class="number">100</span>)</span><br><span class="line">poly100_reg.fit(X, y)</span><br><span class="line">y100_predict = poly100_reg.predict(X)</span><br><span class="line">mean_squared_error(y, y100_predict)</span><br><span class="line"><span class="comment"># 0.687293250556113</span></span><br><span class="line">x_plot = np.linspace(-<span class="number">3</span>, <span class="number">3</span>, <span class="number">100</span>).reshape(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line">y_plot = poly100_reg.predict(x_plot)</span><br><span class="line"></span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.plot(x_plot[:,<span class="number">0</span>], y_plot, color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.axis([-<span class="number">3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">10</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/915bd3a61f4248c286861b2625cc3cff.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16" alt="过拟合"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">lin_reg.coef_</span><br><span class="line">array([ 1.21093453e+12,  1.19203091e+01,  1.78867645e+02, -2.95982349e+02,</span><br><span class="line">       -1.79531458e+04, -1.54155027e+04,  8.34383276e+05,  8.19774042e+05,</span><br><span class="line">       -2.23627851e+07, -1.44771550e+07,  3.87211418e+08,  1.13421075e+08,</span><br><span class="line">       -4.61600312e+09, -1.25081501e+08,  3.93150405e+10, -5.47576783e+09,</span><br><span class="line">       -2.44176251e+11,  5.46288687e+10,  1.11421043e+12, -2.76406464e+11,</span><br><span class="line">       -3.71329259e+12,  8.55454910e+11,  8.80960804e+12, -1.60748867e+12,</span><br><span class="line">       -1.39204160e+13,  1.49444708e+12,  1.19236879e+13,  2.47473079e+11,</span><br><span class="line">        4.42409192e+11, -1.64280931e+12, -1.05153597e+13, -1.80898849e+11,</span><br><span class="line">        3.00205050e+12,  2.75573418e+12,  8.74124346e+12, -1.36695399e+12,</span><br><span class="line">       -1.22671920e+12, -7.00432918e+11, -8.24895441e+12, -8.66296096e+11,</span><br><span class="line">       -2.75689092e+12,  1.39625207e+12,  6.26145077e+12, -3.47996080e+11,</span><br><span class="line">        6.29123725e+12,  1.33768276e+12, -6.11902468e+11,  2.92339251e+11,</span><br><span class="line">       -6.59758587e+12, -1.85663192e+12, -4.13408727e+12, -9.72012430e+11,</span><br><span class="line">       -3.99030817e+11, -7.53702123e+11,  5.49214630e+12,  2.18518119e+12,</span><br><span class="line">        5.24341931e+12,  7.50251523e+11,  5.50252585e+11,  1.70649474e+12,</span><br><span class="line">       -2.26789998e+12, -1.84570078e+11, -5.47302714e+12, -2.86219945e+12,</span><br><span class="line">       -3.88076411e+12, -1.19593780e+12,  1.16315909e+12, -1.41082803e+12,</span><br><span class="line">        3.56349186e+12,  7.12308678e+11,  4.76397106e+12,  2.60002465e+12,</span><br><span class="line">        1.84222952e+12,  3.06319895e+12, -1.33316498e+12,  6.18544545e+11,</span><br><span class="line">       -2.64567691e+12, -1.01424838e+12, -4.76743525e+12, -3.59230293e+12,</span><br><span class="line">       -1.68055178e+12, -3.57480827e+12,  2.06629318e+12, -6.07564696e+11,</span><br><span class="line">        3.40446395e+12,  3.42181387e+12,  3.31399498e+12,  4.92290870e+12,</span><br><span class="line">        3.79985951e+11,  1.34189037e+12, -3.34878352e+12, -2.07865615e+12,</span><br><span class="line">       -3.24634078e+12, -5.48903768e+12,  5.87242630e+11, -2.27318874e+12,</span><br><span class="line">        2.60023097e+12,  8.21820883e+12,  4.79532121e+10, -3.11436610e+12,</span><br><span class="line">       -6.27736909e+11])</span><br></pre></td></tr></table></figure><p>通过查看多项式回归的系数可以发现，有些系数能差13个数量级，其实这就是过拟合了！而模型正则化就是为了解决这个问题。先来回顾一下多项式回归的目标。<br><img src="https://img-blog.csdnimg.cn/88fc0ddfe5d9456faefda0a237676c09.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>通过加入的正则项来控制系数不要太大，从而使曲线不要那么陡峭，变化的那么剧烈。在这里有几个细节需要注意。</p><ul><li>第一点：θ从1开始，只包含系数不包括截距，这是因为截距只决定曲线的高低，并不会影响曲线的陡峭和缓和。</li><li>第2点：就是这个 <code>1/2</code>，是为了求导之后能够将2消去，为了方便计算。不过其实这个有没有都是可以的，因为在正则化前有一个系数，我们可以把这个 <code>1/2</code> 可以考虑到 <code>ɑ</code>中去。</li><li>第3点：系数<code>ɑ</code>，它表示正则化项在整个损失函数中所占的比例。极端一下，<code>ɑ</code>=0时，相当于模型没有加入正则化，但如果<code>ɑ</code>= 正无穷，此时其实主要的优化任务就变成了需要所有的<code>ɑ</code>都尽可能的小，最优的情况就是全为0。至于<code>ɑ</code>的取值就需要尝试了。</li></ul><h2 id="岭回归（Ridege-Regression）"><a href="#岭回归（Ridege-Regression）" class="headerlink" title="岭回归（Ridege Regression）"></a>岭回归（Ridege Regression）</h2><p><img src="https://img-blog.csdnimg.cn/85d27c23008042acbed7d5b393d3953b.png"><br>测试用例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line">x = np.random.uniform(-<span class="number">3.0</span>, <span class="number">3.0</span>, size=<span class="number">100</span>)</span><br><span class="line">X = x.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = <span class="number">0.5</span> * x + <span class="number">3</span> + np.random.normal(<span class="number">0</span>, <span class="number">1</span>, size=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/b1aa132c365c4aceb4a6017c71feaa5f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PolynomiaRegression</span>(<span class="params">degree</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Pipeline([</span><br><span class="line">        (<span class="string">&#x27;poly&#x27;</span>, PolynomialFeatures(degree=degree)),</span><br><span class="line">        (<span class="string">&#x27;std_scale&#x27;</span>, StandardScaler()),</span><br><span class="line">        (<span class="string">&#x27;lin_reg&#x27;</span>, LinearRegression()),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">666</span>)</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(X, y)</span><br><span class="line"></span><br><span class="line">poly_reg = PolynomiaRegression(degree=<span class="number">20</span>)</span><br><span class="line">poly_reg.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">y_poly_predict = poly_reg.predict(x_test)</span><br><span class="line">mean_squared_error(y_test, y_poly_predict)</span><br><span class="line"><span class="comment"># 167.9401085999025</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">x_plot = np.linspace(-<span class="number">3</span>, <span class="number">3</span>, <span class="number">100</span>).reshape(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line">y_plot = poly_reg.predict(x_plot)</span><br><span class="line"></span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.plot(x_plot[:,<span class="number">0</span>], y_plot, color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.axis([-<span class="number">3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">6</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/c9836b94dd7847658d42e93df349d9b2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"><br>把画图这些操作封装成一个函数，方便后面调用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_model</span>(<span class="params">model</span>):</span></span><br><span class="line">    x_plot = np.linspace(-<span class="number">3</span>, <span class="number">3</span>, <span class="number">100</span>).reshape(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line">    y_plot = model.predict(x_plot)</span><br><span class="line"></span><br><span class="line">    plt.scatter(x, y)</span><br><span class="line">    plt.plot(x_plot[:,<span class="number">0</span>], y_plot, color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    plt.axis([-<span class="number">3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">6</span>])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p><strong>使用岭回归：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">RidgeRegression</span>(<span class="params">degree, alpha</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Pipeline([</span><br><span class="line">        (<span class="string">&#x27;poly&#x27;</span>, PolynomialFeatures(degree=degree)),</span><br><span class="line">        (<span class="string">&#x27;std_scale&#x27;</span>, StandardScaler()),</span><br><span class="line">        (<span class="string">&#x27;lin_reg&#x27;</span>, Ridge(alpha=alpha)),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">ridege1_reg = RidgeRegression(<span class="number">20</span>, alpha=<span class="number">0.0001</span>)</span><br><span class="line">ridege1_reg.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">y1_predict = ridege1_reg.predict(x_test)</span><br><span class="line">mean_squared_error(y_test, y1_predict)</span><br><span class="line"><span class="comment"># 1.3233492754136291</span></span><br><span class="line"><span class="comment"># 跟之前的136.相比小了很多</span></span><br><span class="line">plot_model(ridege1_reg)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/2badbea0090b4d46990a48f2dc7d46ba.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/b8cd8e0a33ac4ef4b620e7d5ee20374e.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ridege2_reg = RidgeRegression(<span class="number">20</span>, alpha=<span class="number">1</span>)</span><br><span class="line">ridege2_reg.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">y2_predict = ridege2_reg.predict(x_test)</span><br><span class="line">mean_squared_error(y_test, y2_predict)</span><br><span class="line"><span class="comment"># 1.1888759304218461</span></span><br><span class="line">plot_model(ridege2_reg)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/545f2db0fe004e4e95cf9fdc7105c039.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ridege3_reg = RidgeRegression(<span class="number">20</span>, alpha=<span class="number">100</span>)</span><br><span class="line">ridege3_reg.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">y3_predict = ridege3_reg.predict(x_test)</span><br><span class="line">mean_squared_error(y_test, y3_predict)</span><br><span class="line"><span class="comment"># 1.3196456113086197</span></span><br><span class="line"><span class="comment"># 此时相比alpha=1时均方误差上升了，说明可能正则过头了</span></span><br><span class="line">plot_model(ridege3_reg)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/c621ca76f4f24f1e80b5e57a2bcde7e3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ridege4_reg = RidgeRegression(<span class="number">20</span>, alpha=<span class="number">1000000</span>)</span><br><span class="line">ridege4_reg.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">y4_predict = ridege4_reg.predict(x_test)</span><br><span class="line">mean_squared_error(y_test, y4_predict)</span><br><span class="line"><span class="comment"># 1.8404103153255003</span></span><br><span class="line">plot_model(ridege4_reg)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/b4cf8e44eb594b3899751dd118198317.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"><br>​ 这也跟之前分析，如果 <code>ɑ</code>=正无穷 时，为了使损失函数最小，就需要所有的系数的平方和最小，即 <code>θ</code> 都趋于0。通过上面几种alpha的取值可以看出我们可以在1-100进行更加细致的搜索，找到最合适的一条相对比较平滑的曲线去拟合。这就是L2正则。</p><h2 id="LASSO-Regularization"><a href="#LASSO-Regularization" class="headerlink" title="LASSO Regularization"></a>LASSO Regularization</h2><p><img src="https://img-blog.csdnimg.cn/8c89e8cb8a984341989870c0a2018604.png"></p><blockquote><p>LASSO: Least Absolute Shrinkage and Selection Operator Regression<br>Shrinkage:收缩，缩小，收缩量。特征缩减。重点在于Selection Operator</p></blockquote><p><strong>使用lasso回归：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">LassoRegression</span>(<span class="params">degree, alpha</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Pipeline([</span><br><span class="line">        (<span class="string">&#x27;poly&#x27;</span>, PolynomialFeatures(degree=degree)),</span><br><span class="line">        (<span class="string">&#x27;std_scale&#x27;</span>, StandardScaler()),</span><br><span class="line">        (<span class="string">&#x27;lin_reg&#x27;</span>, Lasso(alpha=alpha)),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">lasso1_reg = LassoRegression(<span class="number">20</span>, <span class="number">0.01</span>) </span><br><span class="line"><span class="comment">#这里相比Ridge的alpha小了很多，这是因为在Ridge中是平方项</span></span><br><span class="line">lasso1_reg.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">y1_predict = lasso1_reg.predict(x_test)</span><br><span class="line">mean_squared_error(y_test, y1_predict)</span><br><span class="line"><span class="comment"># 1.149608084325997</span></span><br><span class="line">plot_model(lasso1_reg)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/513a47b8a5104538a1db046eced2e9e9.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">lasso2_reg = LassoRegression(<span class="number">20</span>, <span class="number">0.1</span>) </span><br><span class="line">lasso2_reg.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">y2_predict = lasso2_reg.predict(x_test)</span><br><span class="line">mean_squared_error(y_test, y2_predict)</span><br><span class="line"><span class="comment"># 1.1213911351818648</span></span><br><span class="line">plot_model(lasso2_reg)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/57883b6ad285444b8955135b02be6214.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">lasso3_reg = LassoRegression(<span class="number">20</span>, <span class="number">1</span>) </span><br><span class="line">lasso3_reg.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line">y3_predict = lasso3_reg.predict(x_test)</span><br><span class="line">mean_squared_error(y_test, y3_predict)</span><br><span class="line"><span class="comment"># 1.8408939659515595</span></span><br><span class="line">plot_model(lasso3_reg)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/eb19c49b39e24af0b5d14a00dad8c57a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="解释Ridge和LASSO"><a href="#解释Ridge和LASSO" class="headerlink" title="解释Ridge和LASSO"></a>解释Ridge和LASSO</h2><p><img src="https://img-blog.csdnimg.cn/d4b6e79d28d6427aa215ce0a1e1878a1.png"><br><img src="https://img-blog.csdnimg.cn/27238b86bf3942a3a2aa983e4b66fd1d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>通过这两幅图进行对比发现，<code>LASSO</code>拟合的模型更倾向于是一条直线，而<code>Ridge</code>拟合的模型更趋向与一条曲线。这是因为两个正则的本质不同，<code>Ridge</code>是趋向于使所有 <code>θ</code> 的加和尽可能的小，而 <code>Lasso</code> 则是趋向于使得一部分  <code>θ</code>  的值变为0，因此可作为特征选择用，这也是为什么叫 <code>Selection Operation</code> 的原因。<br>下面就对上面这两句话尝试着进行一下解释：<br><img src="https://img-blog.csdnimg.cn/12c4349c4444416594a5125566b9d9e6.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/63ad8e7101ee43d5a7740b983142c05b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>导数中的 <code>θ</code> 都是有值的，顺着梯度方向下降。<code>Ridge</code>是趋向于使所有 <code>θ</code> 的加和尽可能的小，而不是像<code>lasso</code> 一样直接为0。<br><img src="https://img-blog.csdnimg.cn/9f5e71646a094c09884c7a17dedbdb51.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/de9d4586c2af4d5ab092fa37a56a0d1e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_17,color_FFFFFF,t_70,g_se,x_16"><br>所以，当如果从上图的一点开始进行梯度下降的话，就不能想 <code>Ridge</code> 一样曲线地去逼近 <code>0</code>，而是只能使用这些非常规则的方式去逼近零点。在这种路径的梯度下降中，就会达到某些轴的零点，<code>Lasso</code> 则是趋向于使得一部分 <code>θ</code> 的值变为 <code>0</code>。所以可以作为特征选择用。不过也正是因为这样的特性，使得 <code>Lasso</code>这种方法有可能会错误将原来有用的特征的系数变为 <code>0</code>，所以相对 <code>Ridge</code> 来说，准确率还是 <code>Ridge</code> 相对较好一些，但是当特征特别大时候，此时使用 <code>Lasso</code> 也能将模型的特征变少的作用。</p><h2 id="弹性网"><a href="#弹性网" class="headerlink" title="弹性网"></a>弹性网</h2><p><img src="https://img-blog.csdnimg.cn/a1d9313e17424fdeb30d14caf763db9e.png"><br>既然两者各有优势，就把他们结合起来，这就是弹性网（Elastic Net）。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 模型泛化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习(四)——PCA主成分分析</title>
      <link href="/2021/12/01/ML4_PCA/"/>
      <url>/2021/12/01/ML4_PCA/</url>
      
        <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>我们在完成一个机器学习任务比如线性回归，所使用数据的维度可能非常高(训练测试耗时大且占内存大)，或者属性之间可能具有相关性，比如奖学金和绩点（奖学金也反映了绩点的情况），这就会造成数据的冗余。这时我们就可以用到 <code>PCA(Principal components analysis)</code>主成分分析，来对数据进行降维，减小数据的冗余。</p><span id="more"></span><hr><h1 id="PCA的思想"><a href="#PCA的思想" class="headerlink" title="PCA的思想"></a>PCA的思想</h1><p>当然，<code>PCA</code> 不是简单地选择几个属性或者说是去除几个属性，它是综合考虑了所有属性，确定出几个主成分（或者说是新的属性），这个主成分可以说是原始属性的综合。<br><img src="https://img-blog.csdnimg.cn/c3e5a10e1c5e45448f74799db6d30c37.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>所以关键就是 <code>w1</code> <code>w2</code> 是多少。<br>比如下面图中，我们将样本点投影到 <code>u1</code> 好还是投影到 <code>u2</code> 好。<br><img src="https://img-blog.csdnimg.cn/8e304829a09a436fb9258f0069763828.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>直观地看是 <code>u1</code> 比较好，为什么呢？可以有两种解释，第一种解释样本点到这个直线的距离足够近，第二种解释是样本点在这个直线上的投影能尽可能的分开。<br><strong>这里我们以第二种解释来进行下面的讨论。</strong><br>这里样本点在这个直线上的投影能尽可能的分开，一般我们使用方差最大来表示。<br><img src="https://img-blog.csdnimg.cn/92f75238346645cfaa9296352fec531d.png"><br>第一步，将样本进行均值归<code>0</code>，此时：<br><img src="https://img-blog.csdnimg.cn/f0de4b56bc994b5b80e41117f6d02c04.png"><br>第二步，需要定义一个轴的方向 <code>w=(w1,w2)</code>，使得我们的样本，映射到 <code>w</code> 以后，使下面的公式最大：<br><img src="https://img-blog.csdnimg.cn/c9282017f7bf48778986a71c39ae8eca.png"><br>其实括号中的部分是一个向量，更加准确的描述应该是：<br><img src="https://img-blog.csdnimg.cn/af442e431cf647dab33e3f85f3b2d319.png"><br>因为前面已经去均值，所以，这里只需：<br><img src="https://img-blog.csdnimg.cn/2c9dd2cfe8e64ee39becc28bdf684355.png"><br>最后可以化为如下优化问题。<br><img src="https://img-blog.csdnimg.cn/b82a3a7b12d84e4185e1817ac75d77fb.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>使用梯度上升法解决目标函数优化问题。<br><img src="https://img-blog.csdnimg.cn/0531e619927046dabb76a0886ccfa5bd.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>具体代码如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">X = np.empty((<span class="number">100</span>, <span class="number">2</span>))</span><br><span class="line">X[:, <span class="number">0</span>] = np.random.uniform(<span class="number">0.</span>, <span class="number">100.</span>, size=<span class="number">100</span>)</span><br><span class="line">X[:, <span class="number">1</span>] = <span class="number">0.75</span> * X[:, <span class="number">0</span>] + <span class="number">3.</span> + np.random.normal(<span class="number">0.</span>, <span class="number">10.</span>, size=<span class="number">100</span>) </span><br><span class="line"></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">demean</span>(<span class="params">X</span>):</span></span><br><span class="line">    <span class="comment"># 不使用standardscale标准化数据，求解PCA需要方差，只去均值。</span></span><br><span class="line">    <span class="keyword">return</span> X - np.mean(X, axis=<span class="number">0</span>) <span class="comment"># axis=0表示最终求得的均值是一个行向量，也就是说将每一列求和 </span></span><br><span class="line">x_demean = demean(X)</span><br><span class="line">plt.scatter(x_demean[:,<span class="number">0</span>], x_demean[:,<span class="number">1</span>])</span><br><span class="line">plt.show()</span><br><span class="line">np.mean(x_demean[:,<span class="number">0</span>])</span><br><span class="line">np.mean(x_demean[:,<span class="number">1</span>])</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">w ,x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>((x.dot(w) ** <span class="number">2</span>)) / <span class="built_in">len</span>(x)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">df_math</span>(<span class="params">w, x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x.T.dot(x.dot(w)) * <span class="number">2.</span> / <span class="built_in">len</span>(x)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">df_denug</span>(<span class="params">w, x, epsilon=<span class="number">0.0001</span></span>):</span></span><br><span class="line">    res = np.empty(<span class="built_in">len</span>(w))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(w)):</span><br><span class="line">        w_1 = w.copy()</span><br><span class="line">        w_1[i] += epsilon</span><br><span class="line">        w_2 = w.copy()</span><br><span class="line">        w_2[i] -= epsilon</span><br><span class="line">        res[i] = (f(w_1, x) - f(w_2, x)) / (<span class="number">2</span> * epsilon)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">direction</span>(<span class="params">w</span>):</span></span><br><span class="line">    <span class="keyword">return</span> w / np.linalg.norm(w)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_ascent</span>(<span class="params">df, x, init_w, eta, n_iters=<span class="number">1e4</span>, epsilon=<span class="number">1e-8</span></span>):</span></span><br><span class="line"></span><br><span class="line">    w = direction(init_w)</span><br><span class="line">    cur_iter = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> cur_iter &lt; n_iters:</span><br><span class="line">        gradient = df(w, x)</span><br><span class="line">        last_w = w</span><br><span class="line">        w = w + eta * gradient</span><br><span class="line">        w = direction(w)</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">abs</span>(f(w, x) - f(last_w, x)) &lt; epsilon):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        cur_iter += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> w</span><br></pre></td></tr></table></figure><p>测试：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">init_w = np.random.random(X.shape[<span class="number">1</span>])    <span class="comment"># 不能0向量开始</span></span><br><span class="line">init_w</span><br><span class="line">eta = <span class="number">0.001</span></span><br><span class="line">gradient_ascent(df_denug, x_demean, init_w, eta)</span><br></pre></td></tr></table></figure><p>输出结果 <code>array([0.7851916, 0.6192529])</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">w = gradient_ascent(df_math, x_demean, init_w, eta)</span><br><span class="line">plt.scatter(x_demean[:, <span class="number">0</span>], x_demean[:,<span class="number">1</span>])</span><br><span class="line">plt.plot([<span class="number">0</span>, w[<span class="number">0</span>]*<span class="number">30</span>], [<span class="number">0</span>, w[<span class="number">1</span>]*<span class="number">30</span>], color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/84722c72871f45fcaf3d03589815d571.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="sklearn中的PCA"><a href="#sklearn中的PCA" class="headerlink" title="sklearn中的PCA"></a>sklearn中的PCA</h1><p>我们使用 <code>PCA</code> 来应用在 <code>KNN</code> 手写数字识别任务上</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line">x = digits.data</span><br><span class="line">y = digits.target</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">666</span>)</span><br><span class="line">x_train.shape</span><br></pre></td></tr></table></figure><p>Output：(1437, 64)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">knn_clf = KNeighborsClassifier()</span><br><span class="line">knn_clf.fit(x_train, y_train)</span><br></pre></td></tr></table></figure><p>Output：Wall time: 288 ms</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">knn_clf.score(x_test, y_test)</span><br></pre></td></tr></table></figure><p>Output：0.9888888888888889<br>应用 <code>PCA</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">pca.fit(x_train)</span><br><span class="line">x_train_reduction = pca.transform(x_train)</span><br><span class="line">x_test_reduction = pca.transform(x_test)</span><br><span class="line">%%time</span><br><span class="line">knn_clf = KNeighborsClassifier()</span><br><span class="line">knn_clf.fit(x_train_reduction, y_train)</span><br></pre></td></tr></table></figure><p>Output：Wall time: 101 ms</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">knn_clf.score(x_test_reduction, y_test)</span><br></pre></td></tr></table></figure><p>Output：0.6055555555555555<br>测试时间是下降了不少，但准确下降的也很多，这是无法接受的，可见从 <code>64</code>维映射到 <code>2</code>维，损失了很多有效的信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pca.explained_variance_ratio_</span><br></pre></td></tr></table></figure><p>Output：array([0.1450646 , 0.13714246])<br>可见映射到 <code>2</code> 维才保留了不到 <code>30%</code> 的信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components=x_train.shape[<span class="number">1</span>])</span><br><span class="line">pca.fit(x_train)</span><br><span class="line">pca.explained_variance_ratio_</span><br><span class="line">plt.plot([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(x_train.shape[<span class="number">1</span>])],</span><br><span class="line">        [np.<span class="built_in">sum</span>(pca.explained_variance_ratio_[:i+<span class="number">1</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(x_train.shape[<span class="number">1</span>])])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/5c2a868adce94c86b6e175769d5ea3d8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"><br>从图中可以看出，映射到 <code>30</code> 维左右就能保留大部分信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(<span class="number">0.95</span>)</span><br><span class="line">pca.fit(x_train)</span><br><span class="line">pca.n_components_</span><br></pre></td></tr></table></figure><p>Output：28</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x_train_reduction = pca.transform(x_train)</span><br><span class="line">x_test_reduction = pca.transform(x_test)</span><br><span class="line">knn_clf = KNeighborsClassifier()</span><br><span class="line">knn_clf.fit(x_train_reduction, y_train)</span><br><span class="line">knn_clf.score(x_test_reduction, y_test)</span><br></pre></td></tr></table></figure><p>Output：0.9833333333333333</p><hr><h1 id="PCA的特点"><a href="#PCA的特点" class="headerlink" title="PCA的特点"></a>PCA的特点</h1><p>作为一个非监督学习的降维方法，它只需要特征值分解，就可以对数据进行压缩，去噪。因此在实际场景应用很广泛。<br>PCA算法的主要优点有：</p><p>　　　　1）仅仅需要以方差衡量信息量，不受数据集以外的因素影响。　</p><p>　　　　2）各主成分之间正交，可消除原始数据成分间的相互影响的因素。</p><p>　　　　3）计算方法简单，主要运算是特征值分解，易于实现。</p><p>　　　　PCA算法的主要缺点有：</p><p>　　　　1）主成分各个特征维度的含义具有一定的模糊性，不如原始样本特征的解释性强。</p><p>　　　　2）方差小的非主成分也可能含有对样本差异的重要信息，因降维丢弃可能对后续数据处理有影响。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> PCA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习(三)——多项式回归</title>
      <link href="/2021/11/29/ML3_PolynomialRegression/"/>
      <url>/2021/11/29/ML3_PolynomialRegression/</url>
      
        <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>我们创建一组数据，并绘出散点图。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = np.random.uniform(-<span class="number">3</span>, <span class="number">3</span>, size=<span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line">y = <span class="number">0.5</span> + x**<span class="number">2</span> + x + <span class="number">2</span> + np.random.normal(<span class="number">0</span>, <span class="number">1</span>, size=<span class="number">100</span>)</span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/255ba26e58d440b699a000e7ebe1b89a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="散点图"></p><span id="more"></span><p>我们直接使用线性回归看看效果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(X, y)</span><br><span class="line">y_predict = lin_reg.predict(X)</span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.plot(x, y_predict, color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/6ace98ade47441d7b51c933252c0e197.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16" alt="线性回归"><br>可以看出来，拟合效果不是很好，那么该如何解决呢？</p><hr><h1 id="多项式回归"><a href="#多项式回归" class="headerlink" title="多项式回归"></a>多项式回归</h1><p>我们试着添加一个特征，即 <code>x的二次项</code>，再进行线性回归。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X2 = np.hstack([X, X**<span class="number">2</span>])</span><br><span class="line">lin_reg2 = LinearRegression()</span><br><span class="line">lin_reg2.fit(X2, y)</span><br><span class="line">y_predict2 = lin_reg2.predict(X2)</span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.plot(np.sort(x), y_predict2[np.argsort(x)], color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/be8b7dac6b554e5baef0460423abd18f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16" alt="添加一个二次项"><br>可以明显看出，拟合效果大大提高了，这就是多项式回归，利用特征的高次项，可以用来拟合非线性曲线。</p><hr><h1 id="sklearn包完成多项式回归"><a href="#sklearn包完成多项式回归" class="headerlink" title="sklearn包完成多项式回归"></a>sklearn包完成多项式回归</h1><p>我们可以通过 <code>sklearn</code> 包中的 <code>PolynomialFeatures</code> 构建高维特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">1</span>, <span class="number">11</span>).reshape(<span class="number">5</span>, <span class="number">2</span>)</span><br><span class="line">x.shape</span><br><span class="line"><span class="comment"># (5, 2)</span></span><br><span class="line">x</span><br></pre></td></tr></table></figure><p>将其升为二阶</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"></span><br><span class="line">poly = PolynomialFeatures()</span><br><span class="line">poly.fit(x)</span><br><span class="line">x2 = poly.transform(x)</span><br><span class="line">x2.shape</span><br><span class="line"><span class="comment"># (5, 6)</span></span><br><span class="line">x2</span><br><span class="line">array([[  <span class="number">1.</span>,   <span class="number">1.</span>,   <span class="number">2.</span>,   <span class="number">1.</span>,   <span class="number">2.</span>,   <span class="number">4.</span>],</span><br><span class="line">       [  <span class="number">1.</span>,   <span class="number">3.</span>,   <span class="number">4.</span>,   <span class="number">9.</span>,  <span class="number">12.</span>,  <span class="number">16.</span>],</span><br><span class="line">       [  <span class="number">1.</span>,   <span class="number">5.</span>,   <span class="number">6.</span>,  <span class="number">25.</span>,  <span class="number">30.</span>,  <span class="number">36.</span>],</span><br><span class="line">       [  <span class="number">1.</span>,   <span class="number">7.</span>,   <span class="number">8.</span>,  <span class="number">49.</span>,  <span class="number">56.</span>,  <span class="number">64.</span>],</span><br><span class="line">       [  <span class="number">1.</span>,   <span class="number">9.</span>,  <span class="number">10.</span>,  <span class="number">81.</span>,  <span class="number">90.</span>, <span class="number">100.</span>]])</span><br></pre></td></tr></table></figure><p>其中第<code>1</code>项为常数项，第<code>2</code>第<code>3</code>项为一次项x1,x2，第<code>4</code>第<code>6</code>项为二次项x1<sup>2</sup>,x2<sup>2</sup>，第<code>5</code>项为x1x2。<br>我们再将其升为三阶看看。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">poly = PolynomialFeatures(degree=<span class="number">3</span>)</span><br><span class="line">poly.fit(x)</span><br><span class="line">x3 = poly.transform(x)</span><br><span class="line">x3.shape</span><br><span class="line"><span class="comment"># (5, 10)</span></span><br><span class="line">array([[   <span class="number">1.</span>,    <span class="number">1.</span>,    <span class="number">2.</span>,    <span class="number">1.</span>,    <span class="number">2.</span>,    <span class="number">4.</span>,    <span class="number">1.</span>,    <span class="number">2.</span>,    <span class="number">4.</span>,</span><br><span class="line">           <span class="number">8.</span>],</span><br><span class="line">       [   <span class="number">1.</span>,    <span class="number">3.</span>,    <span class="number">4.</span>,    <span class="number">9.</span>,   <span class="number">12.</span>,   <span class="number">16.</span>,   <span class="number">27.</span>,   <span class="number">36.</span>,   <span class="number">48.</span>,</span><br><span class="line">          <span class="number">64.</span>],</span><br><span class="line">       [   <span class="number">1.</span>,    <span class="number">5.</span>,    <span class="number">6.</span>,   <span class="number">25.</span>,   <span class="number">30.</span>,   <span class="number">36.</span>,  <span class="number">125.</span>,  <span class="number">150.</span>,  <span class="number">180.</span>,</span><br><span class="line">         <span class="number">216.</span>],</span><br><span class="line">       [   <span class="number">1.</span>,    <span class="number">7.</span>,    <span class="number">8.</span>,   <span class="number">49.</span>,   <span class="number">56.</span>,   <span class="number">64.</span>,  <span class="number">343.</span>,  <span class="number">392.</span>,  <span class="number">448.</span>,</span><br><span class="line">         <span class="number">512.</span>],</span><br><span class="line">       [   <span class="number">1.</span>,    <span class="number">9.</span>,   <span class="number">10.</span>,   <span class="number">81.</span>,   <span class="number">90.</span>,  <span class="number">100.</span>,  <span class="number">729.</span>,  <span class="number">810.</span>,  <span class="number">900.</span>,</span><br><span class="line">        <span class="number">1000.</span>]])</span><br></pre></td></tr></table></figure><p>这十项分别对应如下：<br><img src="https://img-blog.csdnimg.cn/8677aa372fd34e43b46598ab7929cc76.png"><br><code>sklearn</code> 包没有对多项式回归进行封装，不过可以使用 <code>Pipeline</code> 对数据归一化、多项式生维、线性回归进行整合。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x = np.random.uniform(-<span class="number">3</span>, <span class="number">3</span>, size=<span class="number">100</span>)</span><br><span class="line">X = x.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = <span class="number">0.5</span> * x**<span class="number">2</span> + <span class="number">2</span> + np.random.normal(<span class="number">0</span>, <span class="number">1</span>, size=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">poly_reg = Pipeline([</span><br><span class="line">    (<span class="string">&#x27;poly&#x27;</span>, PolynomialFeatures(degree=<span class="number">2</span>)),</span><br><span class="line">    (<span class="string">&#x27;std_scale&#x27;</span>, StandardScaler()),</span><br><span class="line">    (<span class="string">&#x27;lin_reg&#x27;</span>, LinearRegression())</span><br><span class="line">])  </span><br><span class="line">poly_reg.fit(X, y)</span><br><span class="line">y_predict = poly_reg.predict(X)</span><br><span class="line"></span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.plot(np.sort(x), y_predict[np.argsort(x)], color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><hr><h1 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h1><p>我们可以看到，高维可以有效地拟合训练集，但有没有危害呢？我们来看看下面的情况。<br>我们将数据集分为训练集与测试集，分别训练一维，二维，十维，一百维。观察其在测试集上的均方误差。<br><strong>一维</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">666</span>)</span><br><span class="line">np.random.seed(<span class="number">666</span>)</span><br><span class="line">x = np.random.uniform(-<span class="number">3.0</span>, <span class="number">3.0</span>, size=<span class="number">100</span>)</span><br><span class="line">X = x.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = <span class="number">0.5</span> * x**<span class="number">2</span> + x + <span class="number">2</span> + np.random.normal(<span class="number">0</span>, <span class="number">1</span>, size=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=<span class="number">666</span>)</span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(x_train, y_train)</span><br><span class="line">y_predict = lin_reg.predict(x_test)</span><br><span class="line">mean_squared_error(y_test, y_predict)</span><br></pre></td></tr></table></figure><p>输出结果：2.2199965269396573<br><strong>二维</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PolynomialRegression</span>(<span class="params">degree</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Pipeline([</span><br><span class="line">        (<span class="string">&#x27;poly&#x27;</span>, PolynomialFeatures(degree=degree)),</span><br><span class="line">        (<span class="string">&#x27;std_scale&#x27;</span>, StandardScaler()),</span><br><span class="line">        (<span class="string">&#x27;lin_reg&#x27;</span>, LinearRegression())</span><br><span class="line">    ])</span><br><span class="line">poly2_reg = PolynomialRegression(degree=<span class="number">2</span>)</span><br><span class="line">poly2_reg.fit(x_train, y_train)</span><br><span class="line">y2_predict = poly2_reg.predict(x_test)</span><br><span class="line">mean_squared_error(y_test, y2_predict)</span><br></pre></td></tr></table></figure><p>输出结果： 0.8035641056297901<br><strong>十维</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">poly10_reg = PolynomialRegression(degree=<span class="number">10</span>)</span><br><span class="line">poly10_reg.fit(x_train, y_train)</span><br><span class="line">y10_predict = poly10_reg.predict(x_test)</span><br><span class="line">mean_squared_error(y_test, y10_predict)</span><br></pre></td></tr></table></figure><p>输出结果：0.9212930722150781<br>我们看到二维的误差比一维小了很多，但是十维的测试误差又变大了。<br><strong>百维</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">poly100_reg = PolynomialRegression(degree=<span class="number">100</span>)</span><br><span class="line">poly100_reg.fit(x_train, y_train)</span><br><span class="line">y100_predict = poly100_reg.predict(x_test)</span><br><span class="line">mean_squared_error(y_test, y100_predict)</span><br></pre></td></tr></table></figure><p>输出结果：14440175276.314638，逐渐离谱了起来。<br>这就是产生了过拟合的问题，即训练集表现很好，但测试集表现特别差，泛化能力很差。<br><img src="https://img-blog.csdnimg.cn/679db33e6fb14ac9a151f63f18876a1e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>模型太简单会欠拟合，模型太复杂又会产生过拟合。那么如何辨别当前模型是欠拟合还是过拟合呢？最好的方式就是通过学习曲线判别。</p><hr><h1 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h1><p>封装一个学习曲线的函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_learning_curve</span>(<span class="params">algo, x_train, x_test, y_train, y_test</span>):</span></span><br><span class="line"></span><br><span class="line">    train_score = []</span><br><span class="line">    test_score = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(x_train)+<span class="number">1</span>):</span><br><span class="line">        algo.fit(x_train[:i], y_train[:i])</span><br><span class="line"></span><br><span class="line">        y_train_predict = algo.predict(x_train[:i])</span><br><span class="line">        train_score.append(mean_squared_error(y_train[:i], y_train_predict))</span><br><span class="line"></span><br><span class="line">        y_test_predict = algo.predict(x_test)</span><br><span class="line">        test_score.append(mean_squared_error(y_test, y_test_predict))</span><br><span class="line"></span><br><span class="line">    plt.plot([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(x_train)+<span class="number">1</span>)], np.sqrt(train_score), label=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">    plt.plot([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(x_train)+<span class="number">1</span>)], np.sqrt(test_score), label=<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    <span class="comment"># plt.axis([0, len(x_train)+1, 0, 4])</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>绘制一维的学习曲线</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_learning_curve(LinearRegression(), x_train, x_test, y_train, y_test)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/4081d5278f974f9ebc925adbd0e2b3eb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16"><br>可以看出训练误差和测试误差都很大，这就是发生了欠拟合。<br>绘制二维的学习曲线。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PolynomialRegression</span>(<span class="params">degree</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Pipeline([</span><br><span class="line">        (<span class="string">&#x27;poly&#x27;</span>, PolynomialFeatures(degree=degree)),</span><br><span class="line">        (<span class="string">&#x27;std_scale&#x27;</span>, StandardScaler()),</span><br><span class="line">        (<span class="string">&#x27;lin_reg&#x27;</span>, LinearRegression())</span><br><span class="line">    ])</span><br><span class="line">poly2_reg = PolynomialRegression(degree=<span class="number">2</span>)</span><br><span class="line">plot_learning_curve(poly2_reg, x_train, x_test, y_train, y_test)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/8cf9c9d72cd5484c9b4fc4593fcef506.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"><br>训练误差测试误差都很低，这就是最佳状态。<br>绘制二十维学习曲线。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">poly2_reg = PolynomialRegression(degree=<span class="number">20</span>)</span><br><span class="line">plot_learning_curve(poly2_reg, x_train, x_test, y_train, y_test)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/c41c0eef4193416d83d4a0f39df61fd3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16"><br>可以看出训练误差始终很低，但测试误差中间出现了很大的波动，这就是发生了过拟合。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 多项式回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习(二)——K近邻算法</title>
      <link href="/2021/11/29/ML2_KNN/"/>
      <url>/2021/11/29/ML2_KNN/</url>
      
        <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>在具体讨论 <code>KNN</code> 算法之前，我们先通过一个具体的例子引入。我们创建一个数据集，并将其可视化出来。</p><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">raw_data_x = [[<span class="number">3.3935</span>, <span class="number">2.3313</span>],</span><br><span class="line">              [<span class="number">3.1101</span>, <span class="number">1.7815</span>],</span><br><span class="line">              [<span class="number">1.3438</span>, <span class="number">3.3684</span>],</span><br><span class="line">              [<span class="number">3.5823</span>, <span class="number">4.6792</span>],</span><br><span class="line">              [<span class="number">2.2804</span>, <span class="number">2.8670</span>],</span><br><span class="line">              [<span class="number">7.4234</span>, <span class="number">4.6965</span>],</span><br><span class="line">              [<span class="number">5.7451</span>, <span class="number">3.5340</span>],</span><br><span class="line">              [<span class="number">9.1722</span>, <span class="number">2.5111</span>],</span><br><span class="line">              [<span class="number">7.7928</span>, <span class="number">3.4241</span>],</span><br><span class="line">              [<span class="number">7.9398</span>, <span class="number">0.7916</span>]]</span><br><span class="line">raw_data_y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line">x_train = np.array(raw_data_x)</span><br><span class="line">y_train = np.array(raw_data_y)</span><br><span class="line">x_new = np.array([<span class="number">8.0936</span>, <span class="number">3.3657</span>])</span><br><span class="line">plt.scatter(x_train[y_train==<span class="number">0</span>,<span class="number">0</span>], x_train[y_train==<span class="number">0</span>,<span class="number">1</span>], color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">plt.scatter(x_train[y_train==<span class="number">1</span>,<span class="number">0</span>], x_train[y_train==<span class="number">1</span>,<span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.scatter(x_new[<span class="number">0</span>], x_new[<span class="number">1</span>], color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/14fceba55eaa4bb2a9400ade2e26afd3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16" alt="散点图"><br>从上面的散点图中，蓝色的点明显更接近红色的点。我们将蓝色的点与其它点的距离求出来，并将最近的 <code>5</code> 个点选出来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line">distance = []</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> x_train:</span><br><span class="line">    d = sqrt(np.<span class="built_in">sum</span>((x_new - x) ** <span class="number">2</span>))</span><br><span class="line">    distance.append(d)</span><br><span class="line">nearsest = np.argsort(distance)</span><br><span class="line">k = <span class="number">5</span></span><br><span class="line">topk_y = [y_train[i] <span class="keyword">for</span> i <span class="keyword">in</span> nearsest[:k]]</span><br></pre></td></tr></table></figure><p>可以看到结果是 <code>[1,1,1,1,1]</code>，如果我们将距离最近的 <code>5</code> 个点中，种类数量最多作为蓝色的点的种类，那么蓝色也就是归于红色一类，与我们之前看到的散点图一样。没错这就是 <code>KNN</code> 算法。</p><hr><h1 id="具体思想"><a href="#具体思想" class="headerlink" title="具体思想"></a>具体思想</h1><p><code>KNN</code> 即 <code>K-Nearest Neighbors</code>，其思想特别简单，就是设置一个超参数 <code>k</code>，对于一个新样本，我们计算其与所有训练集中数据的距离（这个计算距离的方式也可以选择，欧式距离、马氏距离….），然后选出最近的 <code>k</code> 个，进行投票，即 <code>k</code> 个数据中，类别最多的那一类即为新样本的类别。<br>是不是很简单，下面附一个手写的 <code>KNN</code> 解决手写数字识别的代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KNNClassifier</span>():</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, k</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="number">1</span> &lt;= k, <span class="string">&quot;k must be valid&quot;</span></span><br><span class="line">        self.k = k</span><br><span class="line">        self._x_train = <span class="literal">None</span></span><br><span class="line">        self._y_train = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, x_train, y_train</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> x_train.shape[<span class="number">0</span>] == y_train.shape[<span class="number">0</span>], \</span><br><span class="line">            <span class="string">&quot;the size of x_train must be equal to the size of y_train&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> self.k &lt;= x_train.shape[<span class="number">0</span>], \</span><br><span class="line">            <span class="string">&quot;the size of x_train must be at least k&quot;</span></span><br><span class="line"></span><br><span class="line">        self._x_train = x_train</span><br><span class="line">        self._y_train = y_train</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, x_new</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> self._x_train <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> self._y_train <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>, \</span><br><span class="line">            <span class="string">&quot;must fit before predict&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> x_new.shape[<span class="number">1</span>] == self._x_train.shape[<span class="number">1</span>], \</span><br><span class="line">            <span class="string">&quot;the feature number of x_new must be equal to x_train&quot;</span></span><br><span class="line"></span><br><span class="line">        y_new = [self._predict(x) <span class="keyword">for</span> x <span class="keyword">in</span> x_new]</span><br><span class="line">        <span class="keyword">return</span> np.array(y_new)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_predict</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> x.shape[<span class="number">0</span>] == self._x_train.shape[<span class="number">1</span>], \</span><br><span class="line">            <span class="string">&quot;the feature number of x must be equal to x_train&quot;</span></span><br><span class="line"></span><br><span class="line">        distances = [sqrt(np.<span class="built_in">sum</span>((x_train - x) ** <span class="number">2</span>)) <span class="keyword">for</span> x_train <span class="keyword">in</span> self._x_train]</span><br><span class="line">        nearest = np.argsort(distances)</span><br><span class="line"></span><br><span class="line">        topk_y = [self._y_train[i] <span class="keyword">for</span> i <span class="keyword">in</span> nearest[:self.k]]</span><br><span class="line">        votes = Counter(topk_y)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> votes.most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span>(<span class="params">self, x_test, y_test</span>):</span></span><br><span class="line">        y_predict = self.predict(x_test)</span><br><span class="line">        <span class="keyword">assert</span> y_test.shape[<span class="number">0</span>] == y_predict.shape[<span class="number">0</span>], \</span><br><span class="line">            <span class="string">&quot;the size of y_true must be equal to the size of y_predict&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(y_test == y_predict) / <span class="built_in">len</span>(y_test)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;KNN(k=%d)&quot;</span> % self.k</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    digits = datasets.load_digits()</span><br><span class="line">    x = digits.data</span><br><span class="line">    y = digits.target</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.2</span>)</span><br><span class="line">    knn_classifier = KNNClassifier(k=<span class="number">3</span>)</span><br><span class="line">    knn_classifier.fit(x_train, y_train)</span><br><span class="line">    <span class="built_in">print</span>(knn_classifier.score(x_test, y_test))</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h1 id="超参数"><a href="#超参数" class="headerlink" title="超参数"></a>超参数</h1><p>我们已经知道，这个模型自己选择的部分一是 <code>k</code> 即选几个邻居，二是计算距离方法。但是实际操作中，可能会遇到平票的情况，而且只是通过类别的个数来判断有时也不是很准确，我们可以设定一个权重，一般为距离的倒数，这样离新样本越近的那个种类所具有的权重也越大，当然我们也可以自己根据具体情况自己设定计算权重的函数。<br>下面附一个，利用<code>sklearn</code>包的 <code>KNN</code> 分类器寻找最优超参数的代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line">x = digits.data</span><br><span class="line">y = digits.target</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">best_p = -<span class="number">1</span></span><br><span class="line">best_score = <span class="number">0.0</span></span><br><span class="line">best_k = -<span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>):</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>):</span><br><span class="line">        knn_clf = KNeighborsClassifier(n_neighbors=k, weights=<span class="string">&quot;distance&quot;</span>, p=p)</span><br><span class="line">        knn_clf.fit(x_train, y_train)</span><br><span class="line">        score = knn_clf.score(x_test, y_test)</span><br><span class="line">        <span class="keyword">if</span> score &gt; best_score:</span><br><span class="line">            best_p = p</span><br><span class="line">            best_k = k</span><br><span class="line">            best_score = score</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;best_p=&quot;</span>, best_p)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;best k=&quot;</span>, best_k)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;best score=&quot;</span>, best_score)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> KNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Anaconda使用指南</title>
      <link href="/2021/11/27/Anaconda/"/>
      <url>/2021/11/27/Anaconda/</url>
      
        <content type="html"><![CDATA[<blockquote><p>这篇文章主要针对Windows操作系统下，Anaconda3的使用指南，主要包括conda常用命令，jupyter notebook常用快捷键、修改默认工作目录、添加虚拟环境，后续如果有新内容会持续更新。</p></blockquote><span id="more"></span><h1 id="conda常用命令"><a href="#conda常用命令" class="headerlink" title="conda常用命令"></a>conda常用命令</h1><ol><li><p><code>conda -V</code> 查看 <code>conda</code> 版本<br><img src="https://img-blog.csdnimg.cn/cb0a27aec462405f85957ef4562795ae.png" alt="查看conda版本"></p></li><li><p><code>conda env list</code> 或 <code>conda info -e</code> 查看当前存在哪些虚拟环境<br> <img src="https://img-blog.csdnimg.cn/c13c8bea47904812b76ade288b5e3da4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_19,color_FFFFFF,t_70,g_se,x_16" alt="查看存在哪些虚拟环境"></p></li><li><p><code>conda update conda</code> 检查更新当前 <code>conda</code>‘<br><img src="https://img-blog.csdnimg.cn/a5a0904ae93b4e83b18263948d3afc11.png" alt="检查更新当前conda"></p></li><li><p><code>conda create -n your_env_name python=x.x</code> 创建虚拟环境，<code>your_env_name</code>为你给虚拟环境起的名字，<code>x.x</code>为指定的python的版本。<br><img src="https://img-blog.csdnimg.cn/3ea7f5ef2e3541c7a03dd974dedcb01c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="创建虚拟环境"><br>输入 <code>y</code>，便会开始创建，创建成功出现如下信息。<br><img src="https://img-blog.csdnimg.cn/dfb15a334fbd4bfc9f438a4a60afb05a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_17,color_FFFFFF,t_70,g_se,x_16" alt="创建成功"></p></li><li><p><code>activate your_env_name</code> 进入虚拟环境<br><img src="https://img-blog.csdnimg.cn/8e71ceb2395c432eae34369e2e1c8737.png" alt="进入虚拟环境"></p></li><li><p><code>conda list</code> 列出当前环境下的包<br><img src="https://img-blog.csdnimg.cn/3627c0d4e9244872a828710c425c679a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="列出当前环境下的包"></p></li><li><p><code>conda install package_name</code> 在当前环境安装包，<code>package_name</code>为指定的包名<br><img src="https://img-blog.csdnimg.cn/ed0964d1b2944f32bbc4343d24891866.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在当前环境安装包"></p></li><li><p><code>conda remove package_name</code> 删除当前环境的某个包<br><img src="https://img-blog.csdnimg.cn/6f5f0dc82f814f12ba73c0a5e36641ee.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在当前环境下删除包"></p></li><li><p><code>conda deactivate</code> 关闭当前虚拟环境<br><img src="https://img-blog.csdnimg.cn/15271eb4660442049016770163ecda2b.png" alt="关闭当前虚拟环境"></p></li><li><p><code>conda remove -n your_env_name --all</code> 删除虚拟环境<br><img src="https://img-blog.csdnimg.cn/723dc33fabea405e86268f552f0962eb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="删除虚拟环境"></p></li></ol><hr><h1 id="Jupyter-Notebook修改默认目录"><a href="#Jupyter-Notebook修改默认目录" class="headerlink" title="Jupyter Notebook修改默认目录"></a>Jupyter Notebook修改默认目录</h1><p>正常 <code>Jupyter Notebook</code> 工作目录默认是 <code>C:\User</code>，我们可以如下方法修改默认工作目录。</p><ol><li><code>cmd</code> 输入 <code>jupyter notebook --generate-config</code>，然后会在 <code>C:\User\XXX\.jupyter</code>生成<code>jupyter_notebook_config.py</code>文件。<br><img src="https://img-blog.csdnimg.cn/b43eec6b1bdd45e7b210b46b44a1e3c4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></li><li>修稿配置文件，将 <code>c.NotebookApp.notebook_dir</code> 后面改为你想设定的目录，如果前面有 <code>#</code> 将 <code>#</code> 删除。<br><img src="https://img-blog.csdnimg.cn/a3778b20c6664b07a973ba365a93f042.png"><br>这样从 <code>Anaconda Navigator</code> 里就能以你设定的工作目录打开，但用 <code>Jupyter Notebook</code> 快捷方式还是不能以你设定的默认工作目录打开。</li><li>修改 <code>Jupyter Notebook</code> 快捷方式，如果目标最后有<code>%USERPROFILE%</code>，要删掉，这样点快捷方式也能以你设定的默认工作目录打开了。<br><img src="https://img-blog.csdnimg.cn/a6f6001e79fb4797a0985a936266ade5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></li></ol><hr><h1 id="Jupyter-Notebook使用Python虚拟环境"><a href="#Jupyter-Notebook使用Python虚拟环境" class="headerlink" title="Jupyter Notebook使用Python虚拟环境"></a>Jupyter Notebook使用Python虚拟环境</h1><p>正常使用 <code>Jupyter Notebook</code>，是使用默认自带的 <code>Python</code> 环境的，并且是不能使用 <code>conda</code> 创建的 <code>Python</code> 虚拟环境的。<br><img src="https://img-blog.csdnimg.cn/40fc521ec6c94f1fb9da31497a9b2210.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>我们在 <code>cmd</code> 输入一下命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一步，切换到想要添加的虚拟环境，env_name为你需要添加的环境：</span></span><br><span class="line">conda activate env_name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二步，安装ipykernel包</span></span><br><span class="line">conda install ipykernel</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第三部，执行如下命令，并确定环境的名称（此处设置为env_name）</span></span><br><span class="line">python -m ipykernel install --name env_name</span><br></pre></td></tr></table></figure><p>之后我们打开 <code>Jupyter Notebook</code>，就可以使用添加的虚拟环境了<br><img src="https://img-blog.csdnimg.cn/b6f07d0c89274a9698fae99c25ded3e1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><hr><h1 id="Jupyter-Notebool-常用快捷键"><a href="#Jupyter-Notebool-常用快捷键" class="headerlink" title="Jupyter Notebool 常用快捷键"></a>Jupyter Notebool 常用快捷键</h1><p>Jupyter Notebook 有两种键盘输入模式。编辑模式，允许你往单元中键入代码或文本；这时的单元框线是绿色的。命令模式，键盘输入运行程序命令；这时的单元框线是灰色。</p><h2 id="命令模式-按键-Esc-开启"><a href="#命令模式-按键-Esc-开启" class="headerlink" title="命令模式 (按键 Esc 开启)"></a>命令模式 (按键 Esc 开启)</h2><ul><li>Enter : 转入编辑模式</li><li>Shift-Enter : 运行本单元，选中下个单元</li><li>Ctrl-Enter : 运行本单元</li><li>Alt-Enter : 运行本单元，在其下插入新单元</li><li>Y : 单元转入代码状态</li><li>M :单元转入markdown状态</li><li>R : 单元转入raw状态</li><li>1 : 设定 1 级标题</li><li>2 : 设定 2 级标题</li><li>3 : 设定 3 级标题</li><li>4 : 设定 4 级标题</li><li>5 : 设定 5 级标题</li><li>6 : 设定 6 级标题</li><li>Up : 选中上方单元</li><li>K : 选中上方单元</li><li>Down : 选中下方单元</li><li>J : 选中下方单元</li><li>Shift-K : 扩大选中上方单元</li><li>Shift-J : 扩大选中下方单元</li><li>A : 在上方插入新单元</li><li>B : 在下方插入新单元</li><li>X : 剪切选中的单元</li><li>C : 复制选中的单元</li><li>Shift-V : 粘贴到上方单元</li><li>V : 粘贴到下方单元</li><li>Z : 恢复删除的最后一个单元</li><li>D,D : 删除选中的单元</li><li>Shift-M : 合并选中的单元</li><li>Ctrl-S : 文件存盘</li><li>S : 文件存盘</li><li>L : 转换行号</li><li>O : 转换输出</li><li>Shift-O : 转换输出滚动</li><li>Esc : 关闭页面</li><li>Q : 关闭页面</li><li>H : 显示快捷键帮助</li><li>I,I : 中断Notebook内核</li><li>0,0 : 重启Notebook内核</li><li>Shift : 忽略</li><li>Shift-Space : 向上滚动</li><li>Space : 向下滚动<h2 id="编辑模式-Enter-键启动"><a href="#编辑模式-Enter-键启动" class="headerlink" title="编辑模式 ( Enter 键启动)"></a>编辑模式 ( Enter 键启动)</h2></li><li>Tab : 代码补全或缩进</li><li>Shift-Tab : 提示</li><li>Ctrl-] : 缩进</li><li>Ctrl-[ : 解除缩进</li><li>Ctrl-A : 全选</li><li>Ctrl-Z : 复原</li><li>Ctrl-Shift-Z : 再做</li><li>Ctrl-Y : 再做</li><li>Ctrl-Home : 跳到单元开头</li><li>Ctrl-Up : 跳到单元开头</li><li>Ctrl-End : 跳到单元末尾</li><li>Ctrl-Down : 跳到单元末尾</li><li>Ctrl-Left : 跳到左边一个字首</li><li>Ctrl-Right : 跳到右边一个字首</li><li>Ctrl-Backspace : 删除前面一个字</li><li>Ctrl-Delete : 删除后面一个字</li><li>Esc : 进入命令模式</li><li>Ctrl-M : 进入命令模式</li><li>Shift-Enter : 运行本单元，选中下一单元</li><li>Ctrl-Enter : 运行本单元</li><li>Alt-Enter : 运行本单元，在下面插入一单元</li><li>Ctrl-Shift– : 分割单元</li><li>Ctrl-Shift-Subtract : 分割单元</li><li>Ctrl-S : 文件存盘</li><li>Shift : 忽略</li><li>Up : 光标上移或转入上一单元</li><li>Down :光标下移或转入下一单元</li></ul>]]></content>
      
      
      <categories>
          
          <category> 使用指南 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Anaconda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性回归实战——波士顿房价预测</title>
      <link href="/2021/11/27/MLPJ_LinearRegression/"/>
      <url>/2021/11/27/MLPJ_LinearRegression/</url>
      
        <content type="html"><![CDATA[<blockquote><p>利用马萨诸塞州波士顿郊区的房屋信息数据，使用线性回归模型训练和测试一个房价预测模型，并对模型的性能和预测能力进行测试分析。使用的编程语言是python，主要使用了pandas、matplotlib、sklearn这几个包。</p></blockquote><h1 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h1><p>Boston房价数据<a href="https://pan.baidu.com/s/159UUzzYBukFT9pBn1vJ4fg">下载地址</a>，提取码：nefu</p><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 载入波士顿房屋的数据集</span></span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;Boston.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># print(data)</span></span><br><span class="line"><span class="comment"># print(type(data))</span></span><br><span class="line">Y = data[<span class="string">&#x27;MEDV&#x27;</span>]</span><br><span class="line">X = data.drop(<span class="string">&#x27;MEDV&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># print(Y)</span></span><br><span class="line"><span class="comment"># print(X)</span></span><br><span class="line"><span class="comment"># 完成</span></span><br><span class="line"><span class="comment"># print(X.shape) # 输出数据集的样本数，每个样本的特征数</span></span><br><span class="line"><span class="comment"># print(X.iloc[0]) # 查看第一个数据</span></span><br></pre></td></tr></table></figure><hr><h1 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h1><p>加载数据后，不要直接急匆匆地上各种处理手段，加各种模型，先慢一点，对数据进行一个初步的了解，了解其各个特征的统计值、分布情况、与目标特征的关系，最好进行可视化，这样会看到很多意料之外的东西。</p><h2 id="基础统计运算"><a href="#基础统计运算" class="headerlink" title="基础统计运算"></a>基础统计运算</h2><p>统计运算用于了解某个特征的整体取值情况，它的最大最小值，平均值中位数，百分数，这些都是最简单的对一个字段进行了解的手段。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># print(data.describe()) # 可以查看各个特征取值的情况，最小值，最大值，均值，方差等</span></span><br><span class="line"><span class="comment"># print(data.head()) # 查看前5个数据</span></span><br><span class="line"><span class="comment"># print(data.dtypes) # 可以查看样本的属性名及数据类型</span></span><br></pre></td></tr></table></figure><h2 id="特征观察"><a href="#特征观察" class="headerlink" title="特征观察"></a>特征观察</h2><p>这里主要考虑各个特征与目标之间的关系，比如是正相关还是负相关，通常都是通过对业务的了解而来的，这里就延申出一个点，机器学习项目通常来说，对业务越了解，越容易得到好的效果，因为所谓的特征工程其实就是<strong>理解业务、深挖业务</strong>的过程。<br><code>比如这个问题中的三个特征：</code></p><ol><li>RM：房间个数明显应该是与房价正相关的；</li><li>LSTAT：低收入比例一定程度上表示着这个社区的级别，因此应该是负相关；</li><li>PTRATIO：学生/教师比例越高，说明教育资源越紧缺，也应该是负相关；</li></ol><p>上述这三个点，同样可以用可视化的方式来验证，事实上也应该去验证而不是只靠主观猜想，有些情况下，主观感觉与客观事实是完全相反的，这里要注意。</p><hr><h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><p>为了验证模型的好坏，通常的做法是进行 <code>cv</code>，即交叉验证，基本思路是将数据平均划分 <code>N</code> 块，取其中 <code>N-1</code> 块训练，并对另外 <code>1</code> 块进行做预测，并对比预测结果与实际结果，这个过程反复 <code>N</code> 次直到每一块都作为验证数据使用过。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"><span class="comment"># print(X_train.shape) # (404, 13)</span></span><br><span class="line"><span class="comment"># print(X_test.shape) # (102, 13)</span></span><br><span class="line"><span class="comment"># print(y_train.shape) # (404)</span></span><br><span class="line"><span class="comment"># print(y_test.shape) # (102)</span></span><br></pre></td></tr></table></figure><hr><h1 id="定义评价函数"><a href="#定义评价函数" class="headerlink" title="定义评价函数"></a>定义评价函数</h1><p>这里主要是根据问题来定义，比如分类问题用的最多的是准确率（精确率、召回率也有使用，具体看业务场景更重视什么），回归问题用 <code>RMSE</code> （均方误差) 等等，实际项目中会根据业务特点定义评价函数。</p><hr><h1 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">model = LinearRegression()</span><br><span class="line"></span><br><span class="line">start = time.process_time()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">train_score = model.score(X_train, y_train) <span class="comment"># 采用R2为评价函数</span></span><br><span class="line">cv_score = model.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;elaspe: &#123;0:.6f&#125;; train_score: &#123;1:.6f&#125;; cv_score: &#123;2:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(time.process_time() - start, train_score,</span><br><span class="line">                                                                        cv_score))</span><br></pre></td></tr></table></figure><p>从结果可以看出，模型拟合效果一般，所以还需要进行模型优化。</p><hr><h1 id="模型调优"><a href="#模型调优" class="headerlink" title="模型调优"></a>模型调优</h1><p>首先观察一下数据，特征数据的范围相差比较大，最小的在10^-3^级别，而最大的在10^2^级别，所以需要数据归一化处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">linear_regression = make_pipeline(StandardScaler(with_mean=<span class="literal">False</span>), LinearRegression())</span><br><span class="line">start = time.process_time()</span><br><span class="line">linear_regression.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">train_score = linear_regression.score(X_train, y_train)</span><br><span class="line">cv_score = linear_regression.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;elaspe: &#123;0:.6f&#125;; train_score: &#123;1:.6f&#125;; cv_score: &#123;2:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(time.process_time() - start, train_score,</span><br><span class="line">                                                                        cv_score))</span><br></pre></td></tr></table></figure><p>从之前的训练分数上来，可以观察到数据对训练样本数据的评分比较低，即数据对训练数据的欠拟合。所以可以通过低成本的方案，即增加多项式特征看能否优化模型的性能。增加多项式特征，其实就是增加模型的复杂度。<br><strong>编写创建多项式模型的函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">polynomial_model</span>(<span class="params">degree=<span class="number">1</span></span>):</span></span><br><span class="line">    polynomial_features = PolynomialFeatures(degree=degree,</span><br><span class="line">                                             include_bias=<span class="literal">False</span>)</span><br><span class="line">    linear_regression = make_pipeline(StandardScaler(with_mean=<span class="literal">False</span>), LinearRegression())</span><br><span class="line">    pipeline = Pipeline([(<span class="string">&quot;polynomial_features&quot;</span>,</span><br><span class="line">                          polynomial_features),</span><br><span class="line">                         (<span class="string">&quot;linear_regression&quot;</span>, linear_regression)])</span><br><span class="line">    <span class="keyword">return</span> pipeline</span><br></pre></td></tr></table></figure><p>接着使用二阶多项式来拟合数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model = polynomial_model(degree=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">start = time.process_time()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line">train_score = model.score(X_train, y_train)</span><br><span class="line">cv_score = model.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;elaspe: &#123;0:.6f&#125;; train_score: &#123;1:.6f&#125;; cv_score: &#123;2:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(time.process_time() - start, train_score,</span><br><span class="line">                                                                        cv_score))</span><br></pre></td></tr></table></figure><p>从训练分数和测试分数都提高了，看来模型缺失得到了优化。我们可以把多项式改为三阶看一下结果，从结果可以看出出现了过拟合。</p><hr><h1 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h1><p>更好的方法是画出学习曲线，这样对模型的状态以及优化方向一目了然。</p><ol><li>首先编写 <code>utils,py</code></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> learning_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> ShuffleSplit</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_learning_curve</span>(<span class="params">estimator, title, X, y, ylim=<span class="literal">None</span>, cv=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                        n_jobs=<span class="number">1</span>, train_sizes=np.linspace(<span class="params"><span class="number">.1</span>, <span class="number">1.0</span>, <span class="number">5</span></span>)</span>):</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.title(title)</span><br><span class="line">    <span class="keyword">if</span> ylim <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        plt.ylim(*ylim)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;Training examples&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;Score&quot;</span>)</span><br><span class="line">    train_sizes, train_scores, test_scores = learning_curve(</span><br><span class="line">        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)</span><br><span class="line">    train_scores_mean = np.mean(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">    train_scores_std = np.std(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">    test_scores_mean = np.mean(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">    test_scores_std = np.std(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">    plt.grid()</span><br><span class="line"></span><br><span class="line">    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,</span><br><span class="line">                     train_scores_mean + train_scores_std, alpha=<span class="number">0.1</span>,</span><br><span class="line">                     color=<span class="string">&quot;r&quot;</span>)</span><br><span class="line">    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,</span><br><span class="line">                     test_scores_mean + test_scores_std, alpha=<span class="number">0.1</span>, color=<span class="string">&quot;g&quot;</span>)</span><br><span class="line">    plt.plot(train_sizes, train_scores_mean, <span class="string">&#x27;o-&#x27;</span>, color=<span class="string">&quot;r&quot;</span>,</span><br><span class="line">             label=<span class="string">&quot;Training score&quot;</span>)</span><br><span class="line">    plt.plot(train_sizes, test_scores_mean, <span class="string">&#x27;o-&#x27;</span>, color=<span class="string">&quot;g&quot;</span>,</span><br><span class="line">             label=<span class="string">&quot;Cross-validation score&quot;</span>)</span><br><span class="line"></span><br><span class="line">    plt.legend(loc=<span class="string">&quot;best&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    digits = load_digits()</span><br><span class="line">    X, y = digits.data, digits.target  <span class="comment"># 加载样例数据</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 图一</span></span><br><span class="line">    title = <span class="string">r&quot;Learning Curves (Naive Bayes)&quot;</span></span><br><span class="line">    cv = ShuffleSplit(n_splits=<span class="number">100</span>, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    estimator = GaussianNB()  <span class="comment"># 建模</span></span><br><span class="line">    plot_learning_curve(estimator, title, X, y, ylim=(<span class="number">0.7</span>, <span class="number">1.01</span>), cv=cv, n_jobs=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 图二</span></span><br><span class="line">    title = <span class="string">r&quot;Learning Curves (SVM, RBF kernel, $\gamma=0.001$)&quot;</span></span><br><span class="line">    cv = ShuffleSplit(n_splits=<span class="number">10</span>, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    estimator = SVC(gamma=<span class="number">0.001</span>)  <span class="comment"># 建模</span></span><br><span class="line">    plot_learning_curve(estimator, title, X, y, (<span class="number">0.7</span>, <span class="number">1.01</span>), cv=cv, n_jobs=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="2"><li>导入<code>utils</code> 的 <code>plot_learing_curve</code>，并分别绘制，一阶，二阶，三阶多项式的训练误差以及交叉验证误差的图像。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> plot_learning_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> ShuffleSplit</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">cv = ShuffleSplit(n_splits=<span class="number">100</span>, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br><span class="line">title = <span class="string">&#x27;Learning Curves (degree=&#123;0&#125;)&#x27;</span></span><br><span class="line">degrees = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">start = time.process_time()</span><br><span class="line"><span class="comment"># plt.figure(figsize=(18, 4), dpi=200)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(degrees)):</span><br><span class="line">    <span class="comment"># print(i+1)</span></span><br><span class="line">    <span class="comment"># print(degrees[i])</span></span><br><span class="line">    <span class="comment"># plt.subplot(1, 3, i+1)</span></span><br><span class="line">    plot_learning_curve(polynomial_model(degrees[i]), title.<span class="built_in">format</span>(degrees[i]), X, Y, (<span class="number">0.7</span>, <span class="number">1.01</span>), cv=cv, n_jobs=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;elaspe: &#123;0:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(time.process_time() - start))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/66623becb2d940439aa97fed9d9a60be.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="一阶"><br><img src="https://img-blog.csdnimg.cn/d007338427ae4c53ba9d212a83064877.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="二阶"><br><img src="https://img-blog.csdnimg.cn/88cb66260a7343f0b81101c70a833646.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="三阶"><br>我们可以清楚的看到，一阶欠拟合，二阶是最好的，三阶过拟合。</p><hr><h1 id="手写版线性回归"><a href="#手写版线性回归" class="headerlink" title="手写版线性回归"></a>手写版线性回归</h1><p>再附一个没有用 <code>sklearn</code> 科学包的版本，有兴趣的可以自己研究一下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_test_split</span>(<span class="params">X, Y, test_size=<span class="number">0.25</span>, random_state=<span class="literal">None</span></span>):</span></span><br><span class="line">    X_test = X.sample(frac=test_size, random_state=random_state)</span><br><span class="line">    X_test = X_test.sort_index()</span><br><span class="line">    Y_test = Y[X.index.isin(X_test.index)]</span><br><span class="line">    X_train = X[~X.index.isin(X_test.index)]</span><br><span class="line">    Y_train = Y[~Y.index.isin(Y_test.index)]</span><br><span class="line">    <span class="keyword">return</span> X_train, Y_train, X_test, Y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算均方误差</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_cost</span>(<span class="params">W, x, y</span>):</span></span><br><span class="line">    y_hat = np.matmul(x, W)</span><br><span class="line">    temp = np.matmul((y_hat - y).T, (y_hat - y))</span><br><span class="line">    <span class="keyword">return</span> temp / (<span class="number">2</span> * y.size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最小-最大标准化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">uniform_norm</span>(<span class="params">x</span>):</span></span><br><span class="line">    X_max = np.amax(x, axis=<span class="number">0</span>)</span><br><span class="line">    X_min = np.amin(x, axis=<span class="number">0</span>)</span><br><span class="line">    uni_train_x = (x - X_min) / (X_max - X_min)</span><br><span class="line">    <span class="keyword">return</span> uni_train_x, X_max, X_min</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">W, x, y, iterations=<span class="number">100000</span>, learn=<span class="number">0.001</span>, threshold=<span class="number">1e-6</span>, lamda=<span class="number">0.03</span></span>):</span></span><br><span class="line">    error = np.empty(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">        y_hat = np.matmul(x, W)</span><br><span class="line">        W = W - learn * (np.matmul(x.T, np.matmul(x, W)-y) / y.size + lamda*W)</span><br><span class="line">        <span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            error = np.insert(error, error.size, values=cal_cost(W, x, y)[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">            <span class="keyword">if</span> error.size &gt; <span class="number">2</span> <span class="keyword">and</span> error[-<span class="number">2</span>] - error[-<span class="number">1</span>] &lt; threshold:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> W, error</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;Boston.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">Y = data[<span class="string">&#x27;MEDV&#x27;</span>]</span><br><span class="line">X = data.drop(<span class="string">&#x27;MEDV&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">X_train, Y_train, X_test, Y_test = train_test_split(X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">x_train = np.array(X_train)</span><br><span class="line">y_train = np.array(Y_train)</span><br><span class="line">x_test = np.array(X_test)</span><br><span class="line">y_test = np.array(Y_test)</span><br><span class="line"></span><br><span class="line">uni_train_x, X_max, X_min = uniform_norm(x_train)</span><br><span class="line">uni_test_x = (x_test - X_min) / (X_max - X_min)</span><br><span class="line"></span><br><span class="line">uni_train_x = np.insert(uni_train_x, <span class="number">0</span>, values=np.ones(uni_train_x.shape[<span class="number">0</span>]), axis=<span class="number">1</span>)</span><br><span class="line">uni_test_x = np.insert(uni_test_x, <span class="number">0</span>, values=np.ones(uni_test_x.shape[<span class="number">0</span>]), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">y_train = np.resize(y_train, (y_train.size, <span class="number">1</span>))</span><br><span class="line">y_test = np.resize(y_test, (y_test.size, <span class="number">1</span>))</span><br><span class="line">W = np.zeros(X.shape[<span class="number">1</span>] + <span class="number">1</span>)</span><br><span class="line">W = np.resize(W, (W.size, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">W, error = train(W, uni_train_x, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">plt.plot(error)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算测试集误差</span></span><br><span class="line">test_error = cal_cost(W, uni_test_x, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试集误差为 &quot;</span> + <span class="built_in">str</span>(test_error[<span class="number">0</span>][<span class="number">0</span>]))</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 线性回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习(一)——线性回归</title>
      <link href="/2021/11/24/ML1_LinearRegression/"/>
      <url>/2021/11/24/ML1_LinearRegression/</url>
      
        <content type="html"><![CDATA[<p>在详细了解线性回归的所有知识点之前，我们先来了解一下线性回归的重要性。</p><ul><li>理论层面的重要性</li></ul><ol><li>Linear Regression：是回归问题的基础</li><li>Logistic Regression：是分类问题的基础</li><li>可扩展性：使用基函数来解决非线性问题</li></ol><ul><li>应用层面的重要性——在工业中最广泛应用的模型</li></ul><ol><li>高效易用（简单、易训练）</li><li>可解释性强（参数直接反应特征强弱）</li><li>适合预估（概率形式）</li><li>资源丰富（开源资料、文档、文献、论文）<span id="more"></span></li></ol><hr><h1 id="建立模型基本形式"><a href="#建立模型基本形式" class="headerlink" title="建立模型基本形式"></a>建立模型基本形式</h1><p>数据集一共有 <code>p</code> 个数据点，每个数据点有 <code>d</code> 个描述的维度 <code>xi=(xi1,xi2,xi3...xid)</code> 其中 <code>xi</code> 是第 <code>i</code> 个数据点。线性模型试图学习到一个通过属性的线性组合来进行预测的函数。<br><img src="https://img-blog.csdnimg.cn/40ded2b41ef44d928ad07e0ba055e40c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="模型基本形式"><br>一般写成向量形式：f(x)=W^T^x+b，其中参数 <code>W</code> 和 <code>b</code> 通过训练得出。</p><hr><h1 id="衡量预测值与真实值的距离"><a href="#衡量预测值与真实值的距离" class="headerlink" title="衡量预测值与真实值的距离"></a>衡量预测值与真实值的距离</h1><p>我们的目标肯定是模型预测出来的结果和真实结果越接近越好，即 <code>f(xi)≈yi</code>。这里解释一下为什么只能无限接近，因为我们只能拿某一类事件所有数据中抽样出来的部分数据进行学习，抽样出来的数据不可能涵盖事件的所有的可能性，所以只能学习到总体的规律。</p><p><strong>问题：如何衡量预测的准确性，即衡量f(x)与真实值y之间的差异？</strong></p><ol><li>   误差平方和<code>SSE</code>判别<br><img src="https://img-blog.csdnimg.cn/0d037a84693d4a94938b925919411561.png" alt="误差平方和">    <strong>解释</strong>：由于误差有正有负，故使用平方和来抵消正负    <strong>问题</strong>：一是使用平方后会放大(差&gt;1)部分的误差，同时缩小(-1&lt;差&lt;1)部分的误差；<br>二是当不同维度之间的度量差异很大时无法处理。例如：衡量一个人有年龄和收入两个维度，两个维度相差100倍以上，模型会严重受到收入大小的影响，要求在建模前对数据进行归一化处理；</li><li>   欧式距离判别<br><img src="https://img-blog.csdnimg.cn/f680c6d813be4045a00d97001e756c3b.png" alt="欧式距离判别"></li></ol><p><strong>问题</strong>：一是带根号，求解麻烦；<br>二是当不同维度之间的度量差异很大时无法处理；<br>3.    曼哈顿距离判别<br><img src="https://img-blog.csdnimg.cn/7d444c6588df45cc90f4c7bc2b5872c5.png" alt="曼哈顿距离"><br><strong>问题</strong>：不是连续函数，求导很麻烦，计算不方便，只能计算垂直、水平距离<br><strong>适用场景</strong>：数据稀疏（自带归一化处理）<br>4.    马氏距离判别<br><img src="https://img-blog.csdnimg.cn/5104b542d5fe47b29792d75849b8ae02.png" alt="马氏距离"><br><strong>问题</strong>：带根号，求解麻烦<br><strong>适用场景</strong>：多维数据（流形学习），解决不同维度之间的度量差异很大时的问题<br>5. 其他距离判别方式：汉明距离（Hamming dist）、编辑距离（Levenshtein dist）……</p><hr><h1 id="建立目标函数"><a href="#建立目标函数" class="headerlink" title="建立目标函数"></a>建立目标函数</h1><blockquote><p>我们先讨论一元线性回归。</p></blockquote><p>这里使用均方误差<code>MSE</code>来判定距离，并限定损失函数为<strong>平方损失函数，也就是普通最小二乘法</strong>（Ordinary Least Square，OLS），得到目标函数。其中 “二乘” 表示取平方，”最小” 表示损失函数最小。<br><img src="https://img-blog.csdnimg.cn/e338ed20bb354c1db1e52dbc8a69a785.png" alt="最小二乘法"><br>接下来通过调整参数使得模型能够更加贴合真实数据<br><img src="https://img-blog.csdnimg.cn/2f0fb589e47640b5af9ecb2ef4653b7a.png"><br><img src="https://img-blog.csdnimg.cn/44d9407899584b73ae4ff0a00dc88b82.png"><br><strong>延伸问题：为什么可以用误差平方和来表示线性回归问题的损失函数</strong><br>线性回归有这样的假设：对于给定的 y^(i)^ 总能找到 ε^(i)^ 使得如下等式成立：<br><img src="https://img-blog.csdnimg.cn/c97db4c82bd948728d99c196e6dd42a4.png"><br>ε^(i)^ 代表真实值和预测值之间的误差且服从正态分布 ε^(i)^ ~ Ν(0,σ^2^)</p><p><strong>为什么要加 ε：</strong> 房价可能由 100 种特征共同组成，但是通常我们建模的时候不可能把所有可能性都考虑完全，所以把剩下的特征及噪声统一放到 ε 中考虑。</p><p><strong>为什么误差服从正态分布：</strong> 误差的产生有很多种因素的影响，误差可以看作是这些因素(随机变量)之和共同作用而产生的，由中心极限定理可知随机变量和的分布近似的服从正态分布。</p><p>随机变量 ε^(i)^ 的概率密度函数为：<br><img src="https://img-blog.csdnimg.cn/64bf9d2d4912491fa4c8bcc617498a66.png"><br>代入  ε^(i)^ = y^(i)^-h<del>θ</del>(x^(i)^)则：<br><img src="https://img-blog.csdnimg.cn/a1794543a951457fafdb5e4ad2f525a0.png"><br>这里的 p(y^(i)^|x^(i)^;θ) 并不代表条件概率，只是一个记号，它表示给定 x^(i)^,y^(i)^和一组θ后的概率密度函数。由<strong>最大似然估计</strong>可知：<br><img src="https://img-blog.csdnimg.cn/b42f5a348e764853a19daf688f3a6501.png"><br>对 <code>L(θ)</code> 取对数从而得到对数化最大似然估计函数：<br><img src="https://img-blog.csdnimg.cn/d752df33d5f6421684d5441e7725fecb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>求解最大化对数似然函数可得：<br><img src="https://img-blog.csdnimg.cn/ceb609f0c0b841f4939521711754645d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br>可以发现两种方法推导出的损失函数都是一样的，我们把这种损失函数叫做<strong>最小二乘法</strong>。<br><img src="https://img-blog.csdnimg.cn/5e47e5fe23e04f27977644b52c7d2aff.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="最小二乘法"></p><hr><h1 id="求w和b的参数"><a href="#求w和b的参数" class="headerlink" title="求w和b的参数"></a>求w和b的参数</h1><p>可以看出最小二乘法得到的cost function是一个凸函数，可以看作一元二次方程，目标是求该方程的最小值，即求一元二次方程导数逼近0的点。介绍两种方法，一种通过矩阵运算得到精确解的方法，另一种在数据量巨大数据情况复杂时使用的逼近最优解的方法：梯度下降法</p><h2 id="方法1-解析解"><a href="#方法1-解析解" class="headerlink" title="方法1. 解析解"></a>方法1. 解析解</h2><ol><li>一元线性回归<br><img src="https://img-blog.csdnimg.cn/5047b9a537e84ce29eaeffa68f9207cc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="一元线性回归"><br>E<del>(w,b)</del> 是关于 w 和 b 的凸函数，当它关于 w 和 b 的导数均为0时，得到 w 和 b 的最优解<br><img src="https://img-blog.csdnimg.cn/1563d7468c31492ea64b03959a344c17.png"><br><img src="https://img-blog.csdnimg.cn/962666509c9c41d9a526a04c5b80c753.png"></li></ol><p><strong>解得</strong><br><img src="https://img-blog.csdnimg.cn/857864ca4b6d476c9054c829218d8848.png"><br><img src="https://img-blog.csdnimg.cn/42254c5d02844bb08b20a50da78ddc2d.png"></p><ol start="2"><li>多元线性回归<br>比一元线性回归复杂的是，多元线性回归组成的不是直线，是一个多维空间中的超平面，数据点散落在超平面两侧。<br><img src="https://img-blog.csdnimg.cn/1a13a09a01ef4f888e21ec92632efbe7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="二元线性回归"><br>将偏置项 b 放入参数矩阵 W 中，并在自变量 X 矩阵中增加一列 value 为 1 的列向量<br>用 W 表示 (w,b)，求具体的参数：<br><img src="https://img-blog.csdnimg.cn/f74d0373d2fa478fa3e996ccb0b368d7.png"><br><img src="https://img-blog.csdnimg.cn/3a4110da3c574acc807711f303457316.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/b20337d5605846a39a6f661403499c22.png"></li></ol><p><strong>问题：X^T^X 在现实任务中往往不是满秩矩阵，所以无法求解矩阵的逆，故无法求得唯一的解</strong><br><strong>解决方法：引入正则化(regularization)将矩阵补成满秩</strong><br><strong>I2正则(ridge regression)：</strong><br><img src="https://img-blog.csdnimg.cn/f2c67543412042c9af8e6ffdaa516111.png"><br>使用了正则化后，X 被补成了满秩矩阵，即使3个变量拥有3个方程，使n个变量拥有n个方程，使得 W^*^  变得唯一：<br><img src="https://img-blog.csdnimg.cn/f20ac462d0b743c689da54a8d0184448.png"><br><strong>正则化其它作用：限制模型复杂度，取效果最好但是模型最简单的参数组合</strong><br><strong>其它正则化方式：</strong> 岭回归、lasso回归、弹性网络（l1、l2的结合）<br><a href="https://blog.csdn.net/jinping_shi/article/details/52433975">补充：I1正则与I2正则对比</a></p><h2 id="方法2-梯度下降法"><a href="#方法2-梯度下降法" class="headerlink" title="方法2. 梯度下降法"></a>方法2. 梯度下降法</h2><p>梯度下降：随机初始化 w 和 b，通过逼近的方式来求解。<br><img src="https://img-blog.csdnimg.cn/6865a94de6714850896b55538ba4a672.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="梯度下降"><br>损失函数回顾：<br><img src="https://img-blog.csdnimg.cn/d076081f8d504f7a83ec69a8b8178f3d.png"><br>梯度下降参数优化方法：<br><img src="https://img-blog.csdnimg.cn/93683bba20a74521bb83d8e6049487c6.png"><br><strong>梯度下降形象解释：</strong> 把损失函数想象成一个山坡，目标是找到山坡最低的点。则随便选一个起点，计算损失函数对于参数矩阵在该点的偏导数，每次往偏导数的反向向走一步，步长通过 [公式] 来控制，直到走到最低点，即导数趋近于0的点为止。<br><strong>缺点：</strong> 最小点时候收敛速度变慢，并且对初始点的选择极为敏感。</p><blockquote><p>梯度下降有时会陷入局部最优解的问题中，即下山的路上有好多小坑，运气不好掉进坑里，但是由于底部梯度(导数)也为0，故以为找到了山的底部<br>同时，步长选择的过大或者过小，都会影响模型的计算精度及计算效率</p></blockquote><p><strong>解决方法：</strong> 随机梯度下降、批量梯度下降、动量梯度下降</p><h2 id="方法对比"><a href="#方法对比" class="headerlink" title="方法对比"></a>方法对比</h2><h3 id="相同点"><a href="#相同点" class="headerlink" title="相同点"></a>相同点</h3><ol><li>本质相同：两种方法都是在给定已知数据（independent &amp; dependent variables）的前提下对dependent variables算出出一个一般性的估值函数。然后对给定新数据的dependent variables进行估算。</li><li>目标相同：都是在已知数据的框架内，使得估算值与实际值的总平方差尽量更小（事实上未必一定要使用平方）<h3 id="不同点"><a href="#不同点" class="headerlink" title="不同点"></a>不同点</h3></li></ol><p><strong>解析解</strong></p><ol><li>不需要选择 α。</li><li>不需要迭代。</li><li>但是需要计算 (X^T^X)^-1^，如果 X 是个 (n,p) 矩阵，则求逆的算法的时间复杂度为 O(np^2^) ≈ O(n^3^)，n 是特征的数量，如果特征很多，运算就会很慢。</li><li>不适用于更加复杂的算法，比如 <code>logistic回归</code>。</li></ol><p><strong>梯度下降</strong></p><ol><li>需要选择 α（学习率）。</li><li>需要多次迭代。</li><li>特征很多的情况下也能良好运行。</li></ol><hr><h1 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h1><p>模型建好了，我们需要设计相关的指标来检验模型的表现。有人会问，最小二乘法不就是评价指标吗，和这里的评价指标有什么区别？</p><p>从概念上讲，两者都是评价指标没什么区别。但是从使用场景上讲，我们在上文提到的最小二乘法，是我们在用训练数据集训练建模时，为了调整模型参数而确定的评价指标，目的是为了优化模型参数。而这里我们要讲的评价指标，是衡量模型建立好以后，使用别的数据集时（测试数据集、真实数据集）这组模型参数的表现效果，目的是为了选择模型参数</p><p><strong>这里给出准确定义：评价指标是针对将相同的数据，输入不同的算法模型，或者输入不同参数的同一种算法模型，而给出这个算法或者参数好坏的定量指标</strong></p><ol><li>均方误差（SSE）<br>真实值-预测值 然后平方之后求和平均<br><img src="https://img-blog.csdnimg.cn/fde5df2f501b492bbfad375bd2911a1a.png"><br>同样的数据集的情况下，SSE越小，误差越小，模型效果越好</li></ol><p><strong>缺点：</strong> SSE数值大小本身没有意义，随着样本增加，SSE必然增加，也就是说，不同的数据集的情况下，SSE比较没有意义。<br><strong>改进：</strong> MSE 对SSE求平均。是线性回归中最常用的损失函数，线性回归过程中尽量让该损失函数最小。那么模型之间的对比也可以用它来比较<br><img src="https://img-blog.csdnimg.cn/6a49e8bdecac4dcbb17cd6430d199630.png"><br>2. 均方根误差（标准误差 RMSE）<br>MSE是用来衡量一组数自身的离散程度，而RMSE是用来衡量观测值同真值之间的偏差，它们的研究对象和研究目的不同。它的意义在于开个根号后，误差的结果就与数据是一个级别的，可以更好地来描述数据。标准误差对一组测量中的特大或特小误差反映非常敏感，所以，标准误差能够很好地反映出测量的精密度。这正是标准误差在工程测量中广泛被采用的原因<br><img src="https://img-blog.csdnimg.cn/d3bbe9ce1eb842bb854716839ed99619.png"><br>当数据集中有一个特别大的异常值，这种情况下，data会被skew，RMSE会被明显拉大。所以对RMSE低估值（under-predicted）的判罚明显小于估值过高(over-predicted)的情况</p><ol start="3"><li>平均绝对误差（MAE）<br>平均绝对误差是绝对误差的平均值，平均绝对误差能更好地反映预测值误差的实际情况<br><img src="https://img-blog.csdnimg.cn/d54d1e2338824d49a80d5651c3b96c30.png"><br>MAE是一个线性的指标，所有个体差异在平均值上均等加权，所以它更加凸显出异常值。MSE和MAE适用于误差相对明显的时候，此时大的误差也有比较高的权重</li><li>R-square（决定系数）<br>对于回归类算法而言，只探索数据预测是否准确是不足够的。除了数据本身的数值大小之外，我们还希望模型能够捕捉到数据的”规律“，比如数据的分布规律，单调性等等，而是否捕获了这些信息并无法使用MSE或者MAE来衡量<img src="https://img-blog.csdnimg.cn/d8d2b09c08fb4d2b838ac59e088d6554.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_18,color_FFFFFF,t_70,g_se,x_16"><br>其中红色线是我们的真实标签，而蓝色线是我们的拟合模型。这是一种比较极端，但的确可能发生的情况。这张图前半部分的拟合非常成功，看上去真实标签和预测结果几乎重合，但后半部分的拟合却非常糟糕，模型向着与真实标签完全相反的方向去了<br>对于这样的一个拟合模型，如果我们使用MSE来对它 进行判断，它的MSE会很小，因为大部分样本其实都被完美拟合了，少数样本的真实值和预测值的巨大差异在被均分到每个样本上之后，MSE就会很小。但这样的拟合结果必然不是一个好结果，因为一旦新样本是处于拟合曲线的后半段的，预测结果必然会有巨大的偏差。所以，我们希望找到新的指标，除了判断预测的数值是否正确之外，还能够判断我们的模型是否拟合了足够多的，数值之外的信息。<br><img src="https://img-blog.csdnimg.cn/7061110562984b49af318d789e2b93cf.png"></li></ol><p><strong>数学理解：分母理解为原始数据的离散程度，分子为预测数据和原始数据的误差，二者相除可以消除原始数据离散程度的影响</strong>    </p><pre><code>1、上面分子就是我们训练出的模型预测的误差和2.、下面分母就是瞎猜的误差和。（通常取观测值的平均值）3.、如果结果是0，就说明我们的模型跟瞎猜差不多4.、如果结果是1。就说明我们模型无错误5.、介于0~1之间，越接近1，回归拟合效果越好，一般认为超过0.8的模型拟合优度比较高</code></pre><p><strong>化简上面的公式</strong><br>分子分母同时除以m，那么分子就变成了我们的均方误差MSE，下面分母就变成了方差。<br><img src="https://img-blog.csdnimg.cn/9a770458360343dfbc754fb42a1c8a5b.png"><br><img src="https://img-blog.csdnimg.cn/f34363cda1e84b108fe9962dbfa2ccca.png"><br>方差的本质是任意一个值和样本均值的差异，差异越大，这些值所带的信息越多<br>在 <code>R2</code> 中，分子是真实值和预测值之差的差值，也就是我们的模型没有捕获到的信息总量，分母是真实标签所带的信息量，所以两者都衡量 <strong>1 - 我们的模型没有捕获到的信息量占真实标签中所带的信息量的比例</strong>，所以，两者都是越接近1越好<br>缺点：数据集的样本越大，R²越大，因此，不同数据集的模型结果比较会有一定的误差<br>5. Adjusted R-square（校正决定系数）<br><img src="https://img-blog.csdnimg.cn/1194dc8f081646ec882c669824c88368.png"><br>n为样本数量，p为特征数量。同时消除了样本数量和特征数量的影响。</p><hr><h1 id="从Bias和Variance角度看模型复杂度问题"><a href="#从Bias和Variance角度看模型复杂度问题" class="headerlink" title="从Bias和Variance角度看模型复杂度问题"></a>从Bias和Variance角度看模型复杂度问题</h1><p>复杂度高的模型通常对训练数据有很好的拟合能力，但是对测试数据就不一定了。而复杂度太低的模型又不能很好的拟合训练数据，更不能很好的拟合测试数据。因此，模型复杂度和模型偏差和方差具有如下图所示关系。<br><img src="https://img-blog.csdnimg.cn/018d9ef51ea84144b416d635d29b8d65.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_17,color_FFFFFF,t_70,g_se,x_16" alt="偏差方差窘境"><br>更多偏差，方差细节可以看<a href="https://zhuanlan.zhihu.com/p/38853908">这篇文章</a>。</p><hr><h1 id="线性回归的适用场景及前提假设"><a href="#线性回归的适用场景及前提假设" class="headerlink" title="线性回归的适用场景及前提假设"></a>线性回归的适用场景及前提假设</h1><p><img src="https://img-blog.csdnimg.cn/06963518a64847f6b81d7fb515e367d8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemp1X2Nidw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="安斯库姆四重奏"><br>那到底什么时候可以使用线性回归呢？统计学家安斯库姆给出了四个数据集，被称为安斯库姆四重奏，从这四个数据集的分布可以看出，并不是所有的数据集都可以用一元线性回归来建模。现实世界中的问题往往更复杂，变量几乎不可能非常理想化地符合线性模型的要求。因此使用线性回归，需要遵守下面几个假设：</p><ul><li>线性回归是一个回归问题（regression）。</li><li>要预测的变量y与自变量x的关系是线性的。</li><li>各项误差服从正太分布，均值为0，与x同方差。</li><li>变量 x 的分布要有变异性。</li><li> 多元线性回归中不同特征之间应该相互独立，避免线性相关。</li></ul><h2 id="回归问题和分类问题"><a href="#回归问题和分类问题" class="headerlink" title="回归问题和分类问题"></a>回归问题和分类问题</h2><p>与回归相对的是分类问题（classification），分类问题要预测的变量y输出集合是有限的，预测值只能是有限集合内的一个。当要预测的变量y输出集合是无限且连续，我们称之为回归。比如，天气预报预测明天是否下雨，是一个二分类问题；预测明天的降雨量多少，就是一个回归问题。</p><h2 id="变量之间是线性关系"><a href="#变量之间是线性关系" class="headerlink" title="变量之间是线性关系"></a>变量之间是线性关系</h2><p>线性通常是指变量之间保持等比例的关系，从图形上来看，变量之间的形状为直线，斜率是常数。这是一个非常强的假设，数据点的分布呈现复杂的曲线，则不能使用线性回归来建模。可以看出，四重奏右上角的数据就不太适合用线性回归的方式进行建模。</p><h2 id="误差服从均值为零的正态分布"><a href="#误差服从均值为零的正态分布" class="headerlink" title="误差服从均值为零的正态分布"></a>误差服从均值为零的正态分布</h2><p>前面最小二乘法求解过程已经提到了误差的概念，误差可以表示为 <code>误差 = 实际值 - 预测值</code>。</p><p>可以这样理解这个假设：线性回归允许预测值与真实值之间存在误差，随着数据量的增多，这些数据的误差平均值为0；从图形上来看，各个真实值可能在直线上方，也可能在直线下方，当数据足够多时，各个数据上上下下相互抵消。如果误差不服从均值为零的正太分布，那么很有可能是出现了一些异常值，数据的分布很可能是安斯库姆四重奏右下角的情况。</p><p>这也是一个非常强的假设，如果要使用线性回归模型，那么必须假设数据的误差均值为零的正太分布。</p><h2 id="变量-x-的分布要有变异性"><a href="#变量-x-的分布要有变异性" class="headerlink" title="变量 x 的分布要有变异性"></a>变量 x 的分布要有变异性</h2><p>线性回归对变量 <code>x </code> 也有要求，要有一定变化，不能像安斯库姆四重奏右下角的数据那样，绝大多数数据都分布在一条竖线上。</p><h2 id="多元线性回归不同特征之间相互独立"><a href="#多元线性回归不同特征之间相互独立" class="headerlink" title="多元线性回归不同特征之间相互独立"></a>多元线性回归不同特征之间相互独立</h2><p>如果不同特征不是相互独立，那么可能导致特征间产生共线性，进而导致模型不准确。举一个比较极端的例子，预测房价时使用多个特征：<code>房间数量</code>，<code>房间数量*2</code>，<code>-房间数量</code>等，特征之间是线性相关的，如果模型只有这些特征，缺少其他有效特征，虽然可以训练出一个模型，但是模型不准确，预测性差。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 线性回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode542.01矩阵</title>
      <link href="/2021/11/19/Leetcode542/"/>
      <url>/2021/11/19/Leetcode542/</url>
      
        <content type="html"><![CDATA[<h1 id="题目链接"><a href="#题目链接" class="headerlink" title="题目链接"></a>题目链接</h1><p><a href="https://leetcode-cn.com/problems/01-matrix/">点我(^_^)</a></p><h1 id="题目大意"><a href="#题目大意" class="headerlink" title="题目大意"></a>题目大意</h1><p>求矩阵中每个位置到最近0的距离（曼哈顿距离）</p><h1 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h1><span id="more"></span><h2 id="思路1-BFS"><a href="#思路1-BFS" class="headerlink" title="思路1.BFS"></a>思路1.BFS</h2><p><code>bfs</code>特性就是搜到该点了，该点就是最优解了。所以，我们可以将所有位置上为<code>0</code>的入队，这时队列里都是到最近<code>0</code>距离为<code>0</code>的位置，之后按<code>bfs</code>进行操作，即从队首取出一个元素，用它去更新其上、下、左、右四个位置，并入队。需要注意的是，之前已经被更新过的就不用再更新了，在代码部分我们用<code>-1</code>表示尚未被更新，并且我们可以直接在原数组上修改。这样时间复杂度为 <code>O(n*m)</code>，空间复杂度也为 <code>O(n*m)</code>(最坏情况下都是<code>0</code>，所以都要入队)。</p><h2 id="思路2-动态规划"><a href="#思路2-动态规划" class="headerlink" title="思路2.动态规划"></a>思路2.动态规划</h2><p><img src="https://img-blog.csdnimg.cn/a089eb9c46e146afa421622593aadc9e.png" alt="四种情况"><br>这里的距离为曼哈顿距离，所以，如果一个位置被<code>0</code>更新，只有一下四种情况：</p><ol><li><code>0</code>在其左上方，可以通过右移<code>x</code>下移<code>y</code>到该位置</li><li><code>0</code>在其右上方，可以通过左移<code>x</code>下移<code>y</code>到该位置</li><li><code>0</code>在其左下方，可以通过右移<code>x</code>上移<code>y</code>到该位置</li><li><code>0</code>在其右下方，可以通过左移<code>x</code>上移<code>y</code>到该位置</li></ol><p>所以，其实我们只要从四个角动态规划即可，例如从左上角，<code>dp</code>转移方程如下：<br><img src="https://img-blog.csdnimg.cn/63cb06d1844a4d0abcf98f272b7aac34.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="转移方程"><br>这样四次两层循环就可以解决。<strong>实际上，我们只需要两次两层循环就可以解决，例如左上角和右下角。</strong><br>我们先从左上角进行<code>dp</code>，后从右下角进行<code>dp</code>，以下论证为什么这样做包含了右上角以及左下角的情况：</p><ol><li>右上角<br><img src="https://img-blog.csdnimg.cn/e16585b973da416baeb2f669389470b9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="右上角"><br>如果<code>0</code>在其右上角，我们在第一次<code>dp</code>时保存了正上方的信息，第二次<code>dp</code>保存了正右方的信息，这样就可以组合得到右上角<code>0</code>的情况。</li><li>左下角<br><img src="https://img-blog.csdnimg.cn/60255ebd87f24b6b9ff4e4e4df625aec.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_19,color_FFFFFF,t_70,g_se,x_16" alt="左上角"><br>如果<code>0</code>在其左下角，我们在第一次<code>dp</code>时保存了正左方的信息，第二次<code>dp</code>保存了正下方的信息，这样就可以组合得到左下角<code>0</code>的情况。</li></ol><p>这样的话，动态规划的时间复杂度为 <code>O(n*m)</code>，空间复杂度为 <code>O(1)</code> （直接利用原数组进行操作，额外的空间就是常数空间）</p><h1 id="具体代码"><a href="#具体代码" class="headerlink" title="具体代码"></a>具体代码</h1><h2 id="代码1-BFS"><a href="#代码1-BFS" class="headerlink" title="代码1.BFS"></a>代码1.BFS</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; pii;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">updateMatrix</span>(vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt;&amp; mat) &#123;</span><br><span class="line">        <span class="keyword">int</span> tx[<span class="number">4</span>] = &#123;<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">-1</span>&#125;;</span><br><span class="line">        <span class="keyword">int</span> ty[<span class="number">4</span>] = &#123;<span class="number">1</span>,<span class="number">-1</span>,<span class="number">0</span>,<span class="number">0</span>&#125;;</span><br><span class="line">        queue&lt;pii&gt; q;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;mat.<span class="built_in">size</span>(); ++i)</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;mat[<span class="number">0</span>].<span class="built_in">size</span>(); ++j)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>(mat[i][j] == <span class="number">0</span>)</span><br><span class="line">                    q.<span class="built_in">push</span>(<span class="built_in">make_pair</span>(i,j));</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    mat[i][j] = <span class="number">-1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="keyword">while</span>(!q.<span class="built_in">empty</span>())</span><br><span class="line">        &#123;</span><br><span class="line">            pii temp = q.<span class="built_in">front</span>();</span><br><span class="line">            q.<span class="built_in">pop</span>();</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">4</span>; ++i)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">int</span> t_x = temp.first+tx[i];</span><br><span class="line">                <span class="keyword">int</span> t_y = temp.second+ty[i];</span><br><span class="line">                <span class="keyword">if</span>(t_x&lt;<span class="number">0</span> || t_x&gt;=mat.<span class="built_in">size</span>() || t_y&lt;<span class="number">0</span> || t_y&gt;=mat[<span class="number">0</span>].<span class="built_in">size</span>() || mat[t_x][t_y]!=<span class="number">-1</span>)</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                mat[t_x][t_y] = mat[temp.first][temp.second]+<span class="number">1</span>;</span><br><span class="line">                q.<span class="built_in">push</span>(<span class="built_in">make_pair</span>(t_x,t_y));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> mat;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="代码2-动态规划"><a href="#代码2-动态规划" class="headerlink" title="代码2.动态规划"></a>代码2.动态规划</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">updateMatrix</span>(vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt;&amp; mat) &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;mat.<span class="built_in">size</span>(); ++i) </span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;mat[<span class="number">0</span>].<span class="built_in">size</span>(); ++j)</span><br><span class="line">                mat[i][j] = ((mat[i][j]==<span class="number">1</span>)?<span class="number">10000</span>:<span class="number">0</span>);</span><br><span class="line">        <span class="comment">// 左上角</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;mat.<span class="built_in">size</span>(); ++i)</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;mat[<span class="number">0</span>].<span class="built_in">size</span>(); ++j)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>(mat[i][j] != <span class="number">0</span>)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="keyword">if</span>(i<span class="number">-1</span>&gt;=<span class="number">0</span>)</span><br><span class="line">                        mat[i][j] = <span class="built_in">min</span>(mat[i][j], mat[i<span class="number">-1</span>][j]+<span class="number">1</span>);</span><br><span class="line">                    <span class="keyword">if</span>(j<span class="number">-1</span>&gt;=<span class="number">0</span>)</span><br><span class="line">                        mat[i][j] = <span class="built_in">min</span>(mat[i][j], mat[i][j<span class="number">-1</span>]+<span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="comment">// 右下角</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=mat.<span class="built_in">size</span>()<span class="number">-1</span>; i&gt;=<span class="number">0</span>; i--)</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=mat[<span class="number">0</span>].<span class="built_in">size</span>()<span class="number">-1</span>; j&gt;=<span class="number">0</span>; j--)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>(mat[i][j] != <span class="number">0</span>)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="keyword">if</span>(i+<span class="number">1</span>&lt;mat.<span class="built_in">size</span>())</span><br><span class="line">                        mat[i][j] = <span class="built_in">min</span>(mat[i][j], mat[i+<span class="number">1</span>][j]+<span class="number">1</span>);</span><br><span class="line">                    <span class="keyword">if</span>(j+<span class="number">1</span>&lt;mat[<span class="number">0</span>].<span class="built_in">size</span>())</span><br><span class="line">                        mat[i][j] = <span class="built_in">min</span>(mat[i][j], mat[i][j+<span class="number">1</span>]+<span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="keyword">return</span> mat;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 力扣刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
            <tag> 动态规划 </tag>
            
            <tag> BFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode132.分隔回文串 II</title>
      <link href="/2021/11/16/Leetcode132/"/>
      <url>/2021/11/16/Leetcode132/</url>
      
        <content type="html"><![CDATA[<h1 id="题目链接"><a href="#题目链接" class="headerlink" title="题目链接"></a>题目链接</h1><p><a href="https://leetcode-cn.com/problems/palindrome-partitioning-ii/">点我(^_^)</a></p><h1 id="题目大意"><a href="#题目大意" class="headerlink" title="题目大意"></a>题目大意</h1><p>返回最少地将字符串<code>s</code>分隔成全是回文子串的次数</p><h1 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h1><span id="more"></span><p>其实很容易就能想到，如果 <code>dp[i]</code> 表示将 <code>s[0]</code>~<code>s[i]</code>分隔成全是回文子串的最少次数，那么就会有如下状态转移方程。<br><img src="https://img-blog.csdnimg.cn/dc2d7b97ac7d4468a172cd3a4f680e83.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="转移方程"><br>这样做的时间复杂度是 <code>O(n^2)*(每次判断是否为回文串的时间)</code>，所以我们只要能 <code>O(1)</code> 判断是否为回文串，这题就迎刃而解了，如果是 <code>O(1)</code>，那就必然是要预处理。我们可以这样想，如果 <code>s[i+1]...s[j-1]</code> 已经为回文串了，那么如果 <code>s[i]==s[j]</code>，那么此时 <code>s[i]...s[j]</code> 也为回文串，这样的话长的字符串由短的字符串转移，可以使用动态规划，我们用 <code>check[i][j]</code> 表示 <code>s[i]...s[j]</code> 是否为回文串，那么可以得到如下转移方程。<br><img src="https://img-blog.csdnimg.cn/fd817cb073c341a6ab6b9b6c8bdb914a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="转移方程"><br>需要注意的是，我们第一层循环要枚举长度，因为只有所有短的都已知，才能正确判断长的。</p><h1 id="具体代码"><a href="#具体代码" class="headerlink" title="具体代码"></a>具体代码</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">minCut</span><span class="params">(string s)</span> </span>&#123;</span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">bool</span>&gt;&gt; <span class="built_in">check</span>(s.<span class="built_in">size</span>(),vector&lt;<span class="keyword">bool</span>&gt;(s.<span class="built_in">size</span>(),<span class="literal">true</span>));</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> len=<span class="number">2</span>; len&lt;=s.<span class="built_in">size</span>(); ++len)</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;s.<span class="built_in">size</span>(); ++i)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">int</span> j = i+len<span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">if</span>(j &gt;= s.<span class="built_in">size</span>())</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                check[i][j] = check[i+<span class="number">1</span>][j<span class="number">-1</span>] &amp;&amp; (s[i]==s[j]);</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">dp</span><span class="params">(s.size(), <span class="number">2005</span>)</span></span>;    </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;s.<span class="built_in">size</span>(); ++i)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(check[<span class="number">0</span>][i])</span><br><span class="line">                dp[i] = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;i; ++j)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="keyword">if</span>(check[j+<span class="number">1</span>][i])</span><br><span class="line">                        dp[i] = <span class="built_in">min</span>(dp[i], dp[j]+<span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[s.<span class="built_in">size</span>()<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 力扣刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
            <tag> 动态规划 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb书城项目(十)———Filter过滤器和Aajx请求</title>
      <link href="/2021/11/12/JavaWeb_BookProject_10/"/>
      <url>/2021/11/12/JavaWeb_BookProject_10/</url>
      
        <content type="html"><![CDATA[<blockquote><p>整个项目源代码可以到我的github上下载。前九个部分我们大致完成了书城项目的所有功能，第十部分我们做一个结尾，主要包括使用Filter过滤器进行权限检查，使用Filter和ThreadLocal组合管理事务，将异常同一交给Tomcat并展示友好的错误页面，使用Aajx请求改进功能。</p></blockquote><h1 id="Filter过滤器实现权限检查"><a href="#Filter过滤器实现权限检查" class="headerlink" title="Filter过滤器实现权限检查"></a>Filter过滤器实现权限检查</h1><p>我们要使用 Filter 过滤器拦截/pages/manager/所有内容，实现权限检查。</p><ol><li><p><code>Filter</code>的工作流程如下</p><span id="more"></span><p><img src="https://img-blog.csdnimg.cn/1517e13efad142f58613cf072b7a3332.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="Filter工作流程图"></p></li><li><p><code>Filter</code> 过滤器的使用步骤：</p></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>、 编写一个类去实现 Filter 接口</span><br><span class="line"></span><br><span class="line"><span class="number">2</span>、 实现过滤方法 doFilter()</span><br><span class="line"></span><br><span class="line"><span class="number">3</span>、 到 web.xml 中去配置 Filter</span><br></pre></td></tr></table></figure><ol start="3"><li><code>Filter</code> 的生命周期</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Filter 的生命周期包含几个方法</span><br><span class="line"><span class="number">1</span>、构造器方法</span><br><span class="line"><span class="number">2</span>、init 初始化方法</span><br><span class="line">第 <span class="number">1</span>，<span class="number">2</span> 步，在 web 工程启动的时候执行（Filter 已经创建）</span><br><span class="line"><span class="number">3</span>、doFilter 过滤方法</span><br><span class="line">第 <span class="number">3</span> 步，每次拦截到请求，就会执行</span><br><span class="line"><span class="number">4</span>、destroy 销毁</span><br><span class="line">第 <span class="number">4</span> 步，停止 web 工程的时候，就会执行（停止 web 工程，也会销毁 Filter 过滤器）</span><br></pre></td></tr></table></figure><ol start="4"><li><code>Filter</code> 的拦截路径</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">--精确匹配</span><br><span class="line"><span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/target.jsp<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line">以上配置的路径，表示请求地址必须为：http://ip:port/工程路径/target.jsp </span><br><span class="line"></span><br><span class="line">--目录匹配</span><br><span class="line"><span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/admin/*<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line">以上配置的路径，表示请求地址必须为：http://ip:port/工程路径/admin/* </span><br><span class="line"></span><br><span class="line">--后缀名匹配</span><br><span class="line"><span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>*.html<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line">以上配置的路径，表示请求地址必须以.html 结尾才会拦截到</span><br><span class="line"><span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>*.do<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line">以上配置的路径，表示请求地址必须以.do 结尾才会拦截到</span><br><span class="line"><span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>*.action<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line">以上配置的路径，表示请求地址必须以.action 结尾才会拦截</span><br></pre></td></tr></table></figure><ol start="5"><li>创建<code>ManagerFilter</code>实现类</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ManagerFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doFilter</span><span class="params">(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain)</span> <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line">        HttpServletRequest httpServletRequest = (HttpServletRequest) servletRequest;</span><br><span class="line">        Object user = httpServletRequest.getSession().getAttribute(<span class="string">&quot;user&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (user == <span class="keyword">null</span>) &#123;</span><br><span class="line">            httpServletRequest.getRequestDispatcher(<span class="string">&quot;/pages/user/login.jsp&quot;</span>).forward(servletRequest,servletResponse);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            filterChain.doFilter(servletRequest, servletResponse);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(FilterConfig filterConfig)</span> <span class="keyword">throws</span> ServletException </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="6"><li>配置 <code>web.xml</code> 文件</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">filter</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">filter-name</span>&gt;</span>ManagerFilter<span class="tag">&lt;/<span class="name">filter-name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">filter-class</span>&gt;</span>com.atguigu.filter.ManagerFilter<span class="tag">&lt;/<span class="name">filter-class</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">filter-mapping</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">filter-name</span>&gt;</span>ManagerFilter<span class="tag">&lt;/<span class="name">filter-name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/pages/manager/*<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/manager/bookServlet<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">filter-mapping</span>&gt;</span></span><br></pre></td></tr></table></figure><hr><h1 id="Filter和ThreadLocal组合管理事务"><a href="#Filter和ThreadLocal组合管理事务" class="headerlink" title="Filter和ThreadLocal组合管理事务"></a>Filter和ThreadLocal组合管理事务</h1><ol><li><code>ThreadLocal</code>的作用</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ThreadLocal 的作用，它可以解决多线程的数据安全问题。</span><br><span class="line"></span><br><span class="line">ThreadLocal 它可以给当前线程关联一个数据（可以是普通变量，可以是对象，也可以是数组，集合）</span><br><span class="line"></span><br><span class="line">ThreadLocal 的特点：</span><br><span class="line"><span class="number">1</span>、ThreadLocal 可以为当前线程关联一个数据。（它可以像 Map 一样存取数据，key 为当前线程）</span><br><span class="line"><span class="number">2</span>、每一个 ThreadLocal 对象，只能为当前线程关联一个数据，如果要为当前线程关联多个数据，就需要使用多个</span><br><span class="line">ThreadLocal 对象实例。</span><br><span class="line"><span class="number">3</span>、每个 ThreadLocal 对象实例定义的时候，一般都是 <span class="keyword">static</span> 类型</span><br><span class="line"><span class="number">4</span>、ThreadLocal 中保存数据，在线程销毁后。会由 JVM 虚拟自动释放</span><br></pre></td></tr></table></figure><ol start="2"><li>使用 <code>ThreadLocal</code> 来确保所有 <code>dao</code> 操作都在同一个 <code>Connection</code> 连接对象中完成。<br><img src="https://img-blog.csdnimg.cn/2ad30d8bb1114107a138d5baf055431e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="原理分析图"><br><code>JdbcUtils</code>工具类的修改</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JdbcUtils</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> DruidDataSource dataSource;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> ThreadLocal&lt;Connection&gt; conns = <span class="keyword">new</span> ThreadLocal&lt;Connection&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">            <span class="comment">// 读取jdbc.properties文件</span></span><br><span class="line">            InputStream inputStream = JdbcUtils.class.getClassLoader().getResourceAsStream(<span class="string">&quot;jdbc.properties&quot;</span>);</span><br><span class="line">            <span class="comment">// 从流中加载数据</span></span><br><span class="line">            properties.load(inputStream);</span><br><span class="line">            <span class="comment">// 创建数据库连接池</span></span><br><span class="line">            dataSource = (DruidDataSource) DruidDataSourceFactory.createDataSource(properties);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e)</span><br><span class="line">        &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取数据库连接池中的连接</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 如果返回null，说明获取连接失败 &lt;br/&gt;有值就是成功</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Connection <span class="title">getConnection</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        Connection conn = conns.get();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (conn == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                conn = dataSource.getConnection(); <span class="comment">// 从数据库连接池中获取连接</span></span><br><span class="line">                conns.set(conn); <span class="comment">// 保存到ThreadLocal对象中，供后面的jdbc操作使用</span></span><br><span class="line">                conn.setAutoCommit(<span class="keyword">false</span>); <span class="comment">// 设置为手动提交</span></span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> conn;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 提交事务，并关闭释放连接</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">commitAndClose</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Connection connection = conns.get();</span><br><span class="line">        <span class="keyword">if</span> (connection != <span class="keyword">null</span>) &#123; <span class="comment">// 如果不等于null，说明之前使用过连接，操作过数据库</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                connection.commit(); <span class="comment">// 提交事务</span></span><br><span class="line">            &#125; <span class="keyword">catch</span> (SQLException throwables) &#123;</span><br><span class="line">                throwables.printStackTrace();</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    connection.close();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (SQLException throwables) &#123;</span><br><span class="line">                    throwables.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 一定要执行remove操作，否则就会出错（因为Tomcat服务器底层使用了线程池技术）</span></span><br><span class="line">        conns.remove();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">rollbackAndClose</span><span class="params">()</span></span>&#123;</span><br><span class="line">        Connection connection = conns.get();</span><br><span class="line">        <span class="keyword">if</span> (connection != <span class="keyword">null</span>) &#123; <span class="comment">//如果不等于null，说明之前使用过连接，操作过数据库</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                connection.rollback(); <span class="comment">// 回滚事务</span></span><br><span class="line">            &#125; <span class="keyword">catch</span> (SQLException throwables) &#123;</span><br><span class="line">                throwables.printStackTrace();</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    connection.close(); <span class="comment">//关闭连接释放资源</span></span><br><span class="line">                &#125; <span class="keyword">catch</span> (SQLException throwables) &#123;</span><br><span class="line">                    throwables.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 一定要执行remove操作，否则就会出错（因为Tomcat底层使用了线程池技术）</span></span><br><span class="line">        conns.remove();</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    /**</span></span><br><span class="line"><span class="comment">//     * 关闭连接，放回数据库连接池</span></span><br><span class="line"><span class="comment">//     * @param conn</span></span><br><span class="line"><span class="comment">//     */</span></span><br><span class="line"><span class="comment">//    public static void close(Connection conn)&#123;</span></span><br><span class="line"><span class="comment">//        if(conn != null)</span></span><br><span class="line"><span class="comment">//        &#123;</span></span><br><span class="line"><span class="comment">//            try &#123;</span></span><br><span class="line"><span class="comment">//                conn.close();</span></span><br><span class="line"><span class="comment">//            &#125; catch (Exception e) &#123;</span></span><br><span class="line"><span class="comment">//                e.printStackTrace();</span></span><br><span class="line"><span class="comment">//            &#125;</span></span><br><span class="line"><span class="comment">//        &#125;</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>修改<code>BaseDao</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">BaseDao</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用DbUtils操作数据库</span></span><br><span class="line">    <span class="keyword">private</span> QueryRunner queryRunner = <span class="keyword">new</span> QueryRunner();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * update() 方法用来执行：Insert\Update\Delete语句</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 如果返回-1说明执行失败&lt;br/&gt;返回其它表示影响的行数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">update</span><span class="params">(String sql, Object ... args)</span></span>&#123;</span><br><span class="line">        Connection connection = JdbcUtils.getConnection();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span>  queryRunner.update(connection, sql, args);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询返回一个javaBean的sql语句</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> type 返回的对象类型</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sql 执行的sql语句</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args sql对应的参数值</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> &lt;T&gt; 返回的类型的泛型</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; <span class="function">T <span class="title">queryForOne</span><span class="params">(Class&lt;T&gt; type, String sql, Object ... args)</span></span>&#123;</span><br><span class="line">        Connection con = JdbcUtils.getConnection();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> queryRunner.query(con, sql, <span class="keyword">new</span> BeanHandler&lt;T&gt;(type), args);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询返回多个javaBean的sql语句</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> type 返回的对象类型</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sql 执行的sql语句</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args sql对应的参数值</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> &lt;T&gt; 返回的类型的泛型</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; <span class="function">List&lt;T&gt; <span class="title">queryForList</span><span class="params">(Class&lt;T&gt; type, String sql, Object ... args)</span></span>&#123;</span><br><span class="line">        Connection con = JdbcUtils.getConnection();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> queryRunner.query(con, sql, <span class="keyword">new</span> BeanListHandler&lt;T&gt;(type), args);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 执行返回一行一列的sql语句</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sql 执行的sql语句</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args sql对应的参数值</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">queryForSingleValue</span><span class="params">(String sql, Object ... args)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        Connection conn = JdbcUtils.getConnection();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>  &#123;</span><br><span class="line">            <span class="keyword">return</span> queryRunner.query(conn, sql, <span class="keyword">new</span> ScalarHandler(), args);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>使用 <code>Filter</code> 过滤器统一给所有的 <code>Service</code> 方法都加上 <code>try-catch</code>。来进行实现的管理。<br><img src="https://img-blog.csdnimg.cn/8f136fe931424dcb88865ccefc36d034.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="原理分析图"><br><code>Filter</code>类代码</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TransactionFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doFilter</span><span class="params">(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain)</span> <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            filterChain.doFilter(servletRequest, servletResponse);</span><br><span class="line">            JdbcUtils.commitAndClose(); <span class="comment">// 提交事务</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            JdbcUtils.rollbackAndClose(); <span class="comment">// 回滚事务</span></span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(FilterConfig filterConfig)</span> <span class="keyword">throws</span> ServletException </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配置<code>web.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">filter</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">filter-name</span>&gt;</span>TransactionFilter<span class="tag">&lt;/<span class="name">filter-name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">filter-class</span>&gt;</span>com.atguigu.filter.TransactionFilter<span class="tag">&lt;/<span class="name">filter-class</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">filter-mapping</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">filter-name</span>&gt;</span>TransactionFilter<span class="tag">&lt;/<span class="name">filter-name</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- /* 表示当前工程下所有请求 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/*<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">filter-mapping</span>&gt;</span></span><br></pre></td></tr></table></figure><p>一定要记得把<code>BaseServlet</code>中的异常往外抛给<code>Filter</code>过滤器</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">BaseServlet</span> <span class="keyword">extends</span> <span class="title">HttpServlet</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doGet</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">        doPost(req, resp);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doPost</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">        <span class="comment">// 解决post请求中文乱码问题</span></span><br><span class="line">        <span class="comment">// 一定要在获取请求参数之前调用才有效</span></span><br><span class="line">        req.setCharacterEncoding(<span class="string">&quot;UTF-8&quot;</span>);</span><br><span class="line"></span><br><span class="line">        String action = req.getParameter(<span class="string">&quot;action&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 获取action业务鉴别字符串，获得相应的业务 方法反射对象</span></span><br><span class="line">            Method method = <span class="keyword">this</span>.getClass().getDeclaredMethod(action, HttpServletRequest.class, HttpServletResponse.class);</span><br><span class="line">            <span class="comment">// 调用目标业务 方法</span></span><br><span class="line">            method.invoke(<span class="keyword">this</span>, req, resp);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e); <span class="comment">// 把异常抛给Filter过滤器</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="Tomcat管理异常"><a href="#Tomcat管理异常" class="headerlink" title="Tomcat管理异常"></a>Tomcat管理异常</h1><p>我们将所有异常都统一交给 <code>Tomcat</code>，让<code>Tomcat</code>展示友好的错误信息页面，这样用户就不用面对一大堆问题代码了。</p><ol><li>在<code>web.xml</code>中我们可以通过错误页面配置来进行管理</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--error-page 标签配置，服务器出错之后，自动跳转的页面--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">error-page</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--error-code 是错误类型--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">error-code</span>&gt;</span>500<span class="tag">&lt;/<span class="name">error-code</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--location 标签表示。要跳转去的页面路径--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">location</span>&gt;</span>/pages/error/error500.jsp<span class="tag">&lt;/<span class="name">location</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">error-page</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--error-page 标签配置，服务器出错之后，自动跳转的页面--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">error-page</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--error-code 是错误类型--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">error-code</span>&gt;</span>404<span class="tag">&lt;/<span class="name">error-code</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--location 标签表示。要跳转去的页面路径--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">location</span>&gt;</span>/pages/error/error404.jsp<span class="tag">&lt;/<span class="name">location</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">error-page</span>&gt;</span></span><br></pre></td></tr></table></figure><ol start="2"><li>编写错误页面，我们就简单做一下<br><code>error500.jsp</code><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;%@ page contentType=<span class="string">&quot;text/html;charset=UTF-8&quot;</span> language=<span class="string">&quot;java&quot;</span> %&gt;</span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>服务器出错啦<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span></span><br><span class="line"><span class="xml">    &lt;%-- 静态包含 base标签，css样式，jQuery文件 --%&gt;</span></span><br><span class="line"><span class="xml">   &lt;%@ include file=&quot;/pages/common/head.jsp&quot;%&gt;</span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span></span><br><span class="line"><span class="xml">服务器出错啦，程序员小哥正在加紧抢修。<span class="tag">&lt;<span class="name">br</span>/&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;index.jsp&quot;</span>&gt;</span>返回首页<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span></span><br></pre></td></tr></table></figure><code>error404.jsp</code></li></ol><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;%@ page contentType=<span class="string">&quot;text/html;charset=UTF-8&quot;</span> language=<span class="string">&quot;java&quot;</span> %&gt;</span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>访问资源不存在<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span></span><br><span class="line"><span class="xml">    &lt;%-- 静态包含 base标签，css样式，jQuery文件 --%&gt;</span></span><br><span class="line"><span class="xml">   &lt;%@ include file=&quot;/pages/common/head.jsp&quot;%&gt;</span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span></span><br><span class="line"><span class="xml">您访问的资源不存在，或已被删除<span class="tag">&lt;<span class="name">br</span>/&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;index.jsp&quot;</span>&gt;</span>返回首页<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span></span><br></pre></td></tr></table></figure><ol start="3"><li><code>TransactionFilter</code>要把异常抛给<code>Tomcat</code><br><img src="https://img-blog.csdnimg.cn/7d5438784aca4f97aa8056ea51d5dd2f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改TransactionFilter"></li></ol><hr><h1 id="使用AJAX验证用户名是否可用"><a href="#使用AJAX验证用户名是否可用" class="headerlink" title="使用AJAX验证用户名是否可用"></a>使用AJAX验证用户名是否可用</h1><ol><li>图解验证用户名是否可用流程<br><img src="https://img-blog.csdnimg.cn/79b8163ffc6b48dc9fe3da77b4c61c50.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="验证用户名是否可用流程"></li><li>导入相关<code>jar</code>包</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gson-<span class="number">2.2</span><span class="number">.4</span>.jar</span><br></pre></td></tr></table></figure><ol start="3"><li><code>UserServlet</code>程序添加<code>ajaxExistsUsername</code>方法</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * ajax请求判断用户名是否存在</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@param</span> req</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@param</span> resp</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@throws</span> ServletException</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">ajaxExistUsername</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">     <span class="comment">// 获取请求的参数username</span></span><br><span class="line">     String username = req.getParameter(<span class="string">&quot;username&quot;</span>);</span><br><span class="line">     <span class="comment">// 调用userService.existUsername()</span></span><br><span class="line">     <span class="keyword">boolean</span> existsUsername = userService.existsUsername(username);</span><br><span class="line">     <span class="comment">// 把返回的结果封装为map对象</span></span><br><span class="line">     Map&lt;String, Object&gt; resultMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">     resultMap.put(<span class="string">&quot;existsUsername&quot;</span>, existsUsername);</span><br><span class="line"></span><br><span class="line">     Gson gson= <span class="keyword">new</span> Gson();</span><br><span class="line">     String json = gson.toJson(resultMap);</span><br><span class="line"></span><br><span class="line">     resp.getWriter().write(json);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><ol start="4"><li>修改<code>regist.jsp</code>中的代码</li></ol><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 给用户名绑定失去焦点事件</span></span><br><span class="line">$(<span class="string">&quot;#username&quot;</span>).blur(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line"><span class="comment">// 1. 获取用户名</span></span><br><span class="line"><span class="keyword">var</span> username = <span class="built_in">this</span>.value;</span><br><span class="line"><span class="comment">//2 创建正则表达式对象</span></span><br><span class="line"><span class="keyword">var</span> usernamePatt = <span class="regexp">/^\w&#123;5,12&#125;$/</span>;</span><br><span class="line"><span class="comment">//3 使用test方法验证</span></span><br><span class="line"><span class="keyword">if</span>(!usernamePatt.test(username)) &#123; <span class="comment">// 用户名不合法</span></span><br><span class="line"><span class="comment">//4 提示用户结果</span></span><br><span class="line">$(<span class="string">&quot;span.errorMsg&quot;</span>).text(<span class="string">&quot;用户名不合法！&quot;</span>);</span><br><span class="line">&#125; <span class="keyword">else</span>&#123;</span><br><span class="line"><span class="comment">// 用户名合法判断用户名是否存在</span></span><br><span class="line"><span class="comment">// alert(&quot;用户名合法&quot;);</span></span><br><span class="line">$.getJSON(<span class="string">&quot;$&#123;pageScope.basePath&#125;userServlet&quot;</span>,<span class="string">&quot;action=ajaxExistsUsername&amp;username=&quot;</span> + username,</span><br><span class="line"><span class="function"><span class="keyword">function</span> (<span class="params">data</span>) </span>&#123;</span><br><span class="line"><span class="keyword">if</span>(data.existsUsername) &#123; <span class="comment">// 用户名存在</span></span><br><span class="line">$(<span class="string">&quot;span.errorMsg&quot;</span>).text(<span class="string">&quot;用户名已存在！&quot;</span>);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123; <span class="comment">// 用户名可用</span></span><br><span class="line">$(<span class="string">&quot;span.errorMsg&quot;</span>).text(<span class="string">&quot;用户名可用！&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><hr><h1 id="AJAX添加商品到购物车"><a href="#AJAX添加商品到购物车" class="headerlink" title="AJAX添加商品到购物车"></a>AJAX添加商品到购物车</h1><p> 我们之前把商品添加到购物车，是刷新了整个页面，这样用户体验不是很好，我们可用使用<code>Ajax</code>请求来完成局部的更新。</p><ol><li><p>图解商品加入购物车<br><img src="https://img-blog.csdnimg.cn/2ca1070e41724c2da0e535819b29308c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="加入购物车流程"></p></li><li><p><code>CartServlet</code>程序添加<code>ajaxAddItem</code>方法</p></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">ajaxAddItem</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 获取请求的参数 商品编号</span></span><br><span class="line">    <span class="keyword">int</span> id = WebUtils.parseInt(req.getParameter(<span class="string">&quot;id&quot;</span>), <span class="number">0</span>);</span><br><span class="line">    <span class="comment">// 调用 bookService.queryBookById(id):Book 得到图书的信息</span></span><br><span class="line">    Book book = bookService.queryBookById(id);</span><br><span class="line">    <span class="comment">// 把图书信息，转换为CartItem商品项</span></span><br><span class="line">    CartItem cartItem = <span class="keyword">new</span> CartItem(book.getId(), book.getName(), <span class="number">1</span>, book.getPrice(), book.getPrice());</span><br><span class="line">    <span class="comment">// 调用Cart.addItem(CartItem);添加商品项</span></span><br><span class="line">    Cart cart = (Cart) req.getSession().getAttribute(<span class="string">&quot;cart&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (cart == <span class="keyword">null</span>) &#123;</span><br><span class="line">        cart = <span class="keyword">new</span> Cart();</span><br><span class="line">        req.getSession().setAttribute(<span class="string">&quot;cart&quot;</span>, cart);</span><br><span class="line">    &#125;</span><br><span class="line">    cart.addItem(cartItem);</span><br><span class="line">    System.out.println(cart);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 最后一个添加的商品名称</span></span><br><span class="line">    req.getSession().setAttribute(<span class="string">&quot;lastName&quot;</span>, cartItem.getName());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 返回购物车总的商品数量和最后一个添加的商品名称</span></span><br><span class="line">    Map&lt;String, Object&gt; resultMap = <span class="keyword">new</span> HashMap&lt;String, Object&gt;();</span><br><span class="line"></span><br><span class="line">    resultMap.put(<span class="string">&quot;totalCount&quot;</span>, cart.getTotalCount());</span><br><span class="line">    resultMap.put(<span class="string">&quot;lastName&quot;</span>, cartItem.getName());</span><br><span class="line"></span><br><span class="line">    Gson gson = <span class="keyword">new</span> Gson();</span><br><span class="line">    String resultMapJsonString = gson.toJson(resultMap);</span><br><span class="line"></span><br><span class="line">    resp.getWriter().write(resultMapJsonString);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>修改<code>index.jsp</code>页面</li></ol><p> <img src="https://img-blog.csdnimg.cn/04287a55e2be458ea5f85b8de8c853e6.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="html代码"></p><p><img src="https://img-blog.csdnimg.cn/b70db4e82ba540879de2f18ba2a789e9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="js代码"></p><ol start="4"><li>修改<code>BaseServlet</code>程序解决中文乱码问题<br><img src="https://img-blog.csdnimg.cn/5678259a888345c6862f1cb0a43c7589.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="解决中文乱码问题"></li></ol>]]></content>
      
      
      <categories>
          
          <category> JavaWeb书城项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jsp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb书城项目(九)———订单模块</title>
      <link href="/2021/11/12/JavaWeb_BookProject_9/"/>
      <url>/2021/11/12/JavaWeb_BookProject_9/</url>
      
        <content type="html"><![CDATA[<blockquote><p>整个项目源代码可以到我的github上下载。上一部分我们已经完成了购物车模块，这一部分我们完成订单模块，主要包括生成订单，查询所有订单，发货，查看订单详情，查看我的订单，签收订单。</p></blockquote><h1 id="订单模块的分析"><a href="#订单模块的分析" class="headerlink" title="订单模块的分析"></a>订单模块的分析</h1><p><img src="https://img-blog.csdnimg.cn/bae0dcd98e014998b6ae9de125bc7910.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="订单模块的分析"></p><span id="more"></span><hr><h1 id="订单模块的实现"><a href="#订单模块的实现" class="headerlink" title="订单模块的实现"></a>订单模块的实现</h1><h2 id="创建订单模块的数据库表"><a href="#创建订单模块的数据库表" class="headerlink" title="创建订单模块的数据库表"></a>创建订单模块的数据库表</h2><p>为订单创建一个<code>t_order</code>表，为订单项创建一个<code>t_order_item</code>表。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">use book;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_order(</span><br><span class="line">`order_id` <span class="type">varchar</span>(<span class="number">50</span>) <span class="keyword">primary</span> key,</span><br><span class="line">`create_time` datetime,</span><br><span class="line">`price` <span class="type">decimal</span>(<span class="number">11</span>,<span class="number">2</span>),</span><br><span class="line">`status` <span class="type">int</span>,</span><br><span class="line">`user_id` <span class="type">int</span>,</span><br><span class="line"><span class="keyword">foreign</span> key(`user_id`) <span class="keyword">references</span> t_user(`id`)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_order_item(</span><br><span class="line">`id` <span class="type">int</span> <span class="keyword">primary</span> key auto_increment,</span><br><span class="line">`name` <span class="type">varchar</span>(<span class="number">100</span>),</span><br><span class="line">`count` <span class="type">int</span>,</span><br><span class="line">`price` <span class="type">decimal</span>(<span class="number">11</span>,<span class="number">2</span>),</span><br><span class="line">`total_price` <span class="type">decimal</span>(<span class="number">11</span>,<span class="number">2</span>),</span><br><span class="line">`order_id` <span class="type">varchar</span>(<span class="number">50</span>),</span><br><span class="line"><span class="keyword">foreign</span> key(`order_id`) <span class="keyword">references</span> t_order(`order_id`)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h2 id="创建订单模块的数据模型"><a href="#创建订单模块的数据模型" class="headerlink" title="创建订单模块的数据模型"></a>创建订单模块的数据模型</h2><p>创建一个<code>Order</code>类和一个<code>OrderItem</code>类，<code>Order</code>类属性如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> String orderId;</span><br><span class="line"><span class="keyword">private</span> Date createTime;</span><br><span class="line"><span class="keyword">private</span> BigDecimal price;</span><br><span class="line"><span class="comment">// 0未发货，1已发货，2已签收</span></span><br><span class="line"><span class="keyword">private</span> Integer status = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">private</span> Integer userId;</span><br></pre></td></tr></table></figure><p><code>OrderItem</code>类属性如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Integer id;</span><br><span class="line"><span class="keyword">private</span> String name;</span><br><span class="line"><span class="keyword">private</span> Integer count;</span><br><span class="line"><span class="keyword">private</span> BigDecimal price;</span><br><span class="line"><span class="keyword">private</span> BigDecimal totalPrice;</span><br><span class="line"><span class="keyword">private</span> String orderId;</span><br></pre></td></tr></table></figure><p>并为其生成构造方法，<code>Get</code>方法，<code>Set</code>方法，以及<code>toString</code>方法。</p><h2 id="编写订单模块的Dao程序和测试"><a href="#编写订单模块的Dao程序和测试" class="headerlink" title="编写订单模块的Dao程序和测试"></a>编写订单模块的Dao程序和测试</h2><p><code>OrderDao</code>接口</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">OrderDao</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">saveOrder</span><span class="params">(Order order)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Order&gt; <span class="title">queryOrders</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Order&gt; <span class="title">queryOrdersByUserId</span><span class="params">(Integer id)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">updateOrder</span><span class="params">(Order order)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>OrderDaoImpl</code>实现类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderDaoImpl</span> <span class="keyword">extends</span> <span class="title">BaseDao</span> <span class="keyword">implements</span> <span class="title">OrderDao</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 保存订单</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> order</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">saveOrder</span><span class="params">(Order order)</span> </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;insert into t_order(`order_id`,`create_time`,`price`,`status`,`user_id`) values(?,?,?,?,?)&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> update(sql, order.getOrderId(), order.getCreateTime(), order.getPrice(), order.getStatus(), order.getUserId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询全部订单</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Order&gt; <span class="title">queryOrders</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;select `order_id` orderId,`create_time` createTime,`price`,`status`,`user_id` userId from t_order&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> queryForList(Order.class, sql);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 根据UserId查询订单</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Order&gt; <span class="title">queryOrdersByUserId</span><span class="params">(Integer id)</span> </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;select `order_id` orderId,`create_time` createTime,`price`,`status`,`user_id` userId from t_order where user_id=?&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> queryForList(Order.class, sql, id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 修改订单</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> order</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">updateOrder</span><span class="params">(Order order)</span> </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;update t_order set `create_time`=?,`price`=?,`status`=? where order_id=?&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> update(sql, order.getCreateTime(), order.getPrice(), order.getStatus(), order.getOrderId());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderDaoTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    OrderDao orderDao = <span class="keyword">new</span> OrderDaoImpl();</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">saveOrder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        orderDao.saveOrder(<span class="keyword">new</span> Order(<span class="string">&quot;12345678&quot;</span>,<span class="keyword">new</span> Date(),<span class="keyword">new</span> BigDecimal(<span class="number">100</span>),<span class="number">0</span>,<span class="number">2</span>));</span><br><span class="line">        orderDao.saveOrder(<span class="keyword">new</span> Order(<span class="string">&quot;123&quot;</span>, <span class="keyword">new</span> Date(), <span class="keyword">new</span> BigDecimal(<span class="number">1005</span>), <span class="number">0</span>, <span class="number">5</span>));</span><br><span class="line">        orderDao.saveOrder(<span class="keyword">new</span> Order(<span class="string">&quot;456&quot;</span>, <span class="keyword">new</span> Date(), <span class="keyword">new</span> BigDecimal(<span class="number">505</span>), <span class="number">1</span>, <span class="number">6</span>));</span><br><span class="line">        orderDao.saveOrder(<span class="keyword">new</span> Order(<span class="string">&quot;789&quot;</span>, <span class="keyword">new</span> Date(), <span class="keyword">new</span> BigDecimal(<span class="number">605</span>), <span class="number">2</span>, <span class="number">6</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">queryOrders</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(orderDao.queryOrders());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">queryOrdersByUserId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(orderDao.queryOrdersByUserId(<span class="number">6</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateOrder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        orderDao.updateOrder(<span class="keyword">new</span> Order(<span class="string">&quot;456&quot;</span>, <span class="keyword">new</span> Date(), <span class="keyword">new</span> BigDecimal(<span class="number">611</span>), <span class="number">2</span>, <span class="number">6</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>OrderDaoItem</code>接口</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">OrderItemDao</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">saveOrderItem</span><span class="params">(OrderItem orderItem)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;OrderItem&gt; <span class="title">queryOrderItemsById</span><span class="params">(String id)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>OrderDaoItemImpl</code>实现类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderItemDaoImpl</span> <span class="keyword">extends</span> <span class="title">BaseDao</span> <span class="keyword">implements</span> <span class="title">OrderItemDao</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 保存订单项</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> orderItem</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">saveOrderItem</span><span class="params">(OrderItem orderItem)</span> </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;insert into t_order_item(`name`,`count`,`price`,`total_price`,`order_id`) values(?,?,?,?,?)&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> update(sql, orderItem.getName(), orderItem.getCount(), orderItem.getPrice(), orderItem.getTotalPrice(), orderItem.getOrderId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 根据order_id查询订单项</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;OrderItem&gt; <span class="title">queryOrderItemsById</span><span class="params">(String id)</span> </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;select `id`,`name`,`count`,`price`,`total_price` totalPrice,`order_id` orderId from t_order_item where order_id=?&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> queryForList(OrderItem.class, sql, id);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderItemDaoTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    OrderItemDao orderItemDao = <span class="keyword">new</span> OrderItemDaoImpl();</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">saveOrderItem</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        orderItemDao.saveOrderItem(<span class="keyword">new</span> OrderItem(<span class="keyword">null</span>,<span class="string">&quot;java 从入门到精通&quot;</span>, <span class="number">1</span>,<span class="keyword">new</span> BigDecimal(<span class="number">100</span>),<span class="keyword">new</span></span><br><span class="line">                BigDecimal(<span class="number">100</span>),<span class="string">&quot;456&quot;</span>));</span><br><span class="line">        orderItemDao.saveOrderItem(<span class="keyword">new</span> OrderItem(<span class="keyword">null</span>,<span class="string">&quot;javaScript 从入门到精通&quot;</span>, <span class="number">2</span>,<span class="keyword">new</span></span><br><span class="line">                BigDecimal(<span class="number">100</span>),<span class="keyword">new</span> BigDecimal(<span class="number">200</span>),<span class="string">&quot;12345678&quot;</span>));</span><br><span class="line">        orderItemDao.saveOrderItem(<span class="keyword">new</span> OrderItem(<span class="keyword">null</span>,<span class="string">&quot;Netty 入门&quot;</span>, <span class="number">1</span>,<span class="keyword">new</span> BigDecimal(<span class="number">100</span>),<span class="keyword">new</span></span><br><span class="line">                BigDecimal(<span class="number">100</span>),<span class="string">&quot;456&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">queryOrderItemsById</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(orderItemDao.queryOrderItemsById(<span class="string">&quot;12345678&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="编写订单模块的Service和测试"><a href="#编写订单模块的Service和测试" class="headerlink" title="编写订单模块的Service和测试"></a>编写订单模块的Service和测试</h2><p><code>OrderService</code>接口</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">OrderService</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建订单</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> cart</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> userId</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">createOrder</span><span class="params">(Cart cart, Integer userId)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 展示所有订单</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Order&gt; <span class="title">showAllOrders</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 发货</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> order</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendOrder</span><span class="params">(Order order)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询订单详情</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;OrderItem&gt; <span class="title">showOrderDetail</span><span class="params">(String id)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 展示我的订单</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Order&gt; <span class="title">showMyOrders</span><span class="params">(Integer id)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 签收</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> order</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">receiverOrder</span><span class="params">(Order order)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>OrderServiceImpl</code>实现类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderServiceImpl</span> <span class="keyword">implements</span> <span class="title">OrderService</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> OrderDao orderDao = <span class="keyword">new</span> OrderDaoImpl();</span><br><span class="line">    <span class="keyword">private</span> OrderItemDao orderItemDao = <span class="keyword">new</span> OrderItemDaoImpl();</span><br><span class="line"><span class="keyword">private</span> BookDao bookDao = <span class="keyword">new</span> BookDaoImpl();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">createOrder</span><span class="params">(Cart cart, Integer userId)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 订单号==唯一性</span></span><br><span class="line">        String orderId = System.currentTimeMillis()+<span class="string">&quot;&quot;</span>+userId;</span><br><span class="line">        <span class="comment">// 创建一个订单对象</span></span><br><span class="line">        Order order = <span class="keyword">new</span> Order(orderId, <span class="keyword">new</span> Date(), cart.getTotalPrice(), <span class="number">0</span>, userId);</span><br><span class="line">        <span class="comment">// 保存订单</span></span><br><span class="line">        orderDao.saveOrder(order);</span><br><span class="line">        <span class="comment">// 遍历购物车中每一个商品项转换成为订单项保存到数据库</span></span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;Integer, CartItem&gt;entry : cart.getItems().entrySet())&#123;</span><br><span class="line">            <span class="comment">// 获取每一个购物车中的商品项</span></span><br><span class="line">            CartItem cartItem = entry.getValue();</span><br><span class="line">            <span class="comment">// 转换为每一个订单项</span></span><br><span class="line">            OrderItem orderItem = <span class="keyword">new</span> OrderItem(<span class="keyword">null</span>, cartItem.getName(), cartItem.getCount(), cartItem.getPrice(), cartItem.getTotalprice(), orderId);</span><br><span class="line">            <span class="comment">// 保存订单项到数据库</span></span><br><span class="line">            orderItemDao.saveOrderItem(orderItem);</span><br><span class="line">            <span class="comment">// 更新库存和销量</span></span><br><span class="line">            Book book = bookDao.queryBookById(cartItem.getId());</span><br><span class="line">            book.setSales( book.getSales() + cartItem.getCount() );</span><br><span class="line">            book.setStock( book.getStock() - cartItem.getCount() );</span><br><span class="line">            bookDao.updateBook(book);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 清空购物车</span></span><br><span class="line">        cart.clear();</span><br><span class="line">        <span class="keyword">return</span> orderId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Order&gt; <span class="title">showAllOrders</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> orderDao.queryOrders();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendOrder</span><span class="params">( Order order )</span> </span>&#123;</span><br><span class="line">        order.setStatus(<span class="number">1</span>);</span><br><span class="line">        orderDao.updateOrder(order);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;OrderItem&gt; <span class="title">showOrderDetail</span><span class="params">(String id)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> orderItemDao.queryOrderItemsById(id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Order&gt; <span class="title">showMyOrders</span><span class="params">(Integer id)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> orderDao.queryOrdersByUserId(id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">receiverOrder</span><span class="params">(Order order)</span> </span>&#123;</span><br><span class="line">        order.setStatus(<span class="number">2</span>);</span><br><span class="line">        orderDao.updateOrder(order);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderServiceImplTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> OrderService orderService = <span class="keyword">new</span> OrderServiceImpl();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createOrder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Cart cart = <span class="keyword">new</span> Cart();</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">1</span>, <span class="string">&quot;java从入门到精通&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">1000</span>),<span class="keyword">new</span> BigDecimal(<span class="number">1000</span>)));</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">1</span>, <span class="string">&quot;java从入门到精通&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">1000</span>),<span class="keyword">new</span> BigDecimal(<span class="number">1000</span>)));</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">2</span>, <span class="string">&quot;数据结构与算法&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">100</span>),<span class="keyword">new</span> BigDecimal(<span class="number">100</span>)));</span><br><span class="line">        System.out.println(<span class="string">&quot;订单号是：&quot;</span> + orderService.createOrder(cart, <span class="number">2</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">showAllOrders</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(orderService.showAllOrders());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendOrder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        orderService.sendOrder(<span class="keyword">new</span> Order(<span class="string">&quot;16366346078552&quot;</span>,<span class="keyword">new</span> Date(), <span class="keyword">new</span> BigDecimal(<span class="number">2100</span>),<span class="number">0</span>,<span class="number">2</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">showOrderDetail</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(orderService.showOrderDetail(<span class="string">&quot;16366346078552&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">showMyOrders</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(orderService.showMyOrders(<span class="number">2</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">receiverOrder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        orderService.receiverOrder(<span class="keyword">new</span> Order(<span class="string">&quot;16366346078552&quot;</span>,<span class="keyword">new</span> Date(), <span class="keyword">new</span> BigDecimal(<span class="number">2100</span>),<span class="number">1</span>,<span class="number">2</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="编写订单模块的Web层和页面联调"><a href="#编写订单模块的Web层和页面联调" class="headerlink" title="编写订单模块的Web层和页面联调"></a>编写订单模块的Web层和页面联调</h2><h3 id="生成订单"><a href="#生成订单" class="headerlink" title="生成订单"></a>生成订单</h3><ol><li><code>OrderServlet</code>添加<code>createOrder</code>方法</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 生成订单</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> req</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> resp</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> ServletException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">createOrder</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 先获取购物车对象</span></span><br><span class="line">    Cart cart = (Cart) req.getSession().getAttribute(<span class="string">&quot;cart&quot;</span>);</span><br><span class="line">    <span class="comment">// 获取Userid</span></span><br><span class="line">    User loginUser = (User) req.getSession().getAttribute(<span class="string">&quot;user&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (loginUser == <span class="keyword">null</span>) &#123;</span><br><span class="line">        req.getRequestDispatcher(<span class="string">&quot;/pages/user/login.jsp&quot;</span>).forward(req, resp);</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Integer userId = loginUser.getId();</span><br><span class="line">    String orderId = orderService.createOrder(cart, userId);</span><br><span class="line"></span><br><span class="line">    req.getSession().setAttribute(<span class="string">&quot;orderId&quot;</span>,orderId);</span><br><span class="line"></span><br><span class="line">    resp.sendRedirect(req.getContextPath()+<span class="string">&quot;/pages/cart/checkout.jsp&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li><p>修改<code>cart.jsp</code>页面，结账的请求地址<br><img src="https://img-blog.csdnimg.cn/fd35d60652764f5587594b4e6088cec0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改cart.jsp"></p></li><li><p>修改<code>checkout.jsp</code>页面<br><img src="https://img-blog.csdnimg.cn/20f5b2796ab0468297e706a0d5b34762.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改checkout.jsp"></p><h3 id="展示全部订单"><a href="#展示全部订单" class="headerlink" title="展示全部订单"></a>展示全部订单</h3></li><li><p><code>OrderServlet</code>添加<code>showAllOrders</code>方法</p></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 展示全部订单</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> req</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> resp</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> ServletException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">showAllOrders</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 1.通过orderService查询所有订单</span></span><br><span class="line">    List&lt;Order&gt; orders = orderService.showAllOrders();</span><br><span class="line">    <span class="comment">// 2.把全部订单保存到Request域</span></span><br><span class="line">    req.setAttribute(<span class="string">&quot;orders&quot;</span>, orders);</span><br><span class="line">    <span class="comment">// 3.请求转发到 /pages/manager/order_manager.jsp</span></span><br><span class="line">    req.getRequestDispatcher(<span class="string">&quot;/pages/manager/order_manager.jsp&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li><p>修改<code>manager_menu.jsp</code>页面，订单管理请求地址<br><img src="https://img-blog.csdnimg.cn/443db4558d6b46ceb30909a3c38da181.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改manager_menu.jsp"></p></li><li><p>修改<code>order_manager.jsp</code>页面<br><img src="https://img-blog.csdnimg.cn/b36930d53a4648dea6b0e1f9ddc5507b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改order_manager.jsp"></p><h3 id="展示我的订单"><a href="#展示我的订单" class="headerlink" title="展示我的订单"></a>展示我的订单</h3></li><li><p><code>OrderServlet</code>添加<code>showMyOrders</code>方法</p></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 展示我的订单</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> req</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> resp</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> ServletException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">showMyOrders</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 获取Userid</span></span><br><span class="line">    User loginUser = (User) req.getSession().getAttribute(<span class="string">&quot;user&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (loginUser == <span class="keyword">null</span>) &#123;</span><br><span class="line">        req.getRequestDispatcher(<span class="string">&quot;/pages/user/login.jsp&quot;</span>).forward(req, resp);</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Integer userId = loginUser.getId();</span><br><span class="line">    List&lt;Order&gt; myOrders = orderService.showMyOrders(userId);</span><br><span class="line"></span><br><span class="line">    req.getSession().setAttribute(<span class="string">&quot;myOrders&quot;</span>, myOrders);</span><br><span class="line"></span><br><span class="line">    resp.sendRedirect(req.getContextPath()+<span class="string">&quot;/pages/order/order.jsp&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li><p>修改<code>login_success_menu.jsp</code>页面，我的订单请求地址<br><img src="https://img-blog.csdnimg.cn/abf61576f6d041638efac41ab0081eb9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改login_menu.jsp"></p></li><li><p>修改<code>order.jsp</code>页面<br><img src="https://img-blog.csdnimg.cn/53eef871befe49e592bf590f016aebed.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改order.jsp"></p></li></ol><h3 id="显示订单详情"><a href="#显示订单详情" class="headerlink" title="显示订单详情"></a>显示订单详情</h3><ol><li><code>OrderServlet</code>增加<code>showOrderDetail</code>方法</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 显示订单详情</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> req</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> resp</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> ServletException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">showOrderDetail</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 1. 获取Orderid</span></span><br><span class="line">    String orderId = req.getParameter(<span class="string">&quot;orderId&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (orderId != <span class="keyword">null</span> &amp;&amp; orderId != <span class="string">&quot;&quot;</span>) &#123;</span><br><span class="line">        <span class="comment">// 2. 查询订单项</span></span><br><span class="line">        List&lt;OrderItem&gt; orderItems = orderService.showOrderDetail(orderId);</span><br><span class="line">        <span class="comment">// 3. 把订单项保存到Request域</span></span><br><span class="line">        req.setAttribute(<span class="string">&quot;orderItems&quot;</span>, orderItems);</span><br><span class="line">        <span class="comment">// 4. 请求转发到 /pages/order/order_detail.jsp</span></span><br><span class="line">        req.getRequestDispatcher(<span class="string">&quot;/pages/order/order_detail.jsp&quot;</span>).forward(req, resp);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li>在<code>order</code>目录下新建<code>order_detail.jsp</code>页面</li></ol><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">&lt;%@ taglib prefix=<span class="string">&quot;c&quot;</span> uri=<span class="string">&quot;http://java.sun.com/jsp/jstl/core&quot;</span> %&gt;</span><br><span class="line">&lt;%@ page contentType=<span class="string">&quot;text/html;charset=UTF-8&quot;</span> language=<span class="string">&quot;java&quot;</span> %&gt;</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset=&quot;UTF-8&quot;&gt;</span><br><span class="line">    &lt;title&gt;我的订单&lt;/title&gt;</span><br><span class="line"></span><br><span class="line">    &lt;%-- 静态包含 base标签，css样式，jQuery文件 --%&gt;</span><br><span class="line">    &lt;%@ include file=&quot;/pages/common/head.jsp&quot;%&gt;</span><br><span class="line"></span><br><span class="line">    &lt;style type=&quot;text/css&quot;&gt;</span><br><span class="line">        h1 &#123;</span><br><span class="line">            text-align: center;</span><br><span class="line">            margin-top: 200px;</span><br><span class="line">        &#125;</span><br><span class="line">    &lt;/style&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line"></span><br><span class="line">&lt;div id=&quot;header&quot;&gt;</span><br><span class="line">    &lt;img class=&quot;logo_img&quot; alt=&quot;&quot; src=&quot;static/img/logo.gif&quot; &gt;</span><br><span class="line">    &lt;span class=&quot;wel_word&quot;&gt;我的订单&lt;/span&gt;</span><br><span class="line"></span><br><span class="line">    &lt;%-- 静态包含登录成功之后的菜单 --%&gt;</span><br><span class="line">    &lt;%@ include file=&quot;/pages/common/login_success_menu.jsp&quot;%&gt;</span><br><span class="line">&lt;/div&gt;</span><br><span class="line"></span><br><span class="line">&lt;div id=&quot;main&quot;&gt;</span><br><span class="line"></span><br><span class="line">    &lt;table&gt;</span><br><span class="line">        &lt;tr&gt;</span><br><span class="line">            &lt;td&gt;商品名称&lt;/td&gt;</span><br><span class="line">            &lt;td&gt;数量&lt;/td&gt;</span><br><span class="line">            &lt;td&gt;单价&lt;/td&gt;</span><br><span class="line">            &lt;td&gt;金额&lt;/td&gt;</span><br><span class="line">        &lt;/tr&gt;</span><br><span class="line">        &lt;c:forEach items=&quot;$&#123;requestScope.orderItems&#125;&quot; var=&quot;orderItem&quot;&gt;</span><br><span class="line">            &lt;tr&gt;</span><br><span class="line">                &lt;td&gt;$&#123;orderItem.name&#125;&lt;/td&gt;</span><br><span class="line">                &lt;td&gt;$&#123;orderItem.count&#125;&lt;/td&gt;</span><br><span class="line">                &lt;td&gt;$&#123;orderItem.price&#125;&lt;/td&gt;</span><br><span class="line">                &lt;td&gt;$&#123;orderItem.totalPrice&#125;&lt;/td&gt;</span><br><span class="line">            &lt;/tr&gt;</span><br><span class="line">        &lt;/c:forEach&gt;</span><br><span class="line">    &lt;/table&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;/div&gt;</span><br><span class="line"></span><br><span class="line">&lt;%-- include包含脚部信息 --%&gt;</span><br><span class="line">&lt;%@ include file=&quot;/pages/common/footer.jsp&quot;%&gt;</span><br><span class="line"></span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure><ol start="3"><li><p>修改<code>order.jsp</code>页面，查看详情请求地址<br><img src="https://img-blog.csdnimg.cn/580f8f71199743a98191b0439ebe88a4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改order.jsp"></p></li><li><p>修改<code>order_manager.jsp</code>页面，查看详情请求地址<br><img src="https://img-blog.csdnimg.cn/d309dfe3ce234fcb98a57085b5edaaff.png" alt="修改order_manager.jsp"></p><h3 id="发货"><a href="#发货" class="headerlink" title="发货"></a>发货</h3></li><li><p> <code>OrderServlet</code>增加<code>sendOrder</code>方法</p></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 发货</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> req</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> resp</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> ServletException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">sendOrder</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 1. 获取Order</span></span><br><span class="line">    Order order = WebUtils.copyParamToBean(req.getParameterMap(), <span class="keyword">new</span> Order());</span><br><span class="line">    <span class="comment">// 2. 调用orderService的sendOrder方法发货</span></span><br><span class="line">    orderService.sendOrder(order);</span><br><span class="line">    <span class="comment">// 3. 重定向回 /pages/manager/order_manager.jsp</span></span><br><span class="line">    resp.sendRedirect(req.getContextPath() + <span class="string">&quot;/pages/manager/order_manager.jsp&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li>修改<code>WebUtils</code>的<code>copyParamToBean</code>方法，因为<code>BeanUtils</code>无法直接将<code>String</code>转为<code>Date</code>，所以要先注册<br><img src="https://img-blog.csdnimg.cn/2f14a1ca89a74fe7ab0c1ba1809d0dff.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改WebUtils"></li><li>修改<code>order_manager.jsp</code>页面，    点击发货请求地址<br><img src="https://img-blog.csdnimg.cn/11bac86444ab4bce897facbd52e596c2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改order_manager.jsp"><h3 id="签收"><a href="#签收" class="headerlink" title="签收"></a>签收</h3></li><li><code>OrderServlet</code>增加<code>receiverOrder</code>方法</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 签收</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> req</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> resp</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> ServletException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">receiverOrder</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 1. 获取Order</span></span><br><span class="line">    Order order = WebUtils.copyParamToBean(req.getParameterMap(), <span class="keyword">new</span> Order());</span><br><span class="line">    <span class="comment">// 2. 调用orderService的receiverOrder方法签收</span></span><br><span class="line">    orderService.receiverOrder(order);</span><br><span class="line">    <span class="comment">// 3. 重定向回 /orderServlet?action=showMyOrders</span></span><br><span class="line">    resp.sendRedirect(req.getContextPath() + <span class="string">&quot;/orderServlet?action=showMyOrders&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li>修改<code>order.jsp</code>页面，点击签收请求地址<br><img src="https://img-blog.csdnimg.cn/5b12e4e0261744f88707abea88404550.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改order.jsp"></li></ol>]]></content>
      
      
      <categories>
          
          <category> JavaWeb书城项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jsp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb书城项目(八)———购物车模块</title>
      <link href="/2021/11/10/JavaWeb_BookProject_8/"/>
      <url>/2021/11/10/JavaWeb_BookProject_8/</url>
      
        <content type="html"><![CDATA[<blockquote><p>整个项目源代码可以到我的github上下载。上一部分，我们对用户功能进行了完善，这一部分我们完成购物车模块，主要包括添加商品到购物车，删除商品，清空购物车。</p></blockquote><h1 id="购物车模块分析"><a href="#购物车模块分析" class="headerlink" title="购物车模块分析"></a>购物车模块分析</h1><span id="more"></span><p><img src="https://img-blog.csdnimg.cn/fe45f138207e448a9c4af7d2a124a9c7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="购物车模块分析"><br>我们使用<code>Session</code>版本实现购物车，这样就不需要 <code>Dao</code> 层和 <code>Service</code> 层了。</p><hr><h1 id="购物车模型编写"><a href="#购物车模型编写" class="headerlink" title="购物车模型编写"></a>购物车模型编写</h1><ol><li>创建<code>CartItem</code>类定义购物车中的商品项，其有以下属性</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Integer id; <span class="comment">//编号</span></span><br><span class="line"><span class="keyword">private</span> String name; <span class="comment">//名称</span></span><br><span class="line"><span class="keyword">private</span> Integer count; <span class="comment">//数量</span></span><br><span class="line"><span class="keyword">private</span> BigDecimal price; <span class="comment">//单价</span></span><br><span class="line"><span class="keyword">private</span> BigDecimal totalprice; <span class="comment">//总价</span></span><br></pre></td></tr></table></figure><ol start="2"><li>创建<code>Cart</code>类定义购物车</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.pojo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.math.BigDecimal;</span><br><span class="line"><span class="keyword">import</span> java.util.LinkedHashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 购物车对象</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Cart</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * key 是商品编号</span></span><br><span class="line"><span class="comment">     * value 是商品信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Map&lt;Integer, CartItem&gt; items = <span class="keyword">new</span> LinkedHashMap&lt;Integer, CartItem&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addItem</span><span class="params">(CartItem cartItem)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 先查看购物车中是否已经添加过此商品，如果已添加，则数量累加，总金额更新，如果没有添加过，直接放到集合中即可</span></span><br><span class="line">        CartItem item = items.get(cartItem.getId());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>( item == <span class="keyword">null</span> )</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// 之前没添加过此商品</span></span><br><span class="line">            items.put(cartItem.getId(), cartItem);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 已经添加过的情况</span></span><br><span class="line">            item.setCount( item.getCount() + <span class="number">1</span> ); <span class="comment">//数量增加</span></span><br><span class="line">            item.setTotalprice( item.getPrice().multiply(<span class="keyword">new</span> BigDecimal( item.getCount() ))); <span class="comment">// 更新总金额</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 删除商品项</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">deleteItem</span><span class="params">(Integer id)</span> </span>&#123;</span><br><span class="line">        items.remove(id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 清空购物车</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        items.clear();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 修改商品数量</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> count</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateCount</span><span class="params">(Integer id, Integer count)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 先查看购物车是否有此商品。如果有，修改商品数量，更新总金额</span></span><br><span class="line">        CartItem cartItem = items.get(id);</span><br><span class="line">        <span class="keyword">if</span> (cartItem != <span class="keyword">null</span>) &#123;</span><br><span class="line">            cartItem.setCount(count); <span class="comment">// 修改商品数量</span></span><br><span class="line">            cartItem.setTotalprice( cartItem.getPrice().multiply(<span class="keyword">new</span> BigDecimal( cartItem.getCount() )));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获得总数量</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Integer <span class="title">getTotalCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Integer totalCount = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;Integer,CartItem&gt;entry : items.entrySet()) &#123;</span><br><span class="line">            totalCount += entry.getValue().getCount();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> totalCount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> BigDecimal <span class="title">getTotalPrice</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        BigDecimal totalPrice = <span class="keyword">new</span> BigDecimal(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;Integer,CartItem&gt;entry : items.entrySet()) &#123;</span><br><span class="line">            totalPrice = totalPrice.add(entry.getValue().getTotalprice());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span>  totalPrice;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;Integer, CartItem&gt; <span class="title">getItems</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> items;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setItems</span><span class="params">(Map&lt;Integer, CartItem&gt; items)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.items = items;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Cart&#123;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;totalCount=&quot;</span> + getTotalCount() +</span><br><span class="line">                <span class="string">&quot;, totalPrice=&quot;</span> + getTotalPrice() +</span><br><span class="line">                <span class="string">&quot;, items=&quot;</span> + items +</span><br><span class="line">                <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="3"><li>购物车的测试，创建测试类<code>CartTest</code></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.Cart;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.CartItem;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.math.BigDecimal;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.junit.Assert.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CartTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addItem</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Cart cart = <span class="keyword">new</span> Cart();</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">1</span>, <span class="string">&quot;java从入门到精通&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">1000</span>),<span class="keyword">new</span> BigDecimal(<span class="number">1000</span>)));</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">1</span>, <span class="string">&quot;java从入门到精通&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">1000</span>),<span class="keyword">new</span> BigDecimal(<span class="number">1000</span>)));</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">2</span>, <span class="string">&quot;数据结构与算法&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">100</span>),<span class="keyword">new</span> BigDecimal(<span class="number">100</span>)));</span><br><span class="line">        System.out.println(cart);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">deleteItem</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Cart cart = <span class="keyword">new</span> Cart();</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">1</span>, <span class="string">&quot;java从入门到精通&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">1000</span>),<span class="keyword">new</span> BigDecimal(<span class="number">1000</span>)));</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">1</span>, <span class="string">&quot;java从入门到精通&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">1000</span>),<span class="keyword">new</span> BigDecimal(<span class="number">1000</span>)));</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">2</span>, <span class="string">&quot;数据结构与算法&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">100</span>),<span class="keyword">new</span> BigDecimal(<span class="number">100</span>)));</span><br><span class="line">        cart.deleteItem(<span class="number">1</span>);</span><br><span class="line">        System.out.println(cart);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Cart cart = <span class="keyword">new</span> Cart();</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">1</span>, <span class="string">&quot;java从入门到精通&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">1000</span>),<span class="keyword">new</span> BigDecimal(<span class="number">1000</span>)));</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">1</span>, <span class="string">&quot;java从入门到精通&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">1000</span>),<span class="keyword">new</span> BigDecimal(<span class="number">1000</span>)));</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">2</span>, <span class="string">&quot;数据结构与算法&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">100</span>),<span class="keyword">new</span> BigDecimal(<span class="number">100</span>)));</span><br><span class="line">        cart.deleteItem(<span class="number">1</span>);</span><br><span class="line">        cart.clear();</span><br><span class="line">        System.out.println(cart);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Cart cart = <span class="keyword">new</span> Cart();</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">1</span>, <span class="string">&quot;java从入门到精通&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">1000</span>),<span class="keyword">new</span> BigDecimal(<span class="number">1000</span>)));</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">1</span>, <span class="string">&quot;java从入门到精通&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">1000</span>),<span class="keyword">new</span> BigDecimal(<span class="number">1000</span>)));</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">2</span>, <span class="string">&quot;数据结构与算法&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">100</span>),<span class="keyword">new</span> BigDecimal(<span class="number">100</span>)));</span><br><span class="line">        cart.deleteItem(<span class="number">1</span>);</span><br><span class="line">        cart.clear();</span><br><span class="line">        cart.addItem(<span class="keyword">new</span> CartItem(<span class="number">1</span>, <span class="string">&quot;java从入门到精通&quot;</span>, <span class="number">1</span>, <span class="keyword">new</span> BigDecimal(<span class="number">1000</span>),<span class="keyword">new</span> BigDecimal(<span class="number">1000</span>)));</span><br><span class="line">        cart.updateCount(<span class="number">1</span>, <span class="number">10</span>);</span><br><span class="line">        System.out.println(cart);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="加入购物车功能的实现"><a href="#加入购物车功能的实现" class="headerlink" title="加入购物车功能的实现"></a>加入购物车功能的实现</h1><ol><li><code>CartServlet</code>程序中的代码</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">addItem</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 获取请求的参数 商品编号</span></span><br><span class="line">    <span class="keyword">int</span> id = WebUtils.parseInt(req.getParameter(<span class="string">&quot;id&quot;</span>), <span class="number">0</span>);</span><br><span class="line">    <span class="comment">// 调用 bookService.queryBookById(id):Book 得到图书的信息</span></span><br><span class="line">    Book book = bookService.queryBookById(id);</span><br><span class="line">    <span class="comment">// 把图书信息，转换为CartItem商品项</span></span><br><span class="line">    CartItem cartItem = <span class="keyword">new</span> CartItem(book.getId(), book.getName(), <span class="number">1</span>, book.getPrice(), book.getPrice());</span><br><span class="line">    <span class="comment">// 调用Cart.addItem(CartItem);添加商品项</span></span><br><span class="line">    Cart cart = (Cart) req.getSession().getAttribute(<span class="string">&quot;cart&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (cart == <span class="keyword">null</span>) &#123;</span><br><span class="line">        cart = <span class="keyword">new</span> Cart();</span><br><span class="line">        req.getSession().setAttribute(<span class="string">&quot;cart&quot;</span>, cart);</span><br><span class="line">    &#125;</span><br><span class="line">    cart.addItem(cartItem);</span><br><span class="line"></span><br><span class="line">    System.out.println(cart);</span><br><span class="line">    System.out.println(<span class="string">&quot;请求头Referer的值：&quot;</span> + req.getHeader(<span class="string">&quot;Referer&quot;</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 重定向回原来商品所在的地址页面</span></span><br><span class="line">    resp.sendRedirect(req.getHeader(<span class="string">&quot;Referer&quot;</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li><code>index.jsp</code>页面<code>js</code>的代码<br><img src="https://img-blog.csdnimg.cn/967ff7dd6fb14b9bba656bd59316e665.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改index.jsp"></li></ol><ol start="3"><li>图解说明，如何跳回添加商品的页面<br><img src="https://img-blog.csdnimg.cn/c8a6d5a175b04d4190d17057b5b9ea22.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="跳回添加商品的页面"></li></ol><hr><h1 id="购物车的展示"><a href="#购物车的展示" class="headerlink" title="购物车的展示"></a>购物车的展示</h1><p>修改 <code>cart.jsp</code><br><img src="https://img-blog.csdnimg.cn/b79928ef14a14ae29140a0999566097f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改cart,jsp(一)"><br><img src="https://img-blog.csdnimg.cn/47f2edc36f914f26a2ba5d1903e1da50.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改cart.jsp(二)"></p><hr><h1 id="删除购物车商品项"><a href="#删除购物车商品项" class="headerlink" title="删除购物车商品项"></a>删除购物车商品项</h1><ol><li><code>CartServlet</code>增加<code>deleteItem</code>方法</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">deleteItem</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 获取商品编号</span></span><br><span class="line">    <span class="keyword">int</span> id = WebUtils.parseInt(req.getParameter(<span class="string">&quot;id&quot;</span>), <span class="number">0</span>);</span><br><span class="line">    <span class="comment">// 获取购物车对象</span></span><br><span class="line">    Cart cart = (Cart) req.getSession().getAttribute(<span class="string">&quot;cart&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (cart != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 删除购物车商品项</span></span><br><span class="line">        cart.deleteItem(id);</span><br><span class="line">        <span class="comment">// 重定向回原来购物车展示页面</span></span><br><span class="line">        resp.sendRedirect(req.getHeader(<span class="string">&quot;Referer&quot;</span>));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><ol start="2"><li>修改<code>cart.jsp</code>，添加删除的请求地址，并增加确认删除的提示。</li></ol><p><img src="https://img-blog.csdnimg.cn/e0a2c453d2c14e0cb777ac861ec0a302.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改cart.jsp"></p><hr><h1 id="清空购物车"><a href="#清空购物车" class="headerlink" title="清空购物车"></a>清空购物车</h1><p><code>CartServlet</code>增加<code>clear</code>方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">clear</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException,IOException</span>&#123;</span><br><span class="line">    <span class="comment">// 1 获取购物车对象</span></span><br><span class="line">    Cart cart = (Cart) req.getSession().getAttribute(<span class="string">&quot;cart&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (cart != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 清空购物车</span></span><br><span class="line">        cart.clear();</span><br><span class="line">        <span class="comment">// 重定向回原来购物车的展示页面</span></span><br><span class="line">        resp.sendRedirect(req.getHeader(<span class="string">&quot;Referer&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>cart.jsp</code>页面的内容，给购物车添加请求地址，和添加<code>id</code>属性，以及清空确认提示操作<br><img src="https://img-blog.csdnimg.cn/bdbe6c477e464cdc9736c96851c9c494.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改cart.jsp"></p><hr><h1 id="修改购物车商品的数量"><a href="#修改购物车商品的数量" class="headerlink" title="修改购物车商品的数量"></a>修改购物车商品的数量</h1><ol><li><code>CartServlet</code>添加<code>updateCount</code>方法</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">updateCount</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException,IOException</span>&#123;</span><br><span class="line">    <span class="comment">// 获取请求的参数 商品编号，商品数量</span></span><br><span class="line">    <span class="keyword">int</span> id = WebUtils.parseInt(req.getParameter(<span class="string">&quot;id&quot;</span>), <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">int</span> count = WebUtils.parseInt(req.getParameter(<span class="string">&quot;count&quot;</span>), <span class="number">1</span>);</span><br><span class="line">    <span class="comment">// 获取Cart购物车对象</span></span><br><span class="line">    Cart cart = (Cart) req.getSession().getAttribute(<span class="string">&quot;cart&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (cart != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 修改商品数量</span></span><br><span class="line">        cart.updateCount(id, count);</span><br><span class="line">        <span class="comment">// 重定向回原来购物车展示页面</span></span><br><span class="line">        resp.sendRedirect(req.getHeader(<span class="string">&quot;Referer&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li>修改 <code>cart.jsp</code><br><img src="https://img-blog.csdnimg.cn/bb99c951e0a549d2ad53ebdde849ccc5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改cart.jsp(一)"><br><img src="https://img-blog.csdnimg.cn/a51ebac832d14122b33ff395a8ea9bfe.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改cart.jsp(二)"></li></ol><hr><h1 id="首页购物车数据回显"><a href="#首页购物车数据回显" class="headerlink" title="首页购物车数据回显"></a>首页购物车数据回显</h1><ol><li>在添加商品到购物车的时候，保存最后一个添加的商品名称。<br><img src="https://img-blog.csdnimg.cn/44e766f03bab4fe5864074ba774db232.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改CartServlet的addItem方法"></li><li>在<code>index.jsp</code>页面中输出购物车信息<br><img src="https://img-blog.csdnimg.cn/2d060503f45e43b3afe7a5543aecf6be.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改index.jsp"></li></ol>]]></content>
      
      
      <categories>
          
          <category> JavaWeb书城项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jsp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb书城项目(七)———用户功能完善</title>
      <link href="/2021/11/10/JavaWeb_BookProject_7/"/>
      <url>/2021/11/10/JavaWeb_BookProject_7/</url>
      
        <content type="html"><![CDATA[<blockquote><p>整个项目源代码可以到我的github上下载。之前我们做出了用户功能的注册与登录功能，这次我们将用户功能完善，包括用户登录显示用户名，注销用户，以及验证码的使用</p></blockquote><h1 id="登录显示用户名"><a href="#登录显示用户名" class="headerlink" title="登录显示用户名"></a>登录显示用户名</h1><p>一般来说，我们登录之后会显示用户名，我们之前是写死的，这次改成动态的。</p><span id="more"></span><ol><li><code>UserServlet</code>程序中保存用户登录的信息。因为我们登录之后的所有网页都是要显示用户名的，所以不能保存到<code>request</code>域，而是要保存到<code>session</code>域。</li><li>修改<code>login_success_menu.jsp</code>,，因为我们之前把登录成功之后的菜单信息提取出一个<code>jsp</code>文件，所以只需要修改这个公共的部分。<br><img src="https://img-blog.csdnimg.cn/55f0ff711a5e470785333aca061f2086.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改login_success_menu.jsp"></li><li>修改首页<code>index.jsp</code>页面的菜单，使其在登录之后也能显示用户信息。<br><img src="https://img-blog.csdnimg.cn/515f4d64ef0a46258f909fde5d1e7115.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改首页index.jsp"></li></ol><hr><h1 id="登出注销用户"><a href="#登出注销用户" class="headerlink" title="登出注销用户"></a>登出注销用户</h1><ol><li><code>UserServlet</code>程序中添加<code>logout</code>方法</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 注销</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> req</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> resp</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> ServletException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">logout</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 1. 销毁Session中用户登录的信息（或者销毁Session）</span></span><br><span class="line">    req.getSession().invalidate();</span><br><span class="line">    <span class="comment">// 2. 重定向到首页（或登录页面）。</span></span><br><span class="line">    resp.sendRedirect(req.getContextPath());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li> 修改注销的菜单地址<br><img src="https://img-blog.csdnimg.cn/2e33e94694e94432a8d0f72b90db8c96.png" alt="修改注销菜单的地址"></li></ol><hr><h1 id="使用验证码的原因及原理"><a href="#使用验证码的原因及原理" class="headerlink" title="使用验证码的原因及原理"></a>使用验证码的原因及原理</h1><p>之前验证码一直是写死的，这次我们实现动态的验证码。使用验证码的原因之一是为了防止用户重复提交表单而产生错误。<br>表单重复提交有以下三种情况。</p><ol><li>提交完表单。服务器使用请求转来进行页面跳转。这个时候，用户按下功能键 F5，就会发起最后一次的请求。造成表单重复提交问题。解决方法：这个可以使用重定向来进行跳转</li><li>用户正常提交服务器，但是由于网络延迟等原因，迟迟未收到服务器的响应，这个时候，用户以为提交失败，就会着急，然后多点了几次提交操作，也会造成表单重复提交。</li><li>用户正常提交服务器。服务器也没有延迟，但是提交完成后，用户回退浏览器。重新提交。也会造成表单重复提交。</li></ol><p>最后两种情况无法通过重定向解决，所以我们可以使用验证码解决。<br><img src="https://img-blog.csdnimg.cn/8019390f37f24a0dab7465015333eb35.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="验证码解决表单重复提交的底层原理"></p><hr><h1 id="谷歌-kaptcha-图片验证码的使用"><a href="#谷歌-kaptcha-图片验证码的使用" class="headerlink" title="谷歌 kaptcha 图片验证码的使用"></a>谷歌 kaptcha 图片验证码的使用</h1><p>我们使用现有的 <code>jar</code> 包来完成我们的验证码功能。</p><ol><li>导入谷歌验证码的 <code>jar</code> 包</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kaptcha-<span class="number">2.3</span><span class="number">.2</span>.jar</span><br></pre></td></tr></table></figure><ol start="2"><li>在 <code>web.xml</code> 中去配置用于生成验证码的 <code>Servlet</code> 程序，因为 <code>kaptcha</code> 提供的也是 <code>Servlet</code> 程序，所以要在 <code>web.xml</code> 中配置完成才能使用。</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">servlet</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>KaptchaServlet<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-class</span>&gt;</span>com.google.code.kaptcha.servlet.KaptchaServlet<span class="tag">&lt;/<span class="name">servlet-class</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">servlet</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">servlet-mapping</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>KaptchaServlet<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/kaptcha.jpg<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">servlet-mapping</span>&gt;</span></span><br></pre></td></tr></table></figure><ol start="3"><li><p>在表单中使用 <code>img</code> 标签去显示验证码图片并使用它<br><img src="https://img-blog.csdnimg.cn/a9d816a489f04b46ac3a6556f9d9bca5.png" alt="使用验证码图片"></p></li><li><p>在服务器获取谷歌生成的验证码和客户端发送过来的验证码比较使用<br><img src="https://img-blog.csdnimg.cn/bd8d876090d44865aaf4cb9631367829.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="服务器比较验证码"></p></li><li><p>切换验证码，用户有时候可能看不清验证码，所以我们还要提供点击图片替换的功能。</p></li></ol><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 给验证码图片绑定单击事件</span></span><br><span class="line">$(<span class="string">&quot;#code_img&quot;</span>).click(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line"><span class="comment">// 在事件响应的function函数中有一个this对象，这个this对象，是当前正在响应事件的dom对象</span></span><br><span class="line"><span class="comment">// src 属性表示验证码img标签的图片路径。它可读可写</span></span><br><span class="line"><span class="comment">// 添加随机变量，防止调用缓存</span></span><br><span class="line"><span class="built_in">this</span>.src = <span class="string">&quot;$&#123;basePath&#125;kaptcha.jpg?d=&quot;</span> + <span class="keyword">new</span> <span class="built_in">Date</span>();</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> JavaWeb书城项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jsp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb书城项目(六)———图书分页</title>
      <link href="/2021/11/08/JavaWeb_BookProject_6/"/>
      <url>/2021/11/08/JavaWeb_BookProject_6/</url>
      
        <content type="html"><![CDATA[<blockquote><p>整个项目源代码可以到我的github上下载。前五个部分我们已经完成了用户的注册与登录模块，以及后台的图书管理，第六部分我们完成图书的分页部分，分页的原因就是一页显示全部信息太繁杂了，所以需要需要分页来解决这个问题。</p></blockquote><h1 id="分页模块的分析"><a href="#分页模块的分析" class="headerlink" title="分页模块的分析"></a>分页模块的分析</h1><span id="more"></span><p><img src="https://img-blog.csdnimg.cn/76b627176473437793a8821d8053a8b7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="分页模块的分析"></p><hr><h1 id="分页模型Page的抽取"><a href="#分页模型Page的抽取" class="headerlink" title="分页模型Page的抽取"></a>分页模型Page的抽取</h1><p>由分页的视图分析出分页的对象模型<code>Page</code>类有如下属性</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Page是分页的模型对象</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;T&gt; 是具体的模块的javaBean类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Page</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Integer PAGE_SIZE = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 当前页码</span></span><br><span class="line">    <span class="keyword">private</span> Integer pageNo;</span><br><span class="line">    <span class="comment">// 总页码</span></span><br><span class="line">    <span class="keyword">private</span> Integer pageTotal;</span><br><span class="line">    <span class="comment">// 当前页显示数量</span></span><br><span class="line">    <span class="keyword">private</span> Integer pageSize = PAGE_SIZE;</span><br><span class="line">    <span class="comment">// 总记录数</span></span><br><span class="line">    <span class="keyword">private</span> Integer pageTotalCount;</span><br><span class="line">    <span class="comment">// 当前页数据</span></span><br><span class="line">    <span class="keyword">private</span> List&lt;Book&gt; items;</span><br></pre></td></tr></table></figure><hr><h1 id="分页的初步实现"><a href="#分页的初步实现" class="headerlink" title="分页的初步实现"></a>分页的初步实现</h1><p><code>BookDao</code>代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Integer <span class="title">queryForPageTotalCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    String sql = <span class="string">&quot;select count(*) from t_book&quot;</span>;</span><br><span class="line">    Number count = (Number) queryForSingleValue(sql);</span><br><span class="line">    <span class="keyword">return</span> count.intValue();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">queryForPageItems</span><span class="params">(<span class="keyword">int</span> begin, <span class="keyword">int</span> pageSize)</span> </span>&#123;</span><br><span class="line">    String sql = <span class="string">&quot;select `id`,`name`,`author`,`price`,`sales`,`stock`,`img_path` imgPath&quot;</span> +</span><br><span class="line">            <span class="string">&quot; from t_book limit ?,?&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> queryForList(Book.class, sql, begin, pageSize);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>BookService</code>代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Page&lt;Book&gt; <span class="title">page</span><span class="params">(<span class="keyword">int</span> pageNo, <span class="keyword">int</span> pageSize)</span> </span>&#123;</span><br><span class="line">    Page&lt;Book&gt; page = <span class="keyword">new</span> Page&lt;Book&gt;();</span><br><span class="line">    <span class="comment">// 设置当前页码</span></span><br><span class="line">    page.setPageNo(pageNo);</span><br><span class="line">    <span class="comment">// 设置每页显示的数量</span></span><br><span class="line">    page.setPageSize(pageSize);</span><br><span class="line">    <span class="comment">// 求总记录数</span></span><br><span class="line">    Integer pageTotalCount = bookDao.queryForPageTotalCount();</span><br><span class="line">    <span class="comment">// 设置总记录数</span></span><br><span class="line">    page.setPageTotalCount(pageTotalCount);</span><br><span class="line">    <span class="comment">// 求总页码</span></span><br><span class="line">    Integer pageTotal = pageTotalCount / pageSize;</span><br><span class="line">    <span class="keyword">if</span> (pageTotalCount % pageSize &gt; <span class="number">0</span>)&#123;</span><br><span class="line">        pageTotal+=<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 设置总页码</span></span><br><span class="line">    page.setPageTotal(pageTotal);</span><br><span class="line">    <span class="comment">// 求当前页数据的开始索引</span></span><br><span class="line">    <span class="keyword">int</span> begin = (page.getPageNo() - <span class="number">1</span>) * pageSize;</span><br><span class="line">    <span class="comment">// 求当前页数据</span></span><br><span class="line">    List&lt;Book&gt; items = bookDao.queryForPageItems(begin, pageSize);</span><br><span class="line">    <span class="comment">// 设置当前页数据</span></span><br><span class="line">    page.setItems(items);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> page;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>BookServlet</code>程序的代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">page</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">     <span class="comment">//1 获取请求的参数 pageNo 和 pageSize</span></span><br><span class="line">     <span class="keyword">int</span> pageNo = WebUtils.parseInt(req.getParameter(<span class="string">&quot;pageNo&quot;</span>), <span class="number">1</span>);</span><br><span class="line">     <span class="keyword">int</span> pageSize = WebUtils.parseInt(req.getParameter(<span class="string">&quot;pageSize&quot;</span>), Page.PAGE_SIZE);</span><br><span class="line">     <span class="comment">//2 调用BookService.page(pageNo, pageSize): Page对象</span></span><br><span class="line">     Page&lt;Book&gt; page = bookService.page(pageNo, pageSize);</span><br><span class="line">     <span class="comment">//3 保存 Page 对象到 Request 域中</span></span><br><span class="line">     req.setAttribute(<span class="string">&quot;page&quot;</span>, page);</span><br><span class="line">     <span class="comment">//4 请求转发到pages/manager/book_manager.jsp页面</span></span><br><span class="line">     req.getRequestDispatcher(<span class="string">&quot;/pages/manager/book_manager.jsp&quot;</span>).forward(req,resp);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p><code>manager_menu.jsp</code>中图书管理请求地址的修改<br><img src="https://img-blog.csdnimg.cn/3347eb0d1b46461c93adbf88b3521f74.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改图书管理请求地址"><br><code>book_manager.jsp</code>修改<br><img src="https://img-blog.csdnimg.cn/67e6852ccda441cca0ade049e8c1205f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="book_manager.jsp修改(一)"><br><img src="https://img-blog.csdnimg.cn/e456acb44db947bf855dfd51ab3c24c8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="book_manager.jsp修改(二)"></p><hr><h1 id="首页，上一页，下一页，末页实现"><a href="#首页，上一页，下一页，末页实现" class="headerlink" title="首页，上一页，下一页，末页实现"></a>首页，上一页，下一页，末页实现</h1><p>修改<code>book_manager.jsp</code><br><img src="https://img-blog.csdnimg.cn/f19de00dbfd543a4a65420fc81d60d2b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改book_manager.jsp"></p><hr><h1 id="实现跳到指定页数"><a href="#实现跳到指定页数" class="headerlink" title="实现跳到指定页数"></a>实现跳到指定页数</h1><p>修改<code>book_manager.jsp</code>，通过绑定单击事件实现跳到指定页数<br><img src="https://img-blog.csdnimg.cn/adfeee20f36d4678bb7e648bee6e75b9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改book_manager.jsp"><br><code>Page</code>对象的修改，完成数据边界的有效检查，使其不会跳到没有的页数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPageNo</span><span class="params">(Integer pageNo)</span> </span>&#123;</span><br><span class="line"><span class="comment">/* 数据边界的有效检查 */</span></span><br><span class="line"><span class="keyword">if</span> (pageNo &lt; <span class="number">1</span>) &#123;</span><br><span class="line">pageNo = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (pageNo &gt; pageTotal) &#123;</span><br><span class="line">pageNo = pageTotal;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">this</span>.pageNo = pageNo;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>与之对应，要修改 <code>BookService</code>中<code>page</code>方法，因为设置当前页码时，需要 <code>pageTotal</code> 来进行数据边界的有效检查，所以设置当前页码要放在设置总页码之后。<br><img src="https://img-blog.csdnimg.cn/62db9116b0d946f6b91210a366ba014c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改BookService中page方法"></p><hr><h1 id="页码的显示"><a href="#页码的显示" class="headerlink" title="页码的显示"></a>页码的显示</h1><p>一般来说，显示页码的时候，不仅会显示当前页的页码，还会显示前几页的页码，以及后几页的页码，然后点击这些页码就可以跳转到指定页。<br>这里实现一次显示5个页码，下面分情况讨论：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">情况<span class="number">1</span>:</span><br><span class="line">如果总页码小于等于<span class="number">5</span>，页码的范围是：<span class="number">1</span>~总页码</span><br><span class="line"><span class="number">1</span>页 <span class="number">1</span></span><br><span class="line"><span class="number">2</span>页 <span class="number">1</span>，<span class="number">2</span></span><br><span class="line"><span class="number">3</span>页 <span class="number">1</span>，<span class="number">2</span>，<span class="number">3</span></span><br><span class="line"><span class="number">4</span>页 <span class="number">1</span>，<span class="number">2</span>，<span class="number">3</span>，<span class="number">4</span></span><br><span class="line"><span class="number">5</span>页 <span class="number">1</span>，<span class="number">2</span>，<span class="number">3</span>，<span class="number">4</span>，<span class="number">5</span></span><br><span class="line">情况<span class="number">2</span>：</span><br><span class="line">总页码大于<span class="number">5</span>的情况。假设一共<span class="number">10</span>页</span><br><span class="line">小情况<span class="number">1</span>：当前页码为前面<span class="number">2</span>个，页码的范围是：<span class="number">1</span>~<span class="number">5</span></span><br><span class="line">[<span class="number">1</span>],<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span></span><br><span class="line"><span class="number">1</span>,[<span class="number">2</span>],<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span></span><br><span class="line">小情况<span class="number">2</span>：当前页码为最后<span class="number">2</span>个，页码的范围是：总页码-<span class="number">4</span>~总页码</span><br><span class="line"><span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,[<span class="number">9</span>],<span class="number">10</span></span><br><span class="line"><span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,[<span class="number">10</span>]</span><br><span class="line">小情况<span class="number">3</span>：其它情况，页码的范围是：当前页码-<span class="number">2</span>~当前页码+<span class="number">2</span></span><br><span class="line"><span class="number">2</span>,<span class="number">3</span>,[<span class="number">4</span>],<span class="number">5</span>,<span class="number">6</span></span><br><span class="line"><span class="number">3</span>,<span class="number">4</span>,[<span class="number">5</span>],<span class="number">6</span>,<span class="number">7</span></span><br></pre></td></tr></table></figure><p>按照上面的情况修改 <code>book_manager.jsp</code></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&lt;c:choose&gt;</span><br><span class="line">&lt;%--情况<span class="number">1</span>：如果总页码小于等于<span class="number">5</span>--%&gt;</span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:when</span> <span class="attr">test</span>=<span class="string">&quot;$&#123; requestScope.page.pageTotal &lt;=5 &#125;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;begin&quot;</span> <span class="attr">value</span>=<span class="string">&quot;1&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;end&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;requestScope.page.pageTotal&#125;&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">c:when</span>&gt;</span></span></span><br><span class="line">&lt;%--情况<span class="number">2</span>：总页码大于<span class="number">5</span>的情况--%&gt;</span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:when</span> <span class="attr">test</span>=<span class="string">&quot;$&#123;requestScope.page.pageTotal &gt; 5&#125;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:choose</span>&gt;</span></span></span><br><span class="line"><span class="xml">&lt;%--小情况1：当前页码为前面2个--%&gt;</span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:when</span> <span class="attr">test</span>=<span class="string">&quot;$&#123;requestScope.page.pageNo &lt; 3&#125;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;begin&quot;</span> <span class="attr">value</span>=<span class="string">&quot;1&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;end&quot;</span> <span class="attr">value</span>=<span class="string">&quot;5&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">c:when</span>&gt;</span></span></span><br><span class="line"><span class="xml">&lt;%--小情况2：当前页码为最后2个--%&gt;</span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:when</span> <span class="attr">test</span>=<span class="string">&quot;$&#123;requestScope.page.pageNo &gt; requestScope.page.pageTotal-2&#125;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;begin&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;requestScope.page.pageTotal-4&#125;&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;end&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;requestScope.page.pageTotal&#125;&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">c:when</span>&gt;</span></span></span><br><span class="line"><span class="xml">&lt;%--小情况3：其他情况--%&gt;</span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:otherwise</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;begin&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;requestScope.page.pageNo-2&#125;&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;end&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;requestScope.page.pageNo+2&#125;&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">c:otherwise</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">c:choose</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">c:when</span>&gt;</span></span></span><br><span class="line">&lt;/c:choose&gt;</span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;c:forEach begin=<span class="string">&quot;$&#123;begin&#125;&quot;</span> end=<span class="string">&quot;$&#123;end&#125;&quot;</span> <span class="keyword">var</span>=<span class="string">&quot;i&quot;</span>&gt;</span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:if</span> <span class="attr">test</span>=<span class="string">&quot;$&#123; i == requestScope.page.pageNo &#125;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">【$&#123;i&#125;】</span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">c:if</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">c:if</span> <span class="attr">test</span>=<span class="string">&quot;$&#123; i != requestScope.page.pageNo &#125;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;manager/bookServlet?action=page&amp;pageNo=$&#123;i&#125;&quot;</span>&gt;</span>$&#123;i&#125;<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">c:if</span>&gt;</span></span></span><br><span class="line">&lt;/c:forEach&gt;</span><br></pre></td></tr></table></figure><hr><h1 id="修改分页后，增加，删除，修改图书信息的回显页面"><a href="#修改分页后，增加，删除，修改图书信息的回显页面" class="headerlink" title="修改分页后，增加，删除，修改图书信息的回显页面"></a>修改分页后，增加，删除，修改图书信息的回显页面</h1><p>以修改图书为例<br>1.在修改的请求地址上追加当前页码参数<br><img src="https://img-blog.csdnimg.cn/12fec58591d9449bb662fb4c8e0a993f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改book_manager,jsp"><br>2. 在<code>book_edit.jsp</code>页面中使用隐藏域记录下<code>pageNo</code>参数<br><img src="https://img-blog.csdnimg.cn/be8bc7543c4546edb2d3ae393e6e838f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="使用隐藏域记录下pageNo参数"></p><ol start="3"><li>在服务器重定向时，获取当前页码追加上进行跳转<br><img src="https://img-blog.csdnimg.cn/1dc609c769464c06810b4f3a7d16e44f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="追加当前页码进行跳转"></li></ol><hr><h1 id="首页index-jsp的跳转"><a href="#首页index-jsp的跳转" class="headerlink" title="首页index.jsp的跳转"></a>首页index.jsp的跳转</h1><p>因为首页也需要分页，所以我们访问首页的时候需要让其通过 <code>ClientBookServlet</code>程序让其跳转到 <code>web目录/pages/client目录的/index.jsp</code><br><img src="https://img-blog.csdnimg.cn/735658210ebd44b5972d937ce3b2a1c2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="首页index.jsp的跳转"><br>创建<code>ClientBookServlet</code>程序</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.web;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.Book;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.Page;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.service.BookService;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.service.impl.BookServiceImpl;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.utils.WebUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletException;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClientBookServlet</span> <span class="keyword">extends</span> <span class="title">BaseServlet</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> BookService bookService = <span class="keyword">new</span> BookServiceImpl();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">page</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">        <span class="comment">//System.out.println(&quot;经过了前台程序&quot;);</span></span><br><span class="line">        <span class="comment">//1 获取请求的参数 pageNo 和 pageSize</span></span><br><span class="line">        <span class="keyword">int</span> pageNo = WebUtils.parseInt(req.getParameter(<span class="string">&quot;pageNo&quot;</span>), <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">int</span> pageSize = WebUtils.parseInt(req.getParameter(<span class="string">&quot;pageSize&quot;</span>), Page.PAGE_SIZE);</span><br><span class="line">        <span class="comment">//2 调用BookService.page(pageNo, pageSize): Page对象</span></span><br><span class="line">        Page&lt;Book&gt; page = bookService.page(pageNo, pageSize);</span><br><span class="line">        page.setUrl(<span class="string">&quot;client/bookServlet?action=page&quot;</span>);</span><br><span class="line">        <span class="comment">//3 保存 Page 对象到 Request 域中</span></span><br><span class="line">        req.setAttribute(<span class="string">&quot;page&quot;</span>, page);</span><br><span class="line">        <span class="comment">//4 请求转发到pages/client/index.jsp页面</span></span><br><span class="line">        req.getRequestDispatcher(<span class="string">&quot;/pages/client/index.jsp&quot;</span>).forward(req,resp);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>配置<code>web.xml</code>，增加<code>ClientBookServlet</code>的映射</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">servlet</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>ClientBookServlet<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-class</span>&gt;</span>com.atguigu.web.ClientBookServlet<span class="tag">&lt;/<span class="name">servlet-class</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">servlet</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">servlet-mapping</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>ClientBookServlet<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/client/bookServlet<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">servlet-mapping</span>&gt;</span></span><br></pre></td></tr></table></figure><p>创建<code>client/index.jsp</code></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">&lt;%@ taglib prefix=<span class="string">&quot;c&quot;</span> uri=<span class="string">&quot;http://java.sun.com/jsp/jstl/core&quot;</span> %&gt;</span><br><span class="line">&lt;%@ page contentType=<span class="string">&quot;text/html;charset=UTF-8&quot;</span> language=<span class="string">&quot;java&quot;</span> %&gt;</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset=&quot;UTF-8&quot;&gt;</span><br><span class="line">    &lt;title&gt;书城首页&lt;/title&gt;</span><br><span class="line">    &lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; href=&quot;static/css/style.css&quot; &gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line"></span><br><span class="line">&lt;div id=&quot;header&quot;&gt;</span><br><span class="line">    &lt;img class=&quot;logo_img&quot; alt=&quot;&quot; src=&quot;static/img/logo.gif&quot; &gt;</span><br><span class="line">    &lt;span class=&quot;wel_word&quot;&gt;网上书城&lt;/span&gt;</span><br><span class="line">    &lt;div&gt;</span><br><span class="line">        &lt;a href=&quot;pages/user/login.jsp&quot;&gt;登录&lt;/a&gt;</span><br><span class="line">        &lt;a href=&quot;pages/user/regist.jsp&quot;&gt;注册&lt;/a&gt; &amp;nbsp;&amp;nbsp;</span><br><span class="line">        &lt;a href=&quot;pages/cart/cart.jsp&quot;&gt;购物车&lt;/a&gt;</span><br><span class="line">        &lt;a href=&quot;pages/manager/manager.jsp&quot;&gt;后台管理&lt;/a&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">&lt;/div&gt;</span><br><span class="line">&lt;div id=&quot;main&quot;&gt;</span><br><span class="line">    &lt;div id=&quot;book&quot;&gt;</span><br><span class="line">        &lt;div class=&quot;book_cond&quot;&gt;</span><br><span class="line">            &lt;form action=&quot;&quot; method=&quot;get&quot;&gt;</span><br><span class="line">                价格：&lt;input id=&quot;min&quot; type=&quot;text&quot; name=&quot;min&quot; value=&quot;&quot;&gt; 元 -</span><br><span class="line">                &lt;input id=&quot;max&quot; type=&quot;text&quot; name=&quot;max&quot; value=&quot;&quot;&gt; 元</span><br><span class="line">                &lt;input type=&quot;submit&quot; value=&quot;查询&quot; /&gt;</span><br><span class="line">            &lt;/form&gt;</span><br><span class="line">        &lt;/div&gt;</span><br><span class="line">        &lt;div style=&quot;text-align: center&quot;&gt;</span><br><span class="line">            &lt;span&gt;您的购物车中有3件商品&lt;/span&gt;</span><br><span class="line">            &lt;div&gt;</span><br><span class="line">                您刚刚将&lt;span style=&quot;color: #ff0000&quot;&gt;时间简史&lt;/span&gt;加入到了购物车中</span><br><span class="line">            &lt;/div&gt;</span><br><span class="line">        &lt;/div&gt;</span><br><span class="line">        &lt;c:forEach items=&quot;$&#123;requestScope.page.items&#125;&quot; var=&quot;book&quot;&gt;</span><br><span class="line">        &lt;div class=&quot;b_list&quot;&gt;</span><br><span class="line">            &lt;div class=&quot;img_div&quot;&gt;</span><br><span class="line">                &lt;img class=&quot;book_img&quot; alt=&quot;&quot; src=&quot;$&#123;book.imgPath&#125;&quot; /&gt;</span><br><span class="line">            &lt;/div&gt;</span><br><span class="line">            &lt;div class=&quot;book_info&quot;&gt;</span><br><span class="line">                &lt;div class=&quot;book_name&quot;&gt;</span><br><span class="line">                    &lt;span class=&quot;sp1&quot;&gt;书名:&lt;/span&gt;</span><br><span class="line">                    &lt;span class=&quot;sp2&quot;&gt;$&#123;book.name&#125;&lt;/span&gt;</span><br><span class="line">                &lt;/div&gt;</span><br><span class="line">                &lt;div class=&quot;book_author&quot;&gt;</span><br><span class="line">                    &lt;span class=&quot;sp1&quot;&gt;作者:&lt;/span&gt;</span><br><span class="line">                    &lt;span class=&quot;sp2&quot;&gt;$&#123;book.author&#125;&lt;/span&gt;</span><br><span class="line">                &lt;/div&gt;</span><br><span class="line">                &lt;div class=&quot;book_price&quot;&gt;</span><br><span class="line">                    &lt;span class=&quot;sp1&quot;&gt;价格:&lt;/span&gt;</span><br><span class="line">                    &lt;span class=&quot;sp2&quot;&gt;￥$&#123;book.price&#125;&lt;/span&gt;</span><br><span class="line">                &lt;/div&gt;</span><br><span class="line">                &lt;div class=&quot;book_sales&quot;&gt;</span><br><span class="line">                    &lt;span class=&quot;sp1&quot;&gt;销量:&lt;/span&gt;</span><br><span class="line">                    &lt;span class=&quot;sp2&quot;&gt;$&#123;book.sales&#125;&lt;/span&gt;</span><br><span class="line">                &lt;/div&gt;</span><br><span class="line">                &lt;div class=&quot;book_amount&quot;&gt;</span><br><span class="line">                    &lt;span class=&quot;sp1&quot;&gt;库存:&lt;/span&gt;</span><br><span class="line">                    &lt;span class=&quot;sp2&quot;&gt;$&#123;book.stock&#125;&lt;/span&gt;</span><br><span class="line">                &lt;/div&gt;</span><br><span class="line">                &lt;div class=&quot;book_add&quot;&gt;</span><br><span class="line">                    &lt;button&gt;加入购物车&lt;/button&gt;</span><br><span class="line">                &lt;/div&gt;</span><br><span class="line">            &lt;/div&gt;</span><br><span class="line">        &lt;/div&gt;</span><br><span class="line">        &lt;/c:forEach&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &lt;/div&gt;</span><br><span class="line"></span><br><span class="line">    &lt;div id=&quot;page_nav&quot;&gt;</span><br><span class="line">        &lt;a href=&quot;#&quot;&gt;首页&lt;/a&gt;</span><br><span class="line">        &lt;a href=&quot;#&quot;&gt;上一页&lt;/a&gt;</span><br><span class="line">        &lt;a href=&quot;#&quot;&gt;3&lt;/a&gt;</span><br><span class="line">        【4】</span><br><span class="line">        &lt;a href=&quot;#&quot;&gt;5&lt;/a&gt;</span><br><span class="line">        &lt;a href=&quot;#&quot;&gt;下一页&lt;/a&gt;</span><br><span class="line">        &lt;a href=&quot;#&quot;&gt;末页&lt;/a&gt;</span><br><span class="line">        共10页，30条记录 到第&lt;input value=&quot;4&quot; name=&quot;pn&quot; id=&quot;pn_input&quot;/&gt;页</span><br><span class="line">        &lt;input type=&quot;button&quot; value=&quot;确定&quot;&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line"></span><br><span class="line">&lt;/div&gt;</span><br><span class="line"></span><br><span class="line">&lt;div id=&quot;bottom&quot;&gt;</span><br><span class="line">&lt;span&gt;</span><br><span class="line">尚硅谷书城.Copyright &amp;copy;2015</span><br><span class="line">&lt;/span&gt;</span><br><span class="line">&lt;/div&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure><p>修改<code>web/index.jsp</code>为请求转发到<code>Servlet</code></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;%@ page contentType=<span class="string">&quot;text/html;charset=UTF-8&quot;</span> language=<span class="string">&quot;java&quot;</span> %&gt;</span><br><span class="line">&lt;%--只负责请求转发--%&gt;</span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">jsp:forward</span> <span class="attr">page</span>=<span class="string">&quot;/client/bookServlet?action=page&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">jsp:forward</span>&gt;</span></span></span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h1 id="分页条的抽取"><a href="#分页条的抽取" class="headerlink" title="分页条的抽取"></a>分页条的抽取</h1><p>前台页面也需要分页条，因为对于分页条而言，只是请求的 <code>url</code> 不同，我们可以给 <code>page</code> 添加 <code>url</code> 属性，再把分页条抽取出来，就可以简单的调用分页条。</p><ol><li><p>在 <code>page</code> 对象中添加 <code>url</code> 属性<br><img src="https://img-blog.csdnimg.cn/e63efed158e642599ec75254c30fdd6f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="page对象中添加url属性"></p></li><li><p>在 <code>Servlet</code> 程序中的 <code>page</code> 分页方法中设置 <code>url</code> 的分页请求地址<br><img src="https://img-blog.csdnimg.cn/e32c63bca1c048068792346bd952f0e0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="设置url的分页请求地址"></p></li><li><p>修改分页条中请求地址为<code>url</code>变量输出，并抽取一个单独的<code>page_nav.jsp</code>页面</p></li></ol><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">&lt;%@ page contentType=<span class="string">&quot;text/html;charset=UTF-8&quot;</span> language=<span class="string">&quot;java&quot;</span> %&gt;</span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;page_nav&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">c:choose</span>&gt;</span></span></span><br><span class="line"><span class="xml">        &lt;%--情况1：如果总页码小于等于5--%&gt;</span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">c:when</span> <span class="attr">test</span>=<span class="string">&quot;$&#123; requestScope.page.pageTotal &lt;=5 &#125;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;begin&quot;</span> <span class="attr">value</span>=<span class="string">&quot;1&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;end&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;requestScope.page.pageTotal&#125;&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">c:when</span>&gt;</span></span></span><br><span class="line"><span class="xml">        &lt;%--情况2：总页码大于5的情况--%&gt;</span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">c:when</span> <span class="attr">test</span>=<span class="string">&quot;$&#123;requestScope.page.pageTotal &gt; 5&#125;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">c:choose</span>&gt;</span></span></span><br><span class="line"><span class="xml">                &lt;%--小情况1：当前页码为前面2个--%&gt;</span></span><br><span class="line"><span class="xml">                <span class="tag">&lt;<span class="name">c:when</span> <span class="attr">test</span>=<span class="string">&quot;$&#123;requestScope.page.pageNo &lt; 3&#125;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">                    <span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;begin&quot;</span> <span class="attr">value</span>=<span class="string">&quot;1&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml">                    <span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;end&quot;</span> <span class="attr">value</span>=<span class="string">&quot;5&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml">                <span class="tag">&lt;/<span class="name">c:when</span>&gt;</span></span></span><br><span class="line"><span class="xml">                &lt;%--小情况2：当前页码为最后2个--%&gt;</span></span><br><span class="line"><span class="xml">                <span class="tag">&lt;<span class="name">c:when</span> <span class="attr">test</span>=<span class="string">&quot;$&#123;requestScope.page.pageNo &gt; requestScope.page.pageTotal-2&#125;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">                    <span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;begin&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;requestScope.page.pageTotal-4&#125;&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml">                    <span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;end&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;requestScope.page.pageTotal&#125;&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml">                <span class="tag">&lt;/<span class="name">c:when</span>&gt;</span></span></span><br><span class="line"><span class="xml">                &lt;%--小情况3：其他情况--%&gt;</span></span><br><span class="line"><span class="xml">                <span class="tag">&lt;<span class="name">c:otherwise</span>&gt;</span></span></span><br><span class="line"><span class="xml">                    <span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;begin&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;requestScope.page.pageNo-2&#125;&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml">                    <span class="tag">&lt;<span class="name">c:set</span> <span class="attr">var</span>=<span class="string">&quot;end&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;requestScope.page.pageNo+2&#125;&quot;</span>/&gt;</span></span></span><br><span class="line"><span class="xml">                <span class="tag">&lt;/<span class="name">c:otherwise</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;/<span class="name">c:choose</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">c:when</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">c:choose</span>&gt;</span></span></span><br><span class="line"><span class="xml">    &lt;%--大于首页，才显示--%&gt;</span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">c:if</span> <span class="attr">test</span>=<span class="string">&quot;$&#123;requestScope.page.pageNo &gt; 1&#125;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;$&#123;requestScope.page.url&#125;&amp;pageNo=1&quot;</span>&gt;</span>首页<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;$&#123;requestScope.page.url&#125;&amp;pageNo=$&#123;requestScope.page.pageNo-1&#125;&quot;</span>&gt;</span>上一页<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">c:if</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">c:forEach</span> <span class="attr">begin</span>=<span class="string">&quot;$&#123;begin&#125;&quot;</span> <span class="attr">end</span>=<span class="string">&quot;$&#123;end&#125;&quot;</span> <span class="attr">var</span>=<span class="string">&quot;i&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">c:if</span> <span class="attr">test</span>=<span class="string">&quot;$&#123; i == requestScope.page.pageNo &#125;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">            【$&#123;i&#125;】</span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">c:if</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">c:if</span> <span class="attr">test</span>=<span class="string">&quot;$&#123; i != requestScope.page.pageNo &#125;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;$&#123;requestScope.page.url&#125;&amp;pageNo=$&#123;i&#125;&quot;</span>&gt;</span>$&#123;i&#125;<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">c:if</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">c:forEach</span>&gt;</span></span></span><br><span class="line"><span class="xml">    &lt;%--如果已经是最后一页，则不显示下一页，末页--%&gt;</span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">c:if</span> <span class="attr">test</span>=<span class="string">&quot;$&#123;requestScope.page.pageNo &lt; requestScope.page.pageTotal&#125;&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;$&#123;requestScope.page.url&#125;&amp;pageNo=$&#123;requestScope.page.pageNo+1&#125;&quot;</span>&gt;</span>下一页<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;$&#123;requestScope.page.url&#125;&amp;pageNo=$&#123;requestScope.page.pageTotal&#125;&quot;</span>&gt;</span>末页<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">c:if</span>&gt;</span></span></span><br><span class="line"><span class="xml">    共$&#123; requestScope.page.pageTotal &#125;页，$&#123; requestScope.page.pageTotalCount &#125;条记录 到第<span class="tag">&lt;<span class="name">input</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;param.pageNo&#125;&quot;</span> <span class="attr">name</span>=<span class="string">&quot;pn&quot;</span> <span class="attr">id</span>=<span class="string">&quot;pn_input&quot;</span>/&gt;</span>页</span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">&quot;searchPageBtn&quot;</span> <span class="attr">type</span>=<span class="string">&quot;button&quot;</span> <span class="attr">value</span>=<span class="string">&quot;确定&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span>&gt;</span><span class="javascript"></span></span></span><br><span class="line"><span class="javascript"><span class="xml">        $(<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span></span></span><br><span class="line"><span class="javascript"><span class="xml">            <span class="comment">// 跳到指定页码</span></span></span></span><br><span class="line"><span class="javascript"><span class="xml">            $(<span class="string">&quot;#searchPageBtn&quot;</span>).click(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span></span></span><br><span class="line"><span class="javascript"><span class="xml">                <span class="keyword">var</span> pageNo = $(<span class="string">&quot;#pn_input&quot;</span>).val();</span></span></span><br><span class="line"><span class="javascript"><span class="xml">                &lt;%--<span class="keyword">var</span> pageTotal = $&#123;requestScope.page.pageTotal&#125;;--%&gt;</span></span></span><br><span class="line"><span class="javascript"><span class="xml">                <span class="comment">// alert(pageTotal)</span></span></span></span><br><span class="line"><span class="javascript"><span class="xml">                <span class="comment">// js语言中提供了一个 location 地址栏对象</span></span></span></span><br><span class="line"><span class="javascript"><span class="xml">                <span class="comment">// 它有一个属性叫 href. 它可以获取浏览器中地址栏中的地址</span></span></span></span><br><span class="line"><span class="javascript"><span class="xml">                <span class="comment">// href 属性可读可写</span></span></span></span><br><span class="line"><span class="javascript"><span class="xml">                location.href = <span class="string">&quot;$&#123;pageScope.basePath&#125;$&#123;requestScope.page.url&#125;&amp;pageNo=&quot;</span></span></span></span><br><span class="line"><span class="javascript"><span class="xml">                    + pageNo;</span></span></span><br><span class="line"><span class="javascript"><span class="xml">            &#125;);</span></span></span><br><span class="line"><span class="javascript"><span class="xml">        &#125;);</span></span></span><br><span class="line"><span class="javascript"><span class="xml">    </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br></pre></td></tr></table></figure><ol start="4"><li>静态包含<code>page_nav.jsp</code><br><img src="https://img-blog.csdnimg.cn/3359be11389e48e8bf94020bba39683e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="静态包含page_nav.jsp"></li></ol><hr><h1 id="首页价格搜索"><a href="#首页价格搜索" class="headerlink" title="首页价格搜索"></a>首页价格搜索</h1><p><img src="https://img-blog.csdnimg.cn/6dbff20b112540c880c521e2676c854d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="首页价格搜索"><br><code>BookDao</code>程序添加如下方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Integer <span class="title">queryForPageTotalCountByPrice</span><span class="params">(<span class="keyword">int</span> min, <span class="keyword">int</span> max)</span> </span>&#123;</span><br><span class="line">    String sql = <span class="string">&quot;select count(*) from t_book where price between ? and ?&quot;</span>;</span><br><span class="line">    Number count = (Number) queryForSingleValue(sql, min, max);</span><br><span class="line">    <span class="keyword">return</span> count.intValue();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">queryForPageItemsByPrice</span><span class="params">(<span class="keyword">int</span> begin, <span class="keyword">int</span> pageSize, <span class="keyword">int</span> min, <span class="keyword">int</span> max)</span> </span>&#123;</span><br><span class="line">    String sql = <span class="string">&quot;select `id`,`name`,`author`,`price`,`sales`,`stock`,`img_path` imgPath&quot;</span> +</span><br><span class="line">            <span class="string">&quot; from t_book where price between ? and ? limit ?,?&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> queryForList(Book.class, sql, min, max, begin, pageSize);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>BookService</code>程序添加如下方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Page&lt;Book&gt; <span class="title">pageByPrice</span><span class="params">(<span class="keyword">int</span> pageNo, <span class="keyword">int</span> pageSize, <span class="keyword">int</span> min, <span class="keyword">int</span> max)</span> </span>&#123;</span><br><span class="line">    Page&lt;Book&gt; page = <span class="keyword">new</span> Page&lt;Book&gt;();</span><br><span class="line">    <span class="comment">// 设置每页显示的数量</span></span><br><span class="line">    page.setPageSize(pageSize);</span><br><span class="line">    <span class="comment">// 求总记录数</span></span><br><span class="line">    Integer pageTotalCount = bookDao.queryForPageTotalCountByPrice(min,max);</span><br><span class="line">    <span class="comment">// 设置总记录数</span></span><br><span class="line">    page.setPageTotalCount(pageTotalCount);</span><br><span class="line">    <span class="comment">// 求总页码</span></span><br><span class="line">    Integer pageTotal = pageTotalCount / pageSize;</span><br><span class="line">    <span class="keyword">if</span> (pageTotalCount % pageSize &gt; <span class="number">0</span>)&#123;</span><br><span class="line">        pageTotal+=<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 设置总页码</span></span><br><span class="line">    page.setPageTotal(pageTotal);</span><br><span class="line">    <span class="comment">// 设置当前页码</span></span><br><span class="line">    page.setPageNo(pageNo);</span><br><span class="line">    <span class="comment">// 求当前页数据的开始索引</span></span><br><span class="line">    <span class="keyword">int</span> begin = (page.getPageNo() - <span class="number">1</span>) * pageSize;</span><br><span class="line">    <span class="comment">// 求当前页数据</span></span><br><span class="line">    List&lt;Book&gt; items = bookDao.queryForPageItemsByPrice(begin, pageSize, min, max);</span><br><span class="line">    <span class="comment">// 设置当前页数据</span></span><br><span class="line">    page.setItems(items);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> page;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>ClientBookServlet</code>程序添加如下方法，需要注意的是设置 <code>url</code> 需要加上 <code>min</code> 和 <code>max</code>参数，这样之后点击下一页之类的，才是按价格查询的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">pageByPrice</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">    <span class="comment">//System.out.println(&quot;经过了前台程序&quot;);</span></span><br><span class="line">    <span class="comment">//1 获取请求的参数 pageNo 和 pageSize, min 和 max</span></span><br><span class="line">    <span class="keyword">int</span> pageNo = WebUtils.parseInt(req.getParameter(<span class="string">&quot;pageNo&quot;</span>), <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">int</span> pageSize = WebUtils.parseInt(req.getParameter(<span class="string">&quot;pageSize&quot;</span>), Page.PAGE_SIZE);</span><br><span class="line">    <span class="keyword">int</span> min = WebUtils.parseInt(req.getParameter(<span class="string">&quot;min&quot;</span>), <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">int</span> max = WebUtils.parseInt(req.getParameter(<span class="string">&quot;max&quot;</span>), Integer.MAX_VALUE);</span><br><span class="line">    <span class="comment">//2 调用BookService.pageByPrice(pageNo, pageSize, min, max): Page对象</span></span><br><span class="line">    Page&lt;Book&gt; page = bookService.pageByPrice(pageNo, pageSize, min, max);</span><br><span class="line">    StringBuilder sb = <span class="keyword">new</span> StringBuilder(<span class="string">&quot;client/bookServlet?action=pageByPrice&quot;</span>);</span><br><span class="line">    <span class="comment">// 如果有最小价格的参数，追加到请求参数中</span></span><br><span class="line">    <span class="keyword">if</span> (req.getParameter(<span class="string">&quot;min&quot;</span>) != <span class="keyword">null</span>) &#123;</span><br><span class="line">        sb.append(<span class="string">&quot;&amp;min=&quot;</span>).append(req.getParameter(<span class="string">&quot;min&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 如果有最大价格的参数，追加到请求参数中</span></span><br><span class="line">    <span class="keyword">if</span> (req.getParameter(<span class="string">&quot;max&quot;</span>) != <span class="keyword">null</span>) &#123;</span><br><span class="line">        sb.append(<span class="string">&quot;&amp;max=&quot;</span>).append(req.getParameter(<span class="string">&quot;max&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    page.setUrl(sb.toString());</span><br><span class="line">    <span class="comment">//3 保存 Page 对象到 Request 域中</span></span><br><span class="line">    req.setAttribute(<span class="string">&quot;page&quot;</span>, page);</span><br><span class="line">    <span class="comment">//4 请求转发到pages/client/index.jsp页面</span></span><br><span class="line">    req.getRequestDispatcher(<span class="string">&quot;/pages/client/index.jsp&quot;</span>).forward(req,resp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> JavaWeb书城项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jsp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode528.按权重随机选择</title>
      <link href="/2021/11/06/Leetcode528/"/>
      <url>/2021/11/06/Leetcode528/</url>
      
        <content type="html"><![CDATA[<h1 id="题目链接"><a href="#题目链接" class="headerlink" title="题目链接"></a>题目链接</h1><p><a href="https://leetcode-cn.com/problems/random-pick-with-weight/">点我(^_^)</a></p><h1 id="题意"><a href="#题意" class="headerlink" title="题意"></a>题意</h1><p><code>w</code>数组为权重数组，我们随机选择下标<code>i</code>，按权重比 <code>w[i]/total</code>，<code>total</code>为<code>w</code>数组权重之和。</p><h1 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h1><span id="more"></span><p>我们可以预处理出一个 <code>w</code>数组的前缀和数组 <code>pre</code>，然后随机从 <code>[0,total)</code> 中随机选择一个数，然后二分找到前缀和中，最小的大于选择的这个数的下标，这样随机选择就是按权重选择的。预处理前缀和数组时间复杂度<code>O(n)</code>，二分查找时间复杂度 <code>O(logn)</code>。</p><h1 id="具体代码"><a href="#具体代码" class="headerlink" title="具体代码"></a>具体代码</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">    vector&lt;<span class="keyword">int</span>&gt; pre;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">Solution</span>(vector&lt;<span class="keyword">int</span>&gt;&amp; w) &#123;</span><br><span class="line">        pre.<span class="built_in">clear</span>();</span><br><span class="line">        pre.<span class="built_in">push_back</span>(w[<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;w.<span class="built_in">size</span>(); ++i)</span><br><span class="line">            pre.<span class="built_in">push_back</span>(pre[i<span class="number">-1</span>]+w[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">pickIndex</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">upper_bound</span>(pre.<span class="built_in">begin</span>(),pre.<span class="built_in">end</span>(),<span class="built_in">rand</span>()%pre[pre.<span class="built_in">size</span>()<span class="number">-1</span>])-pre.<span class="built_in">begin</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Your Solution object will be instantiated and called as such:</span></span><br><span class="line"><span class="comment"> * Solution* obj = new Solution(w);</span></span><br><span class="line"><span class="comment"> * int param_1 = obj-&gt;pickIndex();</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 力扣刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
            <tag> 二分 </tag>
            
            <tag> 前缀和 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb书城项目(五)———图书模块</title>
      <link href="/2021/11/05/JavaWeb_BookProject_5/"/>
      <url>/2021/11/05/JavaWeb_BookProject_5/</url>
      
        <content type="html"><![CDATA[<blockquote><p>整个项目源代码可以到我的github上下载。前四个阶段我们完成了用户的注册与登录功能，并对代码进行了优化，第五阶段我们完成书城项目的图书模块，属于后台管理中的图书管理功能，主要包括图书的添加，删除，修改以及显示。</p></blockquote><h1 id="数据库表"><a href="#数据库表" class="headerlink" title="数据库表"></a>数据库表</h1><p>首先编写图书模块的数据库表，使用如下<code>Sql</code>语句创建<code>t_book</code>表，并插入初始化测试数据。</p><span id="more"></span><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_book(</span><br><span class="line">`id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">primary</span> key auto_increment, ## 主键</span><br><span class="line">`name` <span class="type">varchar</span>(<span class="number">50</span>) <span class="keyword">not</span> <span class="keyword">null</span>,## 书名 </span><br><span class="line">`author` <span class="type">varchar</span>(<span class="number">50</span>) <span class="keyword">not</span> <span class="keyword">null</span>,## 作者</span><br><span class="line">`price` <span class="type">decimal</span>(<span class="number">11</span>,<span class="number">2</span>) <span class="keyword">not</span> <span class="keyword">null</span>,## 价格</span><br><span class="line">`sales` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">not</span> <span class="keyword">null</span>,## 销量</span><br><span class="line">`stock` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">not</span> <span class="keyword">null</span>,## 库存</span><br><span class="line">`img_path` <span class="type">varchar</span>(<span class="number">200</span>) <span class="keyword">not</span> <span class="keyword">null</span>## 书的图片路径</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">## 插入初始化测试数据</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;java从入门到放弃&#x27;</span> , <span class="string">&#x27;国哥&#x27;</span> , <span class="number">80</span> , <span class="number">9999</span> , <span class="number">9</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;数据结构与算法&#x27;</span> , <span class="string">&#x27;严敏君&#x27;</span> , <span class="number">78.5</span> , <span class="number">6</span> , <span class="number">13</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;怎样拐跑别人的媳妇&#x27;</span> , <span class="string">&#x27;龙伍&#x27;</span> , <span class="number">68</span>, <span class="number">99999</span> , <span class="number">52</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;木虚肉盖饭&#x27;</span> , <span class="string">&#x27;小胖&#x27;</span> , <span class="number">16</span>, <span class="number">1000</span> , <span class="number">50</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;C++编程思想&#x27;</span> , <span class="string">&#x27;刚哥&#x27;</span> , <span class="number">45.5</span> , <span class="number">14</span> , <span class="number">95</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;蛋炒饭&#x27;</span> , <span class="string">&#x27;周星星&#x27;</span> , <span class="number">9.9</span>, <span class="number">12</span> , <span class="number">53</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"> </span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;赌神&#x27;</span> , <span class="string">&#x27;龙伍&#x27;</span> , <span class="number">66.5</span>, <span class="number">125</span> , <span class="number">535</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;Java编程思想&#x27;</span> , <span class="string">&#x27;阳哥&#x27;</span> , <span class="number">99.5</span> , <span class="number">47</span> , <span class="number">36</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;JavaScript从入门到精通&#x27;</span> , <span class="string">&#x27;婷姐&#x27;</span> , <span class="number">9.9</span> , <span class="number">85</span> , <span class="number">95</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;cocos2d-x游戏编程入门&#x27;</span> , <span class="string">&#x27;国哥&#x27;</span> , <span class="number">49</span>, <span class="number">52</span> , <span class="number">62</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;C语言程序设计&#x27;</span> , <span class="string">&#x27;谭浩强&#x27;</span> , <span class="number">28</span> , <span class="number">52</span> , <span class="number">74</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;Lua语言程序设计&#x27;</span> , <span class="string">&#x27;雷丰阳&#x27;</span> , <span class="number">51.5</span> , <span class="number">48</span> , <span class="number">82</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;西游记&#x27;</span> , <span class="string">&#x27;罗贯中&#x27;</span> , <span class="number">12</span>, <span class="number">19</span> , <span class="number">9999</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;水浒传&#x27;</span> , <span class="string">&#x27;华仔&#x27;</span> , <span class="number">33.05</span> , <span class="number">22</span> , <span class="number">88</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"> </span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;操作系统原理&#x27;</span> , <span class="string">&#x27;刘优&#x27;</span> , <span class="number">133.05</span> , <span class="number">122</span> , <span class="number">188</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"> </span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;数据结构 java版&#x27;</span> , <span class="string">&#x27;封大神&#x27;</span> , <span class="number">173.15</span> , <span class="number">21</span> , <span class="number">81</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"> </span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;UNIX高级环境编程&#x27;</span> , <span class="string">&#x27;乐天&#x27;</span> , <span class="number">99.15</span> , <span class="number">210</span> , <span class="number">810</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"> </span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;javaScript高级编程&#x27;</span> , <span class="string">&#x27;国哥&#x27;</span> , <span class="number">69.15</span> , <span class="number">210</span> , <span class="number">810</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"> </span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;大话设计模式&#x27;</span> , <span class="string">&#x27;国哥&#x27;</span> , <span class="number">89.15</span> , <span class="number">20</span> , <span class="number">10</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br><span class="line"> </span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_book(`id` , `name` , `author` , `price` , `sales` , `stock` , `img_path`) </span><br><span class="line"><span class="keyword">values</span>(<span class="keyword">null</span> , <span class="string">&#x27;人月神话&#x27;</span> , <span class="string">&#x27;刚哥&#x27;</span> , <span class="number">88.15</span> , <span class="number">20</span> , <span class="number">80</span> , <span class="string">&#x27;static/img/default.jpg&#x27;</span>);</span><br></pre></td></tr></table></figure><hr><h1 id="编写图书模块的JavaBean"><a href="#编写图书模块的JavaBean" class="headerlink" title="编写图书模块的JavaBean"></a>编写图书模块的JavaBean</h1><p>我们在<code>pojo</code>目录下创建<code>Book</code>类，它的属性如下，并设置<code>get</code>,<code>set</code>,有参和无参构造方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Integer id;</span><br><span class="line"><span class="keyword">private</span> String name;</span><br><span class="line"><span class="keyword">private</span> String author;</span><br><span class="line"><span class="keyword">private</span> BigDecimal price;</span><br><span class="line"><span class="keyword">private</span> Integer sales;</span><br><span class="line"><span class="keyword">private</span> Integer stock;</span><br><span class="line"><span class="keyword">private</span> String imgPath = <span class="string">&quot;static/img/default.jpg&quot;</span>;</span><br></pre></td></tr></table></figure><p>需要注意的是，对于图片路径<code>imgPath</code>，我们初始化了一个默认图片路径，对于之后修改，如果传入图片路径为<code>null</code>或空串，我们就不对<code>imgPath</code>进行修改，因此我们需要对默认构造方法以及<code>setImgPath</code>方法做出如下修改。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 要求给定的图书封面图片路径不能为空</span></span><br><span class="line">       <span class="keyword">if</span> (imgPath != <span class="keyword">null</span> &amp;&amp; !<span class="string">&quot;&quot;</span>.equals(imgPath)) &#123;</span><br><span class="line">           <span class="keyword">this</span>.imgPath = imgPath;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure><hr><h1 id="编写图书模块的Dao和测试Dao"><a href="#编写图书模块的Dao和测试Dao" class="headerlink" title="编写图书模块的Dao和测试Dao"></a>编写图书模块的Dao和测试Dao</h1><p><code>Dao</code>接口</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.dao;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.Book;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">BookDao</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">addBook</span><span class="params">(Book book)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">deleteBookById</span><span class="params">(Integer id)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">updateBook</span><span class="params">(Book book)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Book <span class="title">queryBookById</span><span class="params">(Integer id)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">queryBooks</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>BookDaoImpl</code>实现类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.dao.impl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.dao.BookDao;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.Book;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BookDaoImpl</span> <span class="keyword">extends</span> <span class="title">BaseDao</span> <span class="keyword">implements</span> <span class="title">BookDao</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">addBook</span><span class="params">(Book book)</span> </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;insert into t_book(`name`,`author`,`price`,`sales`,`stock`,`img_path`) values(?,?,?,?,?,?)&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> update(sql,book.getName(),book.getAuthor(),book.getPrice(),book.getSales(),book.getStock(),book.getImgPath());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">deleteBookById</span><span class="params">(Integer id)</span> </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;delete from t_book where id = ?&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> update(sql, id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">updateBook</span><span class="params">(Book book)</span> </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;update t_book set `name`=?,`author`=?,`price`=?,`sales`=?,`stock`=?,`img_path`=? where id=?&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> update(sql,book.getName(),book.getAuthor(),book.getPrice(),book.getSales(),book.getStock(),book.getImgPath(),book.getId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Book <span class="title">queryBookById</span><span class="params">(Integer id)</span> </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;select `id`,`name`,`author`,`price`,`sales`,`stock`,`img_path` imgPath from t_book where id = ?&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> queryForOne(Book.class, sql, id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">queryBooks</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;select `id`,`name`,`author`,`price`,`sales`,`stock`,`img_path` imgPath from t_book&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> queryForList(Book.class, sql);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>BookDao</code>的测试：<br>我们在<code>test</code>目录下创建<code>BookDaoTest</code>类进行测试。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.dao.BookDao;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.dao.impl.BookDaoImpl;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.Book;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.math.BigDecimal;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.junit.Assert.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BookDaoTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> BookDao bookDao = <span class="keyword">new</span> BookDaoImpl();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addBook</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        bookDao.addBook(<span class="keyword">new</span> Book(<span class="keyword">null</span>, <span class="string">&quot;博文为太帅了&quot;</span>, <span class="string">&quot;博文&quot;</span>, <span class="keyword">new</span> BigDecimal(<span class="number">199999</span>), <span class="number">1100000</span>, <span class="number">0</span>, <span class="keyword">null</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">deleteBookById</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        bookDao.deleteBookById(<span class="number">21</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateBook</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        bookDao.updateBook(<span class="keyword">new</span> Book(<span class="number">22</span>, <span class="string">&quot;大家都很帅&quot;</span>, <span class="string">&quot;佳庆&quot;</span>,  <span class="keyword">new</span> BigDecimal(<span class="number">199999</span>), <span class="number">1100000</span>, <span class="number">0</span>, <span class="keyword">null</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">queryBookById</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println( bookDao.queryBookById(<span class="number">21</span>) );</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">queryBooks</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (Book queryBook : bookDao.queryBooks())&#123;</span><br><span class="line">            System.out.println(queryBook);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="编写图书模块的Service和测试Service"><a href="#编写图书模块的Service和测试Service" class="headerlink" title="编写图书模块的Service和测试Service"></a>编写图书模块的Service和测试Service</h1><p><code>BookService</code>接口</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.atguigu.pojo.Book;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">BookService</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addBook</span><span class="params">(Book book)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">deleteBookById</span><span class="params">(Integer id)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateBook</span><span class="params">(Book book)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Book <span class="title">queryBookById</span><span class="params">(Integer id)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">queryBooks</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>BookServiceImpl</code>实现类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.service.impl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.dao.BookDao;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.dao.impl.BookDaoImpl;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.Book;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.service.BookService;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BookServiceImpl</span> <span class="keyword">implements</span> <span class="title">BookService</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> BookDao bookDao = <span class="keyword">new</span> BookDaoImpl();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addBook</span><span class="params">(Book book)</span> </span>&#123;</span><br><span class="line">        bookDao.addBook(book);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">deleteBookById</span><span class="params">(Integer id)</span> </span>&#123;</span><br><span class="line">        bookDao.deleteBookById(id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateBook</span><span class="params">(Book book)</span> </span>&#123;</span><br><span class="line">        bookDao.updateBook(book);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Book <span class="title">queryBookById</span><span class="params">(Integer id)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> bookDao.queryBookById(id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">queryBooks</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> bookDao.queryBooks();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>BookService</code>的测试：<br>在<code>test</code>目录下创建<code>BookServiceImplTest</code>测试类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.Book;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.service.BookService;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.service.impl.BookServiceImpl;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.math.BigDecimal;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.junit.Assert.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BookServiceImplTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> BookService bookService = <span class="keyword">new</span> BookServiceImpl();</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addBook</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        bookService.addBook(<span class="keyword">new</span> Book(<span class="keyword">null</span>, <span class="string">&quot;博文真是太帅了&quot;</span>, <span class="string">&quot;博文&quot;</span>, <span class="keyword">new</span> BigDecimal(<span class="number">1555555</span>), <span class="number">200000</span>, <span class="number">0</span>, <span class="keyword">null</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">deleteBookById</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        bookService.deleteBookById(<span class="number">22</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateBook</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        bookService.updateBook(<span class="keyword">new</span> Book(<span class="number">21</span>, <span class="string">&quot;博文帅惨了&quot;</span>, <span class="string">&quot;博文&quot;</span>, <span class="keyword">new</span> BigDecimal(<span class="number">21313131</span>), <span class="number">100005</span>, <span class="number">0</span>, <span class="keyword">null</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">queryBookById</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(bookService.queryBookById(<span class="number">21</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">queryBooks</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(Book bookquery : bookService.queryBooks())</span><br><span class="line">            System.out.println(bookquery);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="编写图书模块的Web层，页面联调测试"><a href="#编写图书模块的Web层，页面联调测试" class="headerlink" title="编写图书模块的Web层，页面联调测试"></a>编写图书模块的Web层，页面联调测试</h1><h2 id="图书列表功能的实现"><a href="#图书列表功能的实现" class="headerlink" title="图书列表功能的实现"></a>图书列表功能的实现</h2><ol><li><p>图解列表功能流程<br><img src="https://img-blog.csdnimg.cn/0f0b9623abf64db5867b8b3b02d6e79c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="列表功能流程"></p></li><li><p><code>BookServlet</code>程序中添加<code>list</code>方法<br>在<code>web</code>目录下创建<code>BookServlet</code>类，并让其继承<code>BaseServlet</code>，并实现<code>list</code>方法，需要注意的是，我们直接访问是通过<code>get</code>访问的，所以我们要实现<code>doGet</code>方法，让其调用<code>doPost</code>方法。</p></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BookServlet</span> <span class="keyword">extends</span> <span class="title">BaseServlet</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> BookService bookService = <span class="keyword">new</span> BookServiceImpl();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doGet</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">        doPost(req, resp);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">list</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">        <span class="comment">//1 通过BookService查询全部图书</span></span><br><span class="line">        List&lt;Book&gt; books = bookService.queryBooks();</span><br><span class="line">        <span class="comment">//2 把全部图书保存到Request域中</span></span><br><span class="line">        req.setAttribute(<span class="string">&quot;books&quot;</span>, books);</span><br><span class="line">        <span class="comment">//3 请求转发到/pages/manager/book_manager.jsp页面</span></span><br><span class="line">        req.getRequestDispatcher(<span class="string">&quot;/pages/manager/book_manager.jsp&quot;</span>).forward(req, resp);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后在<code>web.xml</code>中添加映射</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">servlet</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>BookServlet<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-class</span>&gt;</span>com.atguigu.web.BookServlet<span class="tag">&lt;/<span class="name">servlet-class</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">servlet</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">servlet-mapping</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>BookServlet<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/manager/bookServlet<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">servlet-mapping</span>&gt;</span></span><br></pre></td></tr></table></figure><p>我们将其 <code>url</code> 放在 <code>/manager</code> 下是因为，图书管理属于后台管理，放在<code>/manager</code>下用于区别其是后台功能。<br><img src="https://img-blog.csdnimg.cn/fdf3bd7458634afbbe802b3ecebff7c2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_16,color_FFFFFF,t_70,g_se,x_16" alt="前后台区分"><br>3. 修改图书管理请求地址<br>我们在<code>manager_menu.jsp</code>中修改图书管理请求地址<br><img src="https://img-blog.csdnimg.cn/f30bc392dd9247809ae2f560b55adab1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改图书管理请求地址"><br>4. 修改 <code>pages/manager/book_manager.jsp</code> 页面的数据遍历输出<br>导入如下<code>jar</code>包</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">taglibs-standard-impl-1.2.1.jar</span><br><span class="line">taglibs-standard-spec-1.2.1.jar</span><br></pre></td></tr></table></figure><p>修改<code>book_manager.jsp</code>，利用<code>JSTL</code>标签库遍历输出图书信息。<br><img src="https://img-blog.csdnimg.cn/d30835652dfd45b3b2bf05e9158a09ff.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="利用JSTL标签库遍历输出图书信息"></p><hr><h2 id="添加图书功能的实现"><a href="#添加图书功能的实现" class="headerlink" title="添加图书功能的实现"></a>添加图书功能的实现</h2><ol><li>添加图书流程细节<br><img src="https://img-blog.csdnimg.cn/58546ca35a8f44fcb2a97babe722f1e2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="添加图书流程"></li><li>问题说明<br>如果像之前一样，通过<code>Servlet</code>的程序转发请求，那么前后算是同一个请求，而当用户提交完请求，浏览器会记录下最后一次请求的全部信息。当用户按下功能键 <code>F5</code>，就会发起浏览器记录的最后一次请求。那么就会重复添加图书项，所以这里要使用重定向，这样前后就是两次请求了，就算按<code>F5</code>也是展示图书列表。</li><li><code>BookServlet</code>程序中添加<code>add</code>方法</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">    <span class="comment">//1 获取请求的参数==封装为Book对象</span></span><br><span class="line">    Book book = WebUtils.copyParamToBean(req.getParameterMap(), <span class="keyword">new</span> Book());</span><br><span class="line">    <span class="comment">//2 调用BookService.addBook()保存图书</span></span><br><span class="line">    bookService.addBook(book);</span><br><span class="line">    <span class="comment">//3 跳到图书列表页面</span></span><br><span class="line">    resp.sendRedirect(req.getContextPath() + <span class="string">&quot;/manager/bookServlet?action=list&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="4"><li>修改<code>book_edit.jsp</code>页面<br><img src="https://img-blog.csdnimg.cn/826f8dd3e4b54e49a9bfc5e553ee0110.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改book_edit.jsp"><br>这里如果使用<code>post</code>方法提交会中文乱码，可以通过修改<code>post</code>的编码解决。</li></ol><hr><h2 id="删除图书功能的实现"><a href="#删除图书功能的实现" class="headerlink" title="删除图书功能的实现"></a>删除图书功能的实现</h2><ol><li>图解删除流程<br><img src="https://img-blog.csdnimg.cn/a14b94c36bf348dfb7699139c4935c59.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="删除流程"></li><li><code>BookServlet</code>中添加<code>delete</code>方法<br>删除功能需要 <code>id</code> 项，我们通过 <code>getParameter</code> 方法获得的 <code>id</code> 是字符串类型，需要将其转换为 <code>Integer</code> 型。所以我们给 <code>WebUtils</code> 工具类添加转换 <code>Interger</code> 类型。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 将字符串转换成为 int 类型的数据</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> strInt</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> defaultValue</span></span><br><span class="line"><span class="comment">* <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">parseInt</span><span class="params">(String strInt,<span class="keyword">int</span> defaultValue)</span> </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">return</span> Integer.parseInt(strInt);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> defaultValue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后在<code>BookServlet</code>中添加 <code>delete</code> 方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">delete</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException,</span></span><br><span class="line"><span class="function">IOException </span>&#123;</span><br><span class="line"><span class="comment">// 1、获取请求的参数 id，图书编程</span></span><br><span class="line"><span class="keyword">int</span> id = WebUtils.parseInt(req.getParameter(<span class="string">&quot;id&quot;</span>), <span class="number">0</span>);</span><br><span class="line"><span class="comment">// 2、调用 bookService.deleteBookById();删除图书</span></span><br><span class="line">bookService.deleteBookById(id);</span><br><span class="line"><span class="comment">// 3、重定向回图书列表管理页面</span></span><br><span class="line"><span class="comment">// /book/manager/bookServlet?action=list</span></span><br><span class="line">resp.sendRedirect(req.getContextPath() + <span class="string">&quot;/manager/bookServlet?action=list&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li><p>修改删除的连接地址<br><img src="https://img-blog.csdnimg.cn/eb54af33c7a24b1b83317eb11f712721.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改删除的连接地址"></p></li><li><p>给删除添加确认提示操作<br>删除属于危险项，所以我们需要添加确认操作，给删除的 <code>a</code> 标签绑定单击事件。</p></li></ol><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;script type=<span class="string">&quot;text/javascript&quot;</span>&gt;</span><br><span class="line">$( <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line"><span class="comment">// 给删除的a标签绑定单击事件，用于删除的确认提示操作</span></span><br><span class="line">$(<span class="string">&quot;a.deleteClass&quot;</span>).click(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line"><span class="comment">// 在事件的 function 函数中，有一个 this 对象。这个 this 对象，是当前正在响应事件的 dom 对象。</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * confirm 是确认提示框函数</span></span><br><span class="line"><span class="comment"> * 参数是它的提示内容</span></span><br><span class="line"><span class="comment"> * 它有两个按钮，一个确认，一个是取消。</span></span><br><span class="line"><span class="comment"> * 返回 true 表示点击了，确认，返回 false 表示点击取消。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">return</span> confirm(<span class="string">&quot;你确定要删除【&quot;</span> + $(<span class="built_in">this</span>).parent().parent().find(<span class="string">&quot;td:first&quot;</span>).text() + <span class="string">&quot;】?&quot;</span>);</span><br><span class="line"><span class="comment">// return false// 阻止元素的默认行为===不提交请求</span></span><br><span class="line">&#125;);</span><br><span class="line">&#125;);</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure><hr><h2 id="修改图书功能的实现"><a href="#修改图书功能的实现" class="headerlink" title="修改图书功能的实现"></a>修改图书功能的实现</h2><ol><li><p>图解修改图书细节<br><img src="https://img-blog.csdnimg.cn/577e296c79634466ab846f7662828c9a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改图书"></p></li><li><p>更新修改的请求地址<br><img src="https://img-blog.csdnimg.cn/204199d6089b489ab4dcee50b51b975f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="更新修改的请求地址"></p></li><li><p><code>BookServlet</code>程序中添加<code>getBook</code>方法</p></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">getBook</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException,</span></span><br><span class="line"><span class="function">IOException </span>&#123;</span><br><span class="line"><span class="comment">//1 获取请求的参数图书编号</span></span><br><span class="line"><span class="keyword">int</span> id = WebUtils.parseInt(req.getParameter(<span class="string">&quot;id&quot;</span>), <span class="number">0</span>);</span><br><span class="line"><span class="comment">//2 调用 bookService.queryBookById 查询图书</span></span><br><span class="line">Book book = bookService.queryBookById(id);</span><br><span class="line"><span class="comment">//3 保存到图书到 Request 域中</span></span><br><span class="line">req.setAttribute(<span class="string">&quot;book&quot;</span>, book) ;</span><br><span class="line"><span class="comment">//4 请求转发到。pages/manager/book_edit.jsp 页面</span></span><br><span class="line">req.getRequestDispatcher(<span class="string">&quot;/pages/manager/book_edit.jsp&quot;</span>).forward(req,resp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="4"><li>在<code>book_edit.jsp</code>页面中显示修改的数据<br><img src="https://img-blog.csdnimg.cn/5ff89df479644432b087677b0c785cdc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="显示修改的数据"></li><li>在 <code>BookServlet</code>程序中添加<code>update</code>方法</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">update</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException,</span></span><br><span class="line"><span class="function">IOException </span>&#123;</span><br><span class="line"><span class="comment">// 1、获取请求的参数==封装成为 Book 对象</span></span><br><span class="line">Book book = WebUtils.copyParamToBean(req.getParameterMap(),<span class="keyword">new</span> Book());</span><br><span class="line"><span class="comment">// 2、调用 BookService.updateBook( book );修改图书</span></span><br><span class="line">bookService.updateBook(book);</span><br><span class="line"><span class="comment">// 3、重定向回图书列表管理页面</span></span><br><span class="line"><span class="comment">// 地址：/工程名/manager/bookServlet?action=list</span></span><br><span class="line">resp.sendRedirect(req.getContextPath() + <span class="string">&quot;/manager/bookServlet?action=list&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="6"><li>解决 <code>book_edit.jsp</code> 页面，既要实现添加，又要实现修改操作。<br><img src="https://img-blog.csdnimg.cn/369e13b37816414ea6d96c566a15bcd2.png" alt="实现添加与修改"></li></ol>]]></content>
      
      
      <categories>
          
          <category> JavaWeb书城项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jsp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb书城项目(四)———代码优化</title>
      <link href="/2021/11/04/JavaWeb_BookProject_4/"/>
      <url>/2021/11/04/JavaWeb_BookProject_4/</url>
      
        <content type="html"><![CDATA[<blockquote><p>整个项目源代码可以到我的github上下载。前三部分我们已经完成了书城项目的登录与注册功能，第四部分我们对之前的代码进行优化。</p></blockquote><h1 id="合并Servlet"><a href="#合并Servlet" class="headerlink" title="合并Servlet"></a>合并Servlet</h1><p>在实际的开发中，一个模块，一般只使用一个 <code>Servlet</code> 程序，用户的注册与登录都属于用户模块，因此只需要一个 <code>Servlet</code> 程序即可，所以我们将 <code>LoginServlet</code> 与 <code>RegistSerlet</code> 程序合并为一个 <code>UserServlet</code> 程序。<br><strong>那么一个请求过来，如何知道他是注册还是登录呢？</strong></p><span id="more"></span><p>这时我们就要用到表单项的隐藏域来解决。<br><img src="https://img-blog.csdnimg.cn/00b66ca955184dfe971893d463e24dc4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="登录表单隐藏域"><br><img src="https://img-blog.csdnimg.cn/071e8889d53e403cbe01779153920bf7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="注册表单隐藏域"><br>这样，我们在用 <code>Servlet</code> 程序接收请求时，就能根据 <code>name</code> 的 <code>value</code> 项来判断其是注册还是登录。</p><hr><h1 id="反射优化"><a href="#反射优化" class="headerlink" title="反射优化"></a>反射优化</h1><p>用户模块不止有登录和注册功能，还会有注销，修改密码等其它功能，如果这时都放在一个 <code>Servlet</code> 里，那么代码必定有很多 <code>if...else...</code>，这样代码就会显得很冗杂。我们可以使用反射优化 <code>if...else...</code>。<br><img src="https://img-blog.csdnimg.cn/d763fd5ea8504513b8f8f12241725e60.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="反射优化"><br>这样两行代码就能代替繁琐的 <code>if...else,,,</code>。</p><hr><h1 id="抽取BaseServlet程序"><a href="#抽取BaseServlet程序" class="headerlink" title="抽取BaseServlet程序"></a>抽取BaseServlet程序</h1><p><img src="https://img-blog.csdnimg.cn/59dd6bafc4f84a9cbbfdeac8cb4b2e0e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="抽取BaseServlet"><br>因为我们不止一个模块，除了用户模块，还会有图书模块等，这样其反射优化都是一样的，那么我们可以抽取出父类 <code>BaseServlet</code> 程序，那么其它模块就可以继承这个模块，达到复用代码的目的。<br><code>BaseServlet</code>程序：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.web;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletException;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServlet;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Method;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">BaseServlet</span> <span class="keyword">extends</span> <span class="title">HttpServlet</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doPost</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">        String action = req.getParameter(<span class="string">&quot;action&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 获取action业务鉴别字符串，获得相应的业务 方法反射对象</span></span><br><span class="line">            Method method = <span class="keyword">this</span>.getClass().getDeclaredMethod(action, HttpServletRequest.class, HttpServletResponse.class);</span><br><span class="line">            <span class="comment">// 调用目标业务 方法</span></span><br><span class="line">            method.invoke(<span class="keyword">this</span>, req, resp);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="数据的封装和抽取BeanUtils的使用"><a href="#数据的封装和抽取BeanUtils的使用" class="headerlink" title="数据的封装和抽取BeanUtils的使用"></a>数据的封装和抽取BeanUtils的使用</h1><p>我们一般会将数据封装进<code>JavaBean</code>里，但如果通过调用 <code>Set</code> 方法会使代码很冗余，这时我们可以使用第三方工具类 <code>BeanUtils</code> ，它可以用于把 <code>Map</code> 中的值注入到 <code>JavaBean</code> 中。</p><ol><li>导入需要的 <code>jar</code> 包：<br> commons-beanutils-1.8.0.jar<br> commons-logging-1.1.1.jar</li><li>编写 <code>WebUtils</code> 工具类使用<br><code>WebUtils</code>工具类:</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.beanutils.BeanUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.InvocationTargetException;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WebUtils</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 把Map中的值注入到JavaBean中</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> bean</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> &lt;T&gt;</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function">T <span class="title">copyParamToBean</span><span class="params">(Map value , T bean )</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;注入之前：&quot;</span> + bean);</span><br><span class="line">            <span class="comment">/**</span></span><br><span class="line"><span class="comment">             * 把所有请求的参数都注入到bean对象中</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            BeanUtils.populate(bean, value);</span><br><span class="line">            System.out.println(<span class="string">&quot;注入之后：&quot;</span> + bean);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> bean;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="3"><li>在程序中加入如下代码即可调用方法将请求参数注入到<code>JavaBean</code>中<br><img src="https://img-blog.csdnimg.cn/2efa959e63324468a41ebbaffe4256fe.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="调用方法"></li></ol><hr><h1 id="使用EL表达式修改表单回显"><a href="#使用EL表达式修改表单回显" class="headerlink" title="使用EL表达式修改表单回显"></a>使用EL表达式修改表单回显</h1><p>我们可以使用<code>EL</code>表达式来修改表单回显，这样能使代码更简洁。<br><img src="https://img-blog.csdnimg.cn/85354810ee0f4b11965c4735b49e7ae6.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改login,jsp"><br><img src="https://img-blog.csdnimg.cn/12a629fb600a45619e8ad35c63da5057.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改regist.jsp"></p>]]></content>
      
      
      <categories>
          
          <category> JavaWeb书城项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jsp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb书城项目(三)———表单回显</title>
      <link href="/2021/11/04/JavaWeb_BookProject_3/"/>
      <url>/2021/11/04/JavaWeb_BookProject_3/</url>
      
        <content type="html"><![CDATA[<blockquote><p>整个项目源代码可以到我的github上下载。之前已经基本做好用户的注册和登录功能，但用户注册和登录还缺少错误信息的提示，比如用户名已存在会在页面显示用户名已存在。这次我们就来完成表单回显的功能。</p></blockquote><h1 id="修改所有-html为-jsp"><a href="#修改所有-html为-jsp" class="headerlink" title="修改所有.html为.jsp"></a>修改所有.html为.jsp</h1><p>只有把静态页面改为动态页面，才能完成表单回显的功能，因此第一步我们先将所有 <code>.html</code> 页面 改为 <code>.jsp</code> 页面。<br>将 <code>.html</code> 页面改为 <code>.jsp</code> 页面只需要如下两个步骤。</p><span id="more"></span><ol><li>在头部添加如下语句</li></ol><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;</span><br></pre></td></tr></table></figure><ol start="2"><li>将 <code>.html</code> 后缀改为 <code>.jsp</code> 后缀，<strong>比如，user目录下修改完为如下</strong><br><img src="https://img-blog.csdnimg.cn/985e54af93024573bcf8644783a734bd.png" alt="html改为jsp"></li></ol><hr><h1 id="抽取jsp公共内容"><a href="#抽取jsp公共内容" class="headerlink" title="抽取jsp公共内容"></a>抽取jsp公共内容</h1><p>我们可以将 <code>jsp</code> 页面中的公共内容提取出来，这样以后在维护或者修改的时候，如果需要对公共部分进行修改，那么只需要修改一份代码即可。<br>我们先在 <code>pages</code> 目录下创建 <code>common</code> 文件夹，用于存放公共部分代码</p><h2 id="登录成功菜单部分"><a href="#登录成功菜单部分" class="headerlink" title="登录成功菜单部分"></a>登录成功菜单部分</h2><p><img src="https://img-blog.csdnimg.cn/b864b27054494f8c937c57680c824cd2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="登录成功菜单"><br>我们在登录成功之后的页面，都会有如上图所示，位于页面右上角的菜单部分，我们可以将其提取出来，放入 <code>common</code> 文件夹下的 <code>login_success_menu.jsp</code> 中。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">span</span>&gt;</span>欢迎<span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;um_span&quot;</span>&gt;</span>韩总<span class="tag">&lt;/<span class="name">span</span>&gt;</span>光临尚硅谷书城<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;pages/order/order.jsp&quot;</span>&gt;</span>我的订单<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;index.jsp&quot;</span>&gt;</span>注销<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="symbol">&amp;nbsp;</span><span class="symbol">&amp;nbsp;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;index.jsp&quot;</span>&gt;</span>返回<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure><p>之后在公共位置改为如下代码</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;%-- 静态包含登录成功之后的菜单 --%&gt;</span><br><span class="line">&lt;%@ include file=&quot;/pages/common/login_success_menu.jsp&quot;%&gt;</span><br></pre></td></tr></table></figure><h2 id="头部信息"><a href="#头部信息" class="headerlink" title="头部信息"></a>头部信息</h2><p>我们会在 <code>jsp</code> 页面头部写 <code>base</code> 标签，导入样式及 <code>jQuery</code> 的包，因此也可以提取出如下公共部分放入<code>common</code>文件夹下<code>head.jsp</code>中。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">--%&gt;</span><br><span class="line">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;</span><br><span class="line">&lt;%</span><br><span class="line">  String basePath = request.getScheme()</span><br><span class="line">            + &quot;://&quot;</span><br><span class="line">            + request.getServerName()</span><br><span class="line">            + &quot;:&quot;</span><br><span class="line">            + request.getServerPort()</span><br><span class="line">            + request.getContextPath()</span><br><span class="line">            + &quot;/&quot;;</span><br><span class="line">%&gt;</span><br><span class="line"><span class="comment">&lt;!-- 写base标签，永远固定相对路径跳转的结果 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">base</span> <span class="attr">href</span>=<span class="string">&quot;&lt;%=basePath%&gt;&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">type</span>=<span class="string">&quot;text/css&quot;</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;static/css/style.css&quot;</span> &gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span> <span class="attr">src</span>=<span class="string">&quot;static/script/jquery-1.7.2.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>需要注意的是，我们自己每次试验都是通过 <code>localhost</code> 访问服务器的，但是正常情况下，是用户使用客户端访问服务器的 <code>ip</code>，并且服务器的 <code>ip</code> 是可能会动态变化的，所以我们写 <code>base</code> 标签的时候，必须动态获取服务器的 <code>ip</code> 地址。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;</span><br><span class="line">&lt;%</span><br><span class="line">  String basePath = request.getScheme() //协议名称</span><br><span class="line">            + &quot;://&quot;</span><br><span class="line">            + request.getServerName() //服务器ip</span><br><span class="line">            + &quot;:&quot;</span><br><span class="line">            + request.getServerPort() //服务器端口</span><br><span class="line">            + request.getContextPath() //工程路径</span><br><span class="line">            + &quot;/&quot;;</span><br><span class="line">%&gt;</span><br><span class="line"><span class="comment">&lt;!-- 写base标签，永远固定相对路径跳转的结果 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">base</span> <span class="attr">href</span>=<span class="string">&quot;&lt;%=basePath%&gt;&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">type</span>=<span class="string">&quot;text/css&quot;</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;static/css/style.css&quot;</span> &gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span> <span class="attr">src</span>=<span class="string">&quot;static/script/jquery-1.7.2.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>之后在公共位置改为如下代码</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;%-- 静态包含 base标签，css样式，jQuery文件 --%&gt;</span><br><span class="line">&lt;%@ include file=&quot;/pages/common/head.jsp&quot;%&gt;</span><br></pre></td></tr></table></figure><h2 id="脚部信息"><a href="#脚部信息" class="headerlink" title="脚部信息"></a>脚部信息</h2><p><img src="https://img-blog.csdnimg.cn/0d7de5fdef1f464eb2a45078efb8fa4c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="脚部信息"><br>我们在所有页面下面都会加上如上图所示的脚部信息，因此我们将其提取出来放入 <code>common</code> 文件夹下的 <code>footer.jsp</code> 中。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;bottom&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">span</span>&gt;</span></span><br><span class="line">尚硅谷书城.Copyright <span class="symbol">&amp;copy;</span>2015</span><br><span class="line"><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure><p>之后在公共位置改为如下代码</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;%-- include包含脚部信息 --%&gt;</span><br><span class="line">&lt;%@ include file=&quot;/pages/common/footer.jsp&quot;%&gt;</span><br></pre></td></tr></table></figure><h2 id="后台管理菜单"><a href="#后台管理菜单" class="headerlink" title="后台管理菜单"></a>后台管理菜单</h2><p><img src="https://img-blog.csdnimg.cn/b1cc6f7fb7c94369bdd693010b5054a1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="后台管理菜单"><br>后台管理页面都会有如上图所示的菜单项，我们也可以将其提取出来放入 <code>common</code> 文件夹下的 <code>manager_menu.jsp</code> 中。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;pages/manager/book_manager.jsp&quot;</span>&gt;</span>图书管理<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;pages/manager/order_manager.jsp&quot;</span>&gt;</span>订单管理<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;index.jsp&quot;</span>&gt;</span>返回商城<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure><p>之后在公共位置改为如下代码</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;%-- 静态包含manager管理模块的菜单 --%&gt;</span><br><span class="line">&lt;%@ include file=&quot;/pages/common/manager_menu.jsp&quot;%&gt;</span><br></pre></td></tr></table></figure><hr><h1 id="表单提交失败的错误回显"><a href="#表单提交失败的错误回显" class="headerlink" title="表单提交失败的错误回显"></a>表单提交失败的错误回显</h1><p>具体实现思路</p><ol><li>在 <code>Servlet</code> 程序中将错误回显信息放入 <code>request</code> 域中</li><li>在 <code>jsp</code> 页面中输出回显信息</li></ol><h2 id="修改Servlet程序"><a href="#修改Servlet程序" class="headerlink" title="修改Servlet程序"></a>修改Servlet程序</h2><p>修改 <code>LoginServlet</code> 和 <code>RegistServlet</code> 程序如下<br><img src="https://img-blog.csdnimg.cn/8bd3635c8df348f88334e4fb516658a8.png" alt="修改LoginServlet程序"><br><img src="https://img-blog.csdnimg.cn/f527b7d221a647b79e5223b0b2d1fb8c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改RegistServlet程序"></p><h2 id="修改jsp页面"><a href="#修改jsp页面" class="headerlink" title="修改jsp页面"></a>修改jsp页面</h2><p>修改 <code>login.jsp</code> 和 <code>regist.jsp</code> 如下<br><img src="https://img-blog.csdnimg.cn/b452722e253e4ca4b3f6d9c2fdec76f8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改login,jsp"><br><img src="https://img-blog.csdnimg.cn/ff684faf171041779f38868449815d48.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="修改regist,jsp"></p>]]></content>
      
      
      <categories>
          
          <category> JavaWeb书城项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jsp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode729. 我的日程安排表 I</title>
      <link href="/2021/11/02/Leetcode729/"/>
      <url>/2021/11/02/Leetcode729/</url>
      
        <content type="html"><![CDATA[<h1 id="题目链接"><a href="#题目链接" class="headerlink" title="题目链接"></a>题目链接</h1><p><a href="https://leetcode-cn.com/problems/my-calendar-i/">点我(^_^)</a></p><h1 id="题意"><a href="#题意" class="headerlink" title="题意"></a>题意</h1><p>题意就是不和之前日程重合就可以插入日程并返回true,否则返回false</p><h1 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h1><span id="more"></span><p>黑色代表已有日程，黄色代表待插入日程<br>下面代表合法的，即可插入<br><img src="https://img-blog.csdnimg.cn/2e88ec82d049446e9caa4f3b6b281092.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="合法情况"><br>再看看不能插入的情况<br><img src="https://img-blog.csdnimg.cn/3c03a4c4fadf40f1a1a4af1eda20bf2c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="不合法情况"><br>我们通过观察可以发现，所有不合法情况都是 <strong>已有日程的左端</strong> &lt; **待插入日程右端**，所以我们只要找已有日程中 **小于待插入日程右端** 最大的，看其右端是否 &gt; <strong>待插入日程左端</strong>，如果大于就不能插入，否则就能插入。<br>因此，我们可以维护一个有序序列，然后就可以通过二分找到 <strong>小于待插入日程右端</strong> 最大的位置。<br>分析一下时间复杂度，每次的二分操作是 O(logn)，插入操作是 O(n)，所以整体复杂度还是 O(n^2^)，看着和暴力法差不多，实际对于不能插入的情况，我们 O(logn) 就能判断，并且每次插入操作也不是恒定 O(n) 的，所以还是比暴力法好的。<br>对于平均复杂度 O(nlogn) 的算法，这里可以提供一种 权值线段树 的思路，这样每次就是恒定 O(logk) 的操作，k为日程的数字能取得大小。但是空间就不够了，可以通过动态开点解决。 </p><h1 id="具体代码"><a href="#具体代码" class="headerlink" title="具体代码"></a>具体代码</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; pii;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCalendar</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;pii&gt; vc;</span><br><span class="line">    <span class="built_in">MyCalendar</span>() &#123;</span><br><span class="line">        vc.<span class="built_in">clear</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">book</span><span class="params">(<span class="keyword">int</span> start, <span class="keyword">int</span> end)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(vc.<span class="built_in">empty</span>())</span><br><span class="line">        &#123;</span><br><span class="line">            vc.<span class="built_in">push_back</span>(<span class="built_in">make_pair</span>(start, end));</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>; </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> l=<span class="number">0</span>, r=vc.<span class="built_in">size</span>()<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">int</span> pos=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(l&lt;=r)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">int</span> mid = (l+r)&gt;&gt;<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span>(vc[mid].first &gt;= end)</span><br><span class="line">                r = mid - <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                l = mid + <span class="number">1</span>;</span><br><span class="line">                pos = mid;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(vc[pos].first &gt;= end)</span><br><span class="line">        &#123;</span><br><span class="line">            vc.<span class="built_in">emplace</span>(vc.<span class="built_in">begin</span>(), <span class="built_in">make_pair</span>(start, end));</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(vc[pos].second &gt; start)</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                vc.<span class="built_in">emplace</span>(vc.<span class="built_in">begin</span>()+pos+<span class="number">1</span>, <span class="built_in">make_pair</span>(start, end));</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 力扣刷题笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
            <tag> 二分 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb书城项目(二)——用户注册和登录</title>
      <link href="/2021/11/02/JavaWeb_BookProject_2/"/>
      <url>/2021/11/02/JavaWeb_BookProject_2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>整个项目源代码可以到我的github上下载。之前已经做好前端页面，现在要通过 servlet 程序以及 JDBC 具体实现用户注册和登录，</p></blockquote><h1 id="JavaEE项目的三层架构"><a href="#JavaEE项目的三层架构" class="headerlink" title="JavaEE项目的三层架构"></a>JavaEE项目的三层架构</h1><p><img src="https://img-blog.csdnimg.cn/12e5b581ea2044f3941ceaf8b40f2efc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="三层架构"><br>为什么要分层呢？通过一层完成所有事情不行吗？</p><span id="more"></span><p><strong>分层的目的是为了解耦。解耦就是为了降低代码的耦合度。方便项目后期的维护和升级。</strong><br>我们知道有些项目代码量是巨大的，如果放在一层后期维护和升级会很麻烦，如果分出不同的层，每层都有不同负责的人员，那么维护和升级会变得轻松很多。<br><strong>需求分析</strong><br>需求一：用户注册<br>1）访问注册页面<br>2）填写注册信息，提交给服务器<br>3）服务器应该保存用户<br>4）当用户已经存在—-提示用户注册 失败，用户名已存在<br>5）当用户不存在—–注册成功<br>需求二：用户登录<br>1）访问登陆页面<br>2）填写用户名密码后提交<br>3）服务器判断用户是否存在<br>4）如果登陆失败 —&gt;&gt;&gt;&gt; 返回用户名或者密码错误信息<br>5）如果登录成功 —&gt;&gt;&gt;&gt; 返回登陆成功 信息</p><p><strong>需要的接口和类</strong></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">web 层 com.atguigu.web/servlet/controller</span><br><span class="line">service 层 com.atguigu.service Service 接口包</span><br><span class="line">   com.atguigu.service.impl Service 接口实现类</span><br><span class="line">dao 持久层 com.atguigu.dao Dao 接口包</span><br><span class="line">  com.atguigu.dao.impl Dao 接口实现类</span><br><span class="line">实体 bean 对象 com.atguigu.pojo/entity/domain/bean JavaBean 类</span><br><span class="line">测试包 com.atguigu.test/junit</span><br><span class="line">工具类 com.atguigu.utils</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/2a435f23ee324373ab7ad8f7a9eeff6d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_17,color_FFFFFF,t_70,g_se,x_16" alt="搭建环境"><br>完成类编写后的目录结构如下<br><img src="https://img-blog.csdnimg.cn/566449c03690451e9fc0b7c56acfc6d0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_11,color_FFFFFF,t_70,g_se,x_16" alt="目录结构"></p><hr><h1 id="创建数据库和表"><a href="#创建数据库和表" class="headerlink" title="创建数据库和表"></a>创建数据库和表</h1><p>这里我使用的是 <code>MySql</code>  + <code>Navicat</code>，新建一个<code>book</code>数据库，并新建一个<code>t_user</code>表。<br><img src="https://img-blog.csdnimg.cn/057a45b6e8ad41a3828e48ee2ea66050.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="t_user表"><br>通过建立<code>Unique</code>类型索引，可以使该字段唯一。<br><img src="https://img-blog.csdnimg.cn/58c621cadfaf4b61a8b3fa38bcc4f5a3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="建立Unique索引"><br>插入一条数据<br><img src="https://img-blog.csdnimg.cn/e14597815e174c709be2b985857447e0.png" alt="插入数据"></p><p>当然也可以直接使用如下 <code>Sql</code> 语句创建</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> database if <span class="keyword">exists</span> book;</span><br><span class="line"><span class="keyword">create</span> database book;</span><br><span class="line">use book;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_user(</span><br><span class="line">id <span class="type">int</span> <span class="keyword">primary</span> key auto_increment,</span><br><span class="line">username <span class="type">varchar</span>(<span class="number">20</span>) <span class="keyword">not</span> <span class="keyword">null</span> <span class="keyword">unique</span>,</span><br><span class="line">password <span class="type">varchar</span>(<span class="number">32</span>) <span class="keyword">not</span> <span class="keyword">null</span>,</span><br><span class="line">email <span class="type">varchar</span>(<span class="number">200</span>)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_user(username,password,email) <span class="keyword">values</span>(<span class="string">&#x27;admin&#x27;</span>,<span class="string">&#x27;admin&#x27;</span>,<span class="string">&#x27;admin@atguigu.com&#x27;</span>);</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_user;</span><br></pre></td></tr></table></figure><hr><h1 id="编写数据库对应的JavaBean对象"><a href="#编写数据库对应的JavaBean对象" class="headerlink" title="编写数据库对应的JavaBean对象"></a>编写数据库对应的JavaBean对象</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.pojo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Integer id;</span><br><span class="line">    <span class="keyword">private</span> String username;</span><br><span class="line">    <span class="keyword">private</span> String password;</span><br><span class="line">    <span class="keyword">private</span> String email;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Integer <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setId</span><span class="params">(Integer id)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getUsername</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> username;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUsername</span><span class="params">(String username)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.username = username;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getPassword</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> password;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPassword</span><span class="params">(String password)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.password = password;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getEmail</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> email;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setEmail</span><span class="params">(String email)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.email = email;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;User&#123;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;id=&quot;</span> + id +</span><br><span class="line">                <span class="string">&quot;, username=&#x27;&quot;</span> + username + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, password=&#x27;&quot;</span> + password + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, email=&#x27;&quot;</span> + email + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">User</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">User</span><span class="params">(Integer id, String username, String password, String email)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">        <span class="keyword">this</span>.username = username;</span><br><span class="line">        <span class="keyword">this</span>.password = password;</span><br><span class="line">        <span class="keyword">this</span>.email = email;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h1 id="编写工具类JdbcUtils"><a href="#编写工具类JdbcUtils" class="headerlink" title="编写工具类JdbcUtils"></a>编写工具类JdbcUtils</h1><p><code>JdbcUtils</code>工具类主要用来<strong>建立数据库连接</strong>与<strong>释放数据库连接</strong></p><h2 id="导入jar包"><a href="#导入jar包" class="headerlink" title="导入jar包"></a>导入jar包</h2><p>数据库和连接池需要如下<code>jar</code>包</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">druid-<span class="number">1.1</span><span class="number">.9</span>.jar</span><br><span class="line">mysql-connector-java-<span class="number">5.1</span><span class="number">.7</span>-bin.jar</span><br></pre></td></tr></table></figure><p>以下是测试需要：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hamcrest-core-<span class="number">1.3</span>.jar</span><br><span class="line">junit-<span class="number">4.12</span>.jar</span><br></pre></td></tr></table></figure><h2 id="编写jdbc-properties配置文件"><a href="#编写jdbc-properties配置文件" class="headerlink" title="编写jdbc.properties配置文件"></a>编写jdbc.properties配置文件</h2><p>放在<code>src</code>文件夹下<br><img src="https://img-blog.csdnimg.cn/450cea2bedef4a979d0080d26dc68592.png" alt="放入src文件夹下"><br>内容根据自己情况修改<br><code>username</code> 改为你的用户名<br><code>password</code> 改为你的密码<br><code>initialSize</code> 为初始连接池大小<br><code>maxActive</code> 为最大可用连接数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">username=root</span><br><span class="line">password=<span class="number">123456</span></span><br><span class="line">url=jdbc:mysql:<span class="comment">//localhost:3306/book?useUnicode=true&amp;characterEncoding=utf8</span></span><br><span class="line">driverClassName=com.mysql.jdbc.Driver</span><br><span class="line">initialSize=<span class="number">5</span></span><br><span class="line">maxActive=<span class="number">10</span></span><br></pre></td></tr></table></figure><h2 id="编写JdbcUtils工具类"><a href="#编写JdbcUtils工具类" class="headerlink" title="编写JdbcUtils工具类"></a>编写JdbcUtils工具类</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.druid.pool.DruidDataSource;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.druid.pool.DruidDataSourceFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"><span class="keyword">import</span> java.sql.SQLException;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JdbcUtils</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> DruidDataSource dataSource;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">            <span class="comment">// 读取jdbc.properties文件</span></span><br><span class="line">            InputStream inputStream = JdbcUtils.class.getClassLoader().getResourceAsStream(<span class="string">&quot;jdbc.properties&quot;</span>);</span><br><span class="line">            <span class="comment">// 从流中加载数据</span></span><br><span class="line">            properties.load(inputStream);</span><br><span class="line">            <span class="comment">// 创建数据库连接池</span></span><br><span class="line">            dataSource = (DruidDataSource) DruidDataSourceFactory.createDataSource(properties);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e)</span><br><span class="line">        &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取数据库连接池中的连接</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 如果返回null，说明获取连接失败 &lt;br/&gt;有值就是成功</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Connection <span class="title">getConnection</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        Connection conn = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            conn = dataSource.getConnection();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> conn;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 关闭连接，放回数据库连接池</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> conn</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">(Connection conn)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(conn != <span class="keyword">null</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                conn.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="JdbcUtils测试"><a href="#JdbcUtils测试" class="headerlink" title="JdbcUtils测试"></a>JdbcUtils测试</h2><p>我们在<code>test</code>包下创建<code>JdbcUtilsTest</code>测试类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.utils.JdbcUtils;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JdbcUtilsTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testJdbcUtils</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">100</span>; ++i)</span><br><span class="line">        &#123;</span><br><span class="line">            Connection con = JdbcUtils.getConnection();</span><br><span class="line">            System.out.println(con);</span><br><span class="line">            JdbcUtils.close(con);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/24b52549d221458fa0eaa0e212661984.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="测试结果"></p><hr><h1 id="编写BaseDao"><a href="#编写BaseDao" class="headerlink" title="编写BaseDao"></a>编写BaseDao</h1><p><code>BaseDao</code>类用来封装数据库的更新，查询操作(包括查询一行，查询多行，查询一个值)</p><h2 id="导入-DBUtils-的jar包"><a href="#导入-DBUtils-的jar包" class="headerlink" title="导入 DBUtils 的jar包"></a>导入 DBUtils 的jar包</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">commons-dbutils-<span class="number">1.3</span>.jar</span><br></pre></td></tr></table></figure><h2 id="编写-BaseDao"><a href="#编写-BaseDao" class="headerlink" title="编写 BaseDao"></a>编写 BaseDao</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.dao.impl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.utils.JdbcUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.dbutils.QueryRunner;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.dbutils.handlers.BeanHandler;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.dbutils.handlers.BeanListHandler;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.dbutils.handlers.ScalarHandler;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"><span class="keyword">import</span> java.sql.SQLException;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">BaseDao</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用DbUtils操作数据库</span></span><br><span class="line">    <span class="keyword">private</span> QueryRunner queryRunner = <span class="keyword">new</span> QueryRunner();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * update() 方法用来执行：Insert\Update\Delete语句</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 如果返回-1说明执行失败&lt;br/&gt;返回其它表示影响的行数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">update</span><span class="params">(String sql, Object ... args)</span></span>&#123;</span><br><span class="line">        Connection connection = JdbcUtils.getConnection();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span>  queryRunner.update(connection, sql, args);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (SQLException throwables) &#123;</span><br><span class="line">            throwables.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            JdbcUtils.close(connection);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询返回一个javaBean的sql语句</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> type 返回的对象类型</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sql 执行的sql语句</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args sql对应的参数值</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> &lt;T&gt; 返回的类型的泛型</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; <span class="function">T <span class="title">queryForOne</span><span class="params">(Class&lt;T&gt; type, String sql, Object ... args)</span></span>&#123;</span><br><span class="line">        Connection con = JdbcUtils.getConnection();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> queryRunner.query(con, sql, <span class="keyword">new</span> BeanHandler&lt;T&gt;(type), args);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (SQLException throwables) &#123;</span><br><span class="line">            throwables.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            JdbcUtils.close(con);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询返回多个javaBean的sql语句</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> type 返回的对象类型</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sql 执行的sql语句</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args sql对应的参数值</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> &lt;T&gt; 返回的类型的泛型</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; <span class="function">List&lt;T&gt; <span class="title">queryForList</span><span class="params">(Class&lt;T&gt; type, String sql, Object ... args)</span></span>&#123;</span><br><span class="line">        Connection con = JdbcUtils.getConnection();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> queryRunner.query(con, sql, <span class="keyword">new</span> BeanListHandler&lt;T&gt;(type), args);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (SQLException throwables) &#123;</span><br><span class="line">            throwables.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            JdbcUtils.close(con);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 执行返回一行一列的sql语句</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sql 执行的sql语句</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args sql对应的参数值</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">queryForSingleValue</span><span class="params">(String sql, Object ... args)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        Connection conn = JdbcUtils.getConnection();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>  &#123;</span><br><span class="line">            <span class="keyword">return</span> queryRunner.query(conn, sql, <span class="keyword">new</span> ScalarHandler(), args);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            JdbcUtils.close(conn);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h1 id="编写UserDao和测试"><a href="#编写UserDao和测试" class="headerlink" title="编写UserDao和测试"></a>编写UserDao和测试</h1><p><code>UserDao</code>也是属于<code>Dao</code>层，相比于<code>BaseDao</code>更加抽象，用来通过<strong>用户名查询是否有这个用户，用户名和密码查询，保存用户信息</strong></p><h2 id="UserDao接口"><a href="#UserDao接口" class="headerlink" title="UserDao接口"></a>UserDao接口</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.dao;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.User;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UserDao</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 根据用户名查询用户信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> username 用户名</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 如果返回null,说明没有这个用户,反之亦然</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">queryUserByUsername</span><span class="params">(String username)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 根据用户名和密码查询用户信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> username 用户名</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> password 密码</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 如果返回null, 说明用户名或密码错误, 反之亦然</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">queryUserByUsernameAndPassword</span><span class="params">(String username, String password)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 保存用户信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> user 用户信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> -1表示错误，其它表示影响的行数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">saveUser</span><span class="params">(User user)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="UserDaoImpl实现类"><a href="#UserDaoImpl实现类" class="headerlink" title="UserDaoImpl实现类"></a>UserDaoImpl实现类</h2><p><code>UserDaoImpl</code>实现类继承<code>BaseDao</code>并实现<code>UserDao</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.dao.impl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.dao.UserDao;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.User;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span>   <span class="title">UserDaoImpl</span> <span class="keyword">extends</span> <span class="title">BaseDao</span> <span class="keyword">implements</span> <span class="title">UserDao</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">queryUserByUsername</span><span class="params">(String username)</span> </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;select id,username,password,email from t_user where username = ?&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> queryForOne(User.class, sql, username);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">queryUserByUsernameAndPassword</span><span class="params">(String username, String password)</span> </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;select id,username,password,email from t_user where username = ? and password = ?&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> queryForOne(User.class, sql, username, password);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">saveUser</span><span class="params">(User user)</span> </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;insert into t_user(username,password,email) values(?,?,?)&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> update(sql, user.getUsername(), user.getPassword(), user.getEmail());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="UserDao测试"><a href="#UserDao测试" class="headerlink" title="UserDao测试"></a>UserDao测试</h2><p>在<code>test</code>下创建<code>UserDaoTest</code>测试类 </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.dao.UserDao;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.dao.impl.UserDaoImpl;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.User;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.junit.Assert.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserDaoTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    UserDao userDao = <span class="keyword">new</span> UserDaoImpl();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">queryUserByUsername</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( userDao.queryUserByUsername(<span class="string">&quot;admin1234&quot;</span>) == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;用户名可用！&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span>&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;用户名已存在！&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">queryUserByUsernameAndPassword</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( userDao.queryUserByUsernameAndPassword(<span class="string">&quot;admin&quot;</span>, <span class="string">&quot;admin1234&quot;</span>) == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;用户名或密码错误，登录失败！&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span>&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;登录成功！&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">saveUser</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println( userDao.saveUser(<span class="keyword">new</span> User(<span class="keyword">null</span>, <span class="string">&quot;wzg169&quot;</span>, <span class="string">&quot;123456&quot;</span>, <span class="string">&quot;wzg169 @qq.com&quot;</span>)));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="编写-UserService-和-测试"><a href="#编写-UserService-和-测试" class="headerlink" title="编写 UserService 和 测试"></a>编写 UserService 和 测试</h1><p><code>UserService</code>更加抽象化，具体完成注册，登录，查询用户名是否存在操作，为<code>Servlet</code>程序提供服务。</p><h2 id="UserService接口"><a href="#UserService接口" class="headerlink" title="UserService接口"></a>UserService接口</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.User;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UserService</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 注册用户</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> user</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">registUser</span><span class="params">(User user)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 登录</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> user</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 返回null是登录失败，返回有值是登录成功</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">login</span><span class="params">(User user)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 检查 用户名是否可用</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> username</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 返回 true 表示用户名已存在，返回 false 表示用户名可用</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">existsUsername</span><span class="params">(String username)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="UserServiceImpl实现类"><a href="#UserServiceImpl实现类" class="headerlink" title="UserServiceImpl实现类"></a>UserServiceImpl实现类</h2><p><code>UserServiceImpl</code>实现<code>UseService</code>，底层实际是调用<code>UserDao</code>来进行操作</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.service.impl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.dao.UserDao;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.dao.impl.UserDaoImpl;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.User;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.service.UserService;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserServiceImpl</span> <span class="keyword">implements</span> <span class="title">UserService</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> UserDao userDao = <span class="keyword">new</span> UserDaoImpl();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">registUser</span><span class="params">(User user)</span> </span>&#123;</span><br><span class="line">        userDao.saveUser(user);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">login</span><span class="params">(User user)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> userDao.queryUserByUsernameAndPassword(user.getUsername(), user.getPassword());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">existsUsername</span><span class="params">(String username)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (userDao.queryUserByUsername(username) == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="UserService测试"><a href="#UserService测试" class="headerlink" title="UserService测试"></a>UserService测试</h2><p>在<code>test</code>下创建<code>UserServiceTest</code>测试类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.User;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.service.UserService;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.service.impl.UserServiceImpl;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.junit.Assert.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserServiceTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    UserService userService = <span class="keyword">new</span> UserServiceImpl();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">registUser</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        userService.registUser(<span class="keyword">new</span> User(<span class="keyword">null</span>, <span class="string">&quot;bbj168&quot;</span>, <span class="string">&quot;666666&quot;</span>, <span class="string">&quot;bbj168@qq.com&quot;</span>));</span><br><span class="line">        userService.registUser(<span class="keyword">new</span> User(<span class="keyword">null</span>, <span class="string">&quot;abc168&quot;</span>, <span class="string">&quot;666666&quot;</span>, <span class="string">&quot;abc 168@qq.com&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">login</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println( userService.login(<span class="keyword">new</span> User(<span class="keyword">null</span>, <span class="string">&quot;wzg168&quot;</span>, <span class="string">&quot;123456&quot;</span>, <span class="keyword">null</span>)));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">existsUsername</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (userService.existsUsername(<span class="string">&quot;wzg1688&quot;</span>))&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;用户名已存在！&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span>&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;用户名可用！&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="编写Web层"><a href="#编写Web层" class="headerlink" title="编写Web层"></a>编写Web层</h1><h2 id="实现用户注册的功能"><a href="#实现用户注册的功能" class="headerlink" title="实现用户注册的功能"></a>实现用户注册的功能</h2><h3 id="图解用户注册"><a href="#图解用户注册" class="headerlink" title="图解用户注册"></a>图解用户注册<img src="https://img-blog.csdnimg.cn/852bc4857b4b487e94df876dae14c336.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="用户注册流程"></h3><h3 id="修改-regist-html-和-regist-success-html-页面"><a href="#修改-regist-html-和-regist-success-html-页面" class="headerlink" title="修改 regist.html 和 regist_success.html 页面"></a>修改 regist.html 和 regist_success.html 页面</h3><ol><li><p>添加<code>base</code>标签<br> 通过写<code>base</code>标签我们可用固定相对路径跳转的结果，这样可以让我们在写相对路径时更清晰，一般推荐这么做。<br><img src="https://img-blog.csdnimg.cn/616faae133a24974934e68840a83e54f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="base标签"></p></li><li><p>修改<code>base</code>标签对相对路径的影响<br>我们在添加完<code>base</code>标签之后需要对已有的相对路径进行修改，我们可以先重新部署服务器，之后看哪些资源失败了，来看需要修改哪个的相对路径。</p></li><li><p>修改注册表单的提交地址和请求方式<br><img src="https://img-blog.csdnimg.cn/290c0a8c9db94741b71660e89af07248.png" alt="修改注册表单"></p><h3 id="编写RegistServlet程序"><a href="#编写RegistServlet程序" class="headerlink" title="编写RegistServlet程序"></a>编写RegistServlet程序</h3></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.web;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.User;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.service.UserService;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.service.impl.UserServiceImpl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletException;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServlet;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RegistServlet</span> <span class="keyword">extends</span> <span class="title">HttpServlet</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> UserService userService = <span class="keyword">new</span> UserServiceImpl();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doPost</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException</span>&#123;</span><br><span class="line">        <span class="comment">// 1. 获取请求的参数</span></span><br><span class="line">        String username = req.getParameter(<span class="string">&quot;username&quot;</span>);</span><br><span class="line">        String password = req.getParameter(<span class="string">&quot;password&quot;</span>);</span><br><span class="line">        String email = req.getParameter(<span class="string">&quot;email&quot;</span>);</span><br><span class="line">        String code = req.getParameter(<span class="string">&quot;code&quot;</span>);</span><br><span class="line"><span class="comment">//        System.out.println(code);</span></span><br><span class="line">        <span class="comment">// 2. 验证验证码是否正确 === 写死，要求验证码为:abcde</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="string">&quot;abcde&quot;</span>.equalsIgnoreCase(code))&#123;</span><br><span class="line">            <span class="comment">// 正确</span></span><br><span class="line">            <span class="comment">// 3. 检查用户名是否可用</span></span><br><span class="line">            <span class="keyword">if</span> (userService.existsUsername(username))&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;用户名[&quot;</span> + username + <span class="string">&quot;]已存在！&quot;</span>);</span><br><span class="line">                <span class="comment">// 跳回注册页面</span></span><br><span class="line">                req.getRequestDispatcher(<span class="string">&quot;/pages/user/regist.html&quot;</span>).forward(req, resp);</span><br><span class="line">            &#125; <span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="comment">// 可用，调用Service保存到数据库</span></span><br><span class="line">                userService.registUser(<span class="keyword">new</span> User(<span class="keyword">null</span>, username, password, email));</span><br><span class="line">                <span class="comment">// 跳到注册成功页面</span></span><br><span class="line">                req.getRequestDispatcher(<span class="string">&quot;/pages/user/regist_success.html&quot;</span>).forward(req, resp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span>&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;验证码[&quot;</span> + code + <span class="string">&quot;]错误&quot;</span>);</span><br><span class="line">            req.getRequestDispatcher(<span class="string">&quot;/pages/user/regist.html&quot;</span>).forward(req, resp);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="配置Servlet映射"><a href="#配置Servlet映射" class="headerlink" title="配置Servlet映射"></a>配置Servlet映射</h3><p>在<code>web.xml</code>中添加如下语句</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">servlet</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>RegistServlet<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-class</span>&gt;</span>com.atguigu.web.RegistServlet<span class="tag">&lt;/<span class="name">servlet-class</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">servlet</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">servlet-mapping</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>RegistServlet<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/registServlet<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">servlet-mapping</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="实现用户登录的功能"><a href="#实现用户登录的功能" class="headerlink" title="实现用户登录的功能"></a>实现用户登录的功能</h2><h3 id="图解用户登录"><a href="#图解用户登录" class="headerlink" title="图解用户登录"></a>图解用户登录</h3><p><img src="https://img-blog.csdnimg.cn/05ddba7580b04f148b52e8ac76474d2e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="用户登录的流程"></p><h3 id="修改-login-html-页面和-login-success-html-页面"><a href="#修改-login-html-页面和-login-success-html-页面" class="headerlink" title="修改 login.html 页面和 login_success.html 页面"></a>修改 login.html 页面和 login_success.html 页面</h3><ol><li>添加<code>base</code>标签</li><li> 修改<code>base</code>标签对相对路径的影响</li><li>修改注册表单的提交地址和请求方式<br><img src="https://img-blog.csdnimg.cn/0644fcbf87af44e384c37d5c9a3ed36c.png" alt="修改登录表单"><h3 id="编写-LoginServlet-程序"><a href="#编写-LoginServlet-程序" class="headerlink" title="编写 LoginServlet 程序"></a>编写 LoginServlet 程序</h3></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.web;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.atguigu.pojo.User;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.service.UserService;</span><br><span class="line"><span class="keyword">import</span> com.atguigu.service.impl.UserServiceImpl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletException;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServlet;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginServlet</span> <span class="keyword">extends</span> <span class="title">HttpServlet</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> UserService userService = <span class="keyword">new</span> UserServiceImpl();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doPost</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 获取请求的参数</span></span><br><span class="line">        String username = req.getParameter(<span class="string">&quot;username&quot;</span>);</span><br><span class="line">        String password = req.getParameter(<span class="string">&quot;password&quot;</span>);</span><br><span class="line">        <span class="comment">// 2. userService.login()登录处理业务</span></span><br><span class="line">        User loginUser = userService.login(<span class="keyword">new</span> User( <span class="keyword">null</span>, username, password, <span class="keyword">null</span>));</span><br><span class="line">        <span class="comment">// 如果等于null，说明登录失败！</span></span><br><span class="line">        <span class="keyword">if</span> (loginUser == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 跳回登录页面</span></span><br><span class="line">            req.getRequestDispatcher(<span class="string">&quot;/pages/user/login.html&quot;</span>).forward(req, resp);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 登录 成功</span></span><br><span class="line">            <span class="comment">// 跳到成功页面login_success.html</span></span><br><span class="line">            req.getRequestDispatcher(<span class="string">&quot;/pages/user/login_success.html&quot;</span>).forward(req, resp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="配置Servlet映射-1"><a href="#配置Servlet映射-1" class="headerlink" title="配置Servlet映射"></a>配置Servlet映射</h3><p>在<code>web.xml</code>中添加如下语句</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">servlet</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>LoginServlet<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-class</span>&gt;</span>com.atguigu.web.LoginServlet<span class="tag">&lt;/<span class="name">servlet-class</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">servlet</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">servlet-mapping</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>LoginServlet<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/loginServlet<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">servlet-mapping</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> JavaWeb书城项目 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb书城项目(一)——表单验证的实现</title>
      <link href="/2021/10/30/JavaWeb_BookProject_1/"/>
      <url>/2021/10/30/JavaWeb_BookProject_1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>整个项目源代码可以到我的github上下载。表单验证主要使用JQuery实现，IDE为IDEA。</p></blockquote><h1 id="导入项目"><a href="#导入项目" class="headerlink" title="导入项目"></a>导入项目</h1><p>新建一个模块<br><img src="https://img-blog.csdnimg.cn/087aef774e5f4e41aa97d612a5fa27a1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="新建模块"></p><span id="more"></span><p>把原有的文件导入，<a href="https://pan.baidu.com/share/init?surl=VhoiXQTMKeTCaNK6JTba4g">原有文件链接 提取码:nefu</a><br><img src="https://img-blog.csdnimg.cn/ccc1a7437bf7425f81461ec663e56400.png" alt="导入文件"><br>接下来我们要修改login.html以及regist.html<br><img src="https://img-blog.csdnimg.cn/943f53229aa646aea9d34d53e5087ab1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_12,color_FFFFFF,t_70,g_se,x_16" alt="login与regist"><br>把 <code>jquery.js</code> 放入<code>static/script</code> 文件夹下<br><img src="https://img-blog.csdnimg.cn/3352236662a749e1a5c3e7b853876238.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_11,color_FFFFFF,t_70,g_se,x_16" alt="导入jquery.js"></p><hr><h1 id="regist部分"><a href="#regist部分" class="headerlink" title="regist部分"></a>regist部分</h1><p>我们要验证表单内容，主要有以下几个部分<br><img src="https://img-blog.csdnimg.cn/2cbfdfb17a364d1a8961f0dac2c21718.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_17,color_FFFFFF,t_70,g_se,x_16" alt="注册表单"></p><ul><li>验证用户名：必须由字母，数字下划线组成，并且长度为5到12位</li><li>验证密码：必须由字母，数字下划线组成，并且长度为5到12位</li><li>验证确认密码：和密码相同</li><li>邮箱验证；<a href="mailto:&#x78;&#x78;&#x78;&#120;&#x78;&#64;&#120;&#x78;&#120;&#46;&#x63;&#111;&#x6d;">&#x78;&#x78;&#x78;&#120;&#x78;&#64;&#120;&#x78;&#120;&#46;&#x63;&#111;&#x6d;</a></li><li>验证码：现在只需要验证用户已输入</li></ul><p>具体大致流程如下：</p><ol><li><code>$(#id).val()</code> 获得表单项的值</li><li> <code>/ /</code> 创建正则项表达式</li><li>使用 <code>test</code> 方法测试</li><li><code>$(&quot;span.errorMsg&quot;).text(&quot;提示信息&quot;)</code> 提示用户</li></ol><p>以用户名为例，具体代码如下</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 验证用户名：必须由字母，数字下划线组成，并且长度为5到12位</span></span><br><span class="line"><span class="comment">//1 获取用户名输入框里的内容</span></span><br><span class="line"><span class="keyword">var</span> usernameText = $(<span class="string">&#x27;#username&#x27;</span>).val();</span><br><span class="line"><span class="comment">//2 创建正则表达式对象</span></span><br><span class="line"><span class="keyword">var</span> usernamePatt = <span class="regexp">/^\w&#123;5,12&#125;$/</span>;</span><br><span class="line"><span class="comment">//3 使用test方法验证</span></span><br><span class="line"><span class="keyword">if</span>(!usernamePatt.test(usernameText)) &#123;</span><br><span class="line"><span class="comment">//4 提示用户结果</span></span><br><span class="line">$(<span class="string">&quot;span.errorMsg&quot;</span>).text(<span class="string">&quot;用户名不合法！&quot;</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// 让其不跳转</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>需要注意的是，全部验证完之后，不应该出现错误信息，所以使用 <code>$(&quot;span.errorMsg&quot;).text(&quot;&quot;)</code> 将其清空。<br><strong>regist.html 全部代码如下</strong></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>尚硅谷会员注册页面<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">type</span>=<span class="string">&quot;text/css&quot;</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;../../static/css/style.css&quot;</span> &gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span> <span class="attr">src</span>=<span class="string">&quot;../../static/script/jquery-1.7.2.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript"><span class="comment">// 页面加载完成之后</span></span></span><br><span class="line"><span class="javascript">$(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">$(<span class="string">&quot;#sub_btn&quot;</span>).click(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript"></span></span><br><span class="line"><span class="javascript"><span class="comment">// 验证用户名：必须由字母，数字下划线组成，并且长度为5到12位</span></span></span><br><span class="line"><span class="javascript"><span class="comment">//1 获取用户名输入框里的内容</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> usernameText = $(<span class="string">&#x27;#username&#x27;</span>).val();</span></span><br><span class="line"><span class="javascript"><span class="comment">//2 创建正则表达式对象</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> usernamePatt = <span class="regexp">/^\w&#123;5,12&#125;$/</span>;</span></span><br><span class="line"><span class="javascript"><span class="comment">//3 使用test方法验证</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">if</span>(!usernamePatt.test(usernameText)) &#123;</span></span><br><span class="line"><span class="javascript"><span class="comment">//4 提示用户结果</span></span></span><br><span class="line"><span class="javascript">$(<span class="string">&quot;span.errorMsg&quot;</span>).text(<span class="string">&quot;用户名不合法！&quot;</span>);</span></span><br><span class="line"><span class="javascript"><span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// 让其不跳转</span></span></span><br><span class="line"><span class="javascript">&#125;</span></span><br><span class="line"><span class="javascript"></span></span><br><span class="line"><span class="javascript"><span class="comment">// 验证密码：必须由字母，数字下划线组成，并且长度为5到12位</span></span></span><br><span class="line"><span class="javascript"><span class="comment">//1 获取密码输入框里的内容</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> passwordText = $(<span class="string">&#x27;#password&#x27;</span>).val();</span></span><br><span class="line"><span class="javascript"><span class="comment">//2 创建正则表达式对象</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> passwordPatt = <span class="regexp">/^\w&#123;5,12&#125;$/</span>;</span></span><br><span class="line"><span class="javascript"><span class="comment">//3 使用test方法验证</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">if</span>(!passwordPatt.test(passwordText)) &#123;</span></span><br><span class="line"><span class="javascript"><span class="comment">//4 提示用户结果</span></span></span><br><span class="line"><span class="javascript">$(<span class="string">&quot;span.errorMsg&quot;</span>).text(<span class="string">&quot;密码不合法！&quot;</span>);</span></span><br><span class="line"><span class="javascript"><span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// 让其不跳转</span></span></span><br><span class="line"><span class="javascript">&#125;</span></span><br><span class="line"><span class="javascript"></span></span><br><span class="line"><span class="javascript"><span class="comment">// 验证确认密码：和密码相同</span></span></span><br><span class="line"><span class="javascript"><span class="comment">//1 获取确认密码内容</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> repwdText = $(<span class="string">&quot;#repwd&quot;</span>).val();</span></span><br><span class="line"><span class="javascript"><span class="comment">//2 与密码相比较</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">if</span>(repwdText != passwordText)&#123;</span></span><br><span class="line"><span class="javascript"><span class="comment">//3 提示用户</span></span></span><br><span class="line"><span class="javascript">$(<span class="string">&quot;span.errorMsg&quot;</span>).text(<span class="string">&quot;确认密码和密码不一致！&quot;</span>);</span></span><br><span class="line"><span class="javascript"><span class="keyword">return</span> <span class="literal">false</span>;</span></span><br><span class="line"><span class="javascript">&#125;</span></span><br><span class="line"><span class="javascript"></span></span><br><span class="line"><span class="javascript"></span></span><br><span class="line"><span class="javascript"></span></span><br><span class="line"><span class="javascript"><span class="comment">// 邮箱验证；xxxxx@xxx.com</span></span></span><br><span class="line"><span class="javascript"><span class="comment">//1 获取邮箱里的内容</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> emailText = $(<span class="string">&quot;#email&quot;</span>).val();</span></span><br><span class="line"><span class="javascript"><span class="comment">//2 创建正则表达式对象</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> emailPatt = <span class="regexp">/^[a-z\d]+(\.[a-z\d]+)*@([\da-z](-[\da-z])?)+(\.&#123;1,2&#125;[a-z]+)+$/</span></span></span><br><span class="line"><span class="javascript"><span class="comment">//3 使用test方法测试</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">if</span>(!emailPatt.test(emailText)) &#123;</span></span><br><span class="line"><span class="javascript"><span class="comment">//4 提示用户</span></span></span><br><span class="line"><span class="javascript">$(<span class="string">&quot;span.errorMsg&quot;</span>).text(<span class="string">&quot;邮箱不合法！&quot;</span>);</span></span><br><span class="line"><span class="javascript"><span class="keyword">return</span> <span class="literal">false</span>;</span></span><br><span class="line"><span class="javascript">&#125;</span></span><br><span class="line"><span class="javascript"></span></span><br><span class="line"><span class="javascript"><span class="comment">// 验证码：现在只需要验证用户已输入，因为还没讲到服务器，验证码生成。</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> codeText = $(<span class="string">&quot;#code&quot;</span>).val();</span></span><br><span class="line"><span class="javascript"><span class="comment">// alert(&quot;去空格前&quot;+codeText);</span></span></span><br><span class="line"><span class="javascript">codeText = $.trim(codeText); <span class="comment">// 去除多余的空格</span></span></span><br><span class="line"><span class="javascript"><span class="comment">// alert(&quot;去空格后&quot;+codeText);</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">if</span> (codeText == <span class="literal">null</span> || codeText == <span class="string">&quot;&quot;</span>)&#123;</span></span><br><span class="line"><span class="javascript"><span class="comment">// 提示用户</span></span></span><br><span class="line"><span class="javascript">$(<span class="string">&quot;span.errorMsg&quot;</span>).text(<span class="string">&quot;验证码不能为空！&quot;</span>);</span></span><br><span class="line"><span class="javascript"><span class="keyword">return</span> <span class="literal">false</span>;</span></span><br><span class="line"><span class="javascript">&#125;</span></span><br><span class="line"><span class="javascript"></span></span><br><span class="line"><span class="javascript">$(<span class="string">&quot;span.errorMsg&quot;</span>).text(<span class="string">&quot;&quot;</span>); <span class="comment">//合法将不合法信息去除</span></span></span><br><span class="line"><span class="javascript">&#125;);</span></span><br><span class="line"><span class="javascript">&#125;);</span></span><br><span class="line"><span class="javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">style</span> <span class="attr">type</span>=<span class="string">&quot;text/css&quot;</span>&gt;</span><span class="css"></span></span><br><span class="line"><span class="css"><span class="selector-class">.login_form</span>&#123;</span></span><br><span class="line"><span class="css"><span class="attribute">height</span>:<span class="number">420px</span>;</span></span><br><span class="line"><span class="css"><span class="attribute">margin-top</span>: <span class="number">25px</span>;</span></span><br><span class="line"><span class="css">&#125;</span></span><br><span class="line"><span class="css"></span></span><br><span class="line"><span class="css"></span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;login_header&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">class</span>=<span class="string">&quot;logo_img&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;&quot;</span> <span class="attr">src</span>=<span class="string">&quot;../../static/img/logo.gif&quot;</span> &gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;login_banner&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;l_content&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;login_word&quot;</span>&gt;</span>欢迎注册<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;content&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;login_form&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;login_box&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;tit&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>注册尚硅谷会员<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;errorMsg&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;form&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;regist_success.html&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">label</span>&gt;</span>用户名称：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">class</span>=<span class="string">&quot;itxt&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;请输入用户名&quot;</span> <span class="attr">autocomplete</span>=<span class="string">&quot;off&quot;</span> <span class="attr">tabindex</span>=<span class="string">&quot;1&quot;</span> <span class="attr">name</span>=<span class="string">&quot;username&quot;</span> <span class="attr">id</span>=<span class="string">&quot;username&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">label</span>&gt;</span>用户密码：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">class</span>=<span class="string">&quot;itxt&quot;</span> <span class="attr">type</span>=<span class="string">&quot;password&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;请输入密码&quot;</span> <span class="attr">autocomplete</span>=<span class="string">&quot;off&quot;</span> <span class="attr">tabindex</span>=<span class="string">&quot;1&quot;</span> <span class="attr">name</span>=<span class="string">&quot;password&quot;</span> <span class="attr">id</span>=<span class="string">&quot;password&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">label</span>&gt;</span>确认密码：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">class</span>=<span class="string">&quot;itxt&quot;</span> <span class="attr">type</span>=<span class="string">&quot;password&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;确认密码&quot;</span> <span class="attr">autocomplete</span>=<span class="string">&quot;off&quot;</span> <span class="attr">tabindex</span>=<span class="string">&quot;1&quot;</span> <span class="attr">name</span>=<span class="string">&quot;repwd&quot;</span> <span class="attr">id</span>=<span class="string">&quot;repwd&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">label</span>&gt;</span>电子邮件：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">class</span>=<span class="string">&quot;itxt&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;请输入邮箱地址&quot;</span> <span class="attr">autocomplete</span>=<span class="string">&quot;off&quot;</span> <span class="attr">tabindex</span>=<span class="string">&quot;1&quot;</span> <span class="attr">name</span>=<span class="string">&quot;email&quot;</span> <span class="attr">id</span>=<span class="string">&quot;email&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">label</span>&gt;</span>验证码：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">class</span>=<span class="string">&quot;itxt&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">style</span>=<span class="string">&quot;width: 150px;&quot;</span> <span class="attr">id</span>=<span class="string">&quot;code&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">alt</span>=<span class="string">&quot;&quot;</span> <span class="attr">src</span>=<span class="string">&quot;../../static/img/code.bmp&quot;</span> <span class="attr">style</span>=<span class="string">&quot;float: right; margin-right: 40px&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span> <span class="attr">value</span>=<span class="string">&quot;注册&quot;</span> <span class="attr">id</span>=<span class="string">&quot;sub_btn&quot;</span> /&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;bottom&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">span</span>&gt;</span></span><br><span class="line">尚硅谷书城.Copyright <span class="symbol">&amp;copy;</span>2015</span><br><span class="line"><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>演示结果</strong><br><img src="https://img-blog.csdnimg.cn/a11b2ccd916943cbaa6b8dab05a66597.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="结果"></p><hr><h1 id="login部分"><a href="#login部分" class="headerlink" title="login部分"></a>login部分</h1><p>login部分也是一样的思路，因为表单标签没有提供 <code>id</code>，我们要为其添加一个<code>id</code> 标签，即修改原始代码如下</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">&quot;username&quot;</span> <span class="attr">class</span>=<span class="string">&quot;itxt&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;请输入用户名&quot;</span> <span class="attr">autocomplete</span>=<span class="string">&quot;off&quot;</span> <span class="attr">tabindex</span>=<span class="string">&quot;1&quot;</span> <span class="attr">name</span>=<span class="string">&quot;username&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">&quot;password&quot;</span> <span class="attr">class</span>=<span class="string">&quot;itxt&quot;</span> <span class="attr">type</span>=<span class="string">&quot;password&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;请输入密码&quot;</span> <span class="attr">autocomplete</span>=<span class="string">&quot;off&quot;</span> <span class="attr">tabindex</span>=<span class="string">&quot;1&quot;</span> <span class="attr">name</span>=<span class="string">&quot;password&quot;</span> /&gt;</span></span><br></pre></td></tr></table></figure><p>后面就和注册一样的思路，利用 <code>JQuery</code> 验证表单即可。<br><strong>login.html 全部代码如下</strong></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>尚硅谷会员登录页面<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">type</span>=<span class="string">&quot;text/css&quot;</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;../../static/css/style.css&quot;</span> &gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span> <span class="attr">src</span>=<span class="string">&quot;../../static/script/jquery-1.7.2.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript"><span class="comment">// 页面加载完成之后</span></span></span><br><span class="line"><span class="javascript">$(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">$(<span class="string">&quot;#sub_btn&quot;</span>).click(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript"></span></span><br><span class="line"><span class="javascript"><span class="comment">// 验证用户名：必须由字母，数字下划线组成，并且长度为5到12位</span></span></span><br><span class="line"><span class="javascript"><span class="comment">//1 获取用户名输入框里的内容</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> usernameText = $(<span class="string">&quot;#username&quot;</span>).val();</span></span><br><span class="line"><span class="javascript"><span class="comment">//2 创建正则表达式对象</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> usernamePatt = <span class="regexp">/^\w&#123;5,12&#125;$/</span>;</span></span><br><span class="line"><span class="javascript"><span class="comment">//3 使用test方法验证</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">if</span>(!usernamePatt.test(usernameText)) &#123;</span></span><br><span class="line"><span class="javascript"><span class="comment">//4 提示用户结果</span></span></span><br><span class="line"><span class="javascript">$(<span class="string">&quot;span.errorMsg&quot;</span>).text(<span class="string">&quot;用户名不合法！&quot;</span>);</span></span><br><span class="line"><span class="javascript"><span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// 让其不跳转</span></span></span><br><span class="line"><span class="javascript">&#125;</span></span><br><span class="line"><span class="javascript"></span></span><br><span class="line"><span class="javascript"><span class="comment">// 验证密码：必须由字母，数字下划线组成，并且长度为5到12位</span></span></span><br><span class="line"><span class="javascript"><span class="comment">//1 获取密码输入框里的内容</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> passwordText = $(<span class="string">&quot;#password&quot;</span>).val();</span></span><br><span class="line"><span class="javascript"><span class="comment">//2 创建正则表达式对象</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> passwordPatt = <span class="regexp">/^\w&#123;5,12&#125;$/</span>;</span></span><br><span class="line"><span class="javascript"><span class="comment">//3 使用test方法验证</span></span></span><br><span class="line"><span class="javascript"><span class="keyword">if</span>(!passwordPatt.test(passwordText)) &#123;</span></span><br><span class="line"><span class="javascript"><span class="comment">//4 提示用户结果</span></span></span><br><span class="line"><span class="javascript">$(<span class="string">&quot;span.errorMsg&quot;</span>).text(<span class="string">&quot;密码不合法！&quot;</span>);</span></span><br><span class="line"><span class="javascript"><span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// 让其不跳转</span></span></span><br><span class="line"><span class="javascript">&#125;</span></span><br><span class="line"><span class="javascript"></span></span><br><span class="line"><span class="javascript">$(<span class="string">&quot;span.errorMsg&quot;</span>).text(<span class="string">&quot;&quot;</span>); <span class="comment">//合法将不合法信息去除</span></span></span><br><span class="line"><span class="javascript">&#125;);</span></span><br><span class="line"><span class="javascript">&#125;);</span></span><br><span class="line"><span class="javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;login_header&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">class</span>=<span class="string">&quot;logo_img&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;&quot;</span> <span class="attr">src</span>=<span class="string">&quot;../../static/img/logo.gif&quot;</span> &gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;login_banner&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;l_content&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;login_word&quot;</span>&gt;</span>欢迎登录<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;content&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;login_form&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;login_box&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;tit&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>尚硅谷会员<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;regist.html&quot;</span>&gt;</span>立即注册<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;msg_cont&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">b</span>&gt;</span><span class="tag">&lt;/<span class="name">b</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;errorMsg&quot;</span>&gt;</span>请输入用户名和密码<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;form&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;login_success.html&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">label</span>&gt;</span>用户名称：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">&quot;username&quot;</span> <span class="attr">class</span>=<span class="string">&quot;itxt&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;请输入用户名&quot;</span> <span class="attr">autocomplete</span>=<span class="string">&quot;off&quot;</span></span></span><br><span class="line"><span class="tag">   <span class="attr">tabindex</span>=<span class="string">&quot;1&quot;</span> <span class="attr">name</span>=<span class="string">&quot;username&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">label</span>&gt;</span>用户密码：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">&quot;password&quot;</span> <span class="attr">class</span>=<span class="string">&quot;itxt&quot;</span> <span class="attr">type</span>=<span class="string">&quot;password&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;请输入密码&quot;</span> <span class="attr">autocomplete</span>=<span class="string">&quot;off&quot;</span></span></span><br><span class="line"><span class="tag">   <span class="attr">tabindex</span>=<span class="string">&quot;1&quot;</span> <span class="attr">name</span>=<span class="string">&quot;password&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span> <span class="attr">value</span>=<span class="string">&quot;登录&quot;</span> <span class="attr">id</span>=<span class="string">&quot;sub_btn&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;bottom&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">span</span>&gt;</span></span><br><span class="line">尚硅谷书城.Copyright <span class="symbol">&amp;copy;</span>2015</span><br><span class="line"><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>演示结果</strong><br><img src="https://img-blog.csdnimg.cn/825385f7bb5947c4a97dd9d04e1ec1c0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="结果"></p>]]></content>
      
      
      <categories>
          
          <category> JavaWeb书城项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaWeb前端 </tag>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C和指针学习笔记(四)——内存操作</title>
      <link href="/2021/10/28/C-note-4/"/>
      <url>/2021/10/28/C-note-4/</url>
      
        <content type="html"><![CDATA[<blockquote><p>这个系列主要是我学习《C和指针》这本书的一些笔记，主要关于一些小的细节，目的是供自己学习和参考，详细地部分建议大家可以阅读一下《C和指针》这本书</p></blockquote><hr><p>根据定义，字符串由一个 <code>NUL</code> 字节结尾，所以字符串内部不能包含任何 <code>NUL</code> 字符。但是，非字符串数据内部包含零值的情况并不罕见。我们无法使用字符串函数来处理这种类型的数据，因为当它们遇到第 <strong>1</strong> 个 <code>NUL</code> 字节时将停止工作。<br>不过，我们可以使用另外一组相关的函数，它们的操作与字符串函数类似，但这些函数能够处理任意的字节序列。下面是它们的原型：</p><span id="more"></span><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">memcpy</span><span class="params">( <span class="keyword">void</span> *dst, <span class="keyword">void</span> <span class="keyword">const</span> *src, <span class="keyword">size_t</span> length )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">memmove</span><span class="params">( <span class="keyword">void</span> *dst, <span class="keyword">void</span> <span class="keyword">const</span> *src, <span class="keyword">size_t</span> length )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">memcmp</span><span class="params">( <span class="keyword">void</span> <span class="keyword">const</span> *a, <span class="keyword">void</span> <span class="keyword">const</span> *b, <span class="keyword">size_t</span> length )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">memchr</span><span class="params">( <span class="keyword">void</span> <span class="keyword">const</span> *a, <span class="keyword">int</span> ch, <span class="keyword">size_t</span> length )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">memset</span><span class="params">( <span class="keyword">void</span> *a, <span class="keyword">int</span> ch, <span class="keyword">size_t</span> length )</span></span>;</span><br></pre></td></tr></table></figure><p>每个原型都包含一个显式的参数来说明需要处理的字节数。但和 <code>strn</code> 带头的函数不同，它们在遇到 <code>NUL</code> 字节时并不会停止操作。</p><hr><h1 id="memcpy"><a href="#memcpy" class="headerlink" title="memcpy"></a>memcpy</h1><p><code>memcpy</code> 从 <code>src</code> 的起始位置复制 <code>length</code> 个字节到 <code>dst</code> 的内存起始位置。可以用这种方式复制任何类型的值，第 <strong>3</strong> 个参数指定复制值的长度（以字节计）。如果 <code>src</code> 和 <code>dst</code> 以任何形式出现了重叠，它的结果是未定义的。<br><strong>例如</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> temp[SIZE], values[SIZE];</span><br><span class="line">...</span><br><span class="line"><span class="built_in">memcpy</span>( temp, values, SIZE );</span><br></pre></td></tr></table></figure><p>它从数组 <code>values</code> 复制 <code>SIZE</code> 个字节到数组 <code>temp</code>。<br>但是，如果两个数组都是整型数组该怎么办呢？下面的语句可以完成这项任务：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">memcpy</span>( temp, values, <span class="keyword">sizeof</span>( valies ) );</span><br></pre></td></tr></table></figure><p>前两个参数并不需要强制类型转换，因为在函数的原型中，参数的类型是 <code>void*</code> 型指针，而任何类型的指针都可以转换为 <code>void*</code> 型指针。<br>如果数组只有部分内容需要复制，那么需要复制的数量必须在第 <strong>3</strong> 个参数中指明。对于长度大于一个字节的数据，要确保把数量和数据类型的长度相乘，例如：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">memcpy</span>( saved_answers, answers, count * <span class="keyword">sizeof</span>( answers[<span class="number">0</span>] ) ); </span><br></pre></td></tr></table></figure><p>也可以用这种技巧复制结构或结构数组。</p><hr><h1 id="memmove"><a href="#memmove" class="headerlink" title="memmove"></a>memmove</h1><p> <code>memmove</code> 函数的行为和 <code>memcpy</code> 差不多，只是它的源操作数和目标操作数可以重叠。虽然它并不需要以下面这种方法实现，但 <code>memmove</code> 的结果和这种方法的结果相同：<strong>把源操作数复制到一个临时位置，这个临时位置不会与源或目标操作数重叠，然后再把它从这个临时位置复制到目标操作数</strong>。<br> <code>memmove</code>通常无法使用某些机器所提供的特殊的字节-字符串处理指令来实现，所以它可能比 <code>memcpy</code> 慢一些。但是，如果源和目标参数真的可能存在重叠，就应该使用 <code>memmove</code>，如下例所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** Shift the values in the x array left one position.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">memmove( x, x + <span class="number">1</span>, ( count - <span class="number">1</span> ) * <span class="keyword">sizeof</span>( x[ <span class="number">0</span> ] ) );</span><br></pre></td></tr></table></figure><hr><h1 id="memcmp"><a href="#memcmp" class="headerlink" title="memcmp"></a>memcmp</h1><p><code>memcmp</code> 对两段内存中的内容进行比较，这两段内存分别起始于 <code>a</code> 和 <code>b</code>，共比较 <code>length</code> 个字节。这些值按照无符号字符逐字节进行比较，函数的返回类型和 <code>strcmp</code> 函数一样——负值表示 <code>a</code> 小于 <code>b</code>，正值表示 <code>a</code> 大于 <code>b</code>，零表示 <code>a</code> 等于 <code>b</code>。由于这些值是根据一串无符号字节进行比较的，因此如果 <code>memcmp</code> 函数用于比较不是单字节的数据（如整数或浮点数），就可能给出不可预料的结果，</p><hr><h1 id="memchr"><a href="#memchr" class="headerlink" title="memchr"></a>memchr</h1><p><code>memchr</code> 从 <code>a</code> 的起始位置开始查找字符 <code>ch</code> 第 <strong>1</strong> 次出现的位置，并返回一个指向该位置的指针，它共查找 <code>length</code> 个字节。如果在这 <code>length</code> 个字节中未找到该字符，函数就返回一个 <code>NULL</code> 指针。</p><hr><h1 id="memset"><a href="#memset" class="headerlink" title="memset"></a>memset</h1><p><code>memset</code> 函数把从 <code>a</code> 开始的 <code>length</code> 个字节都设置为字符值 <code>ch</code>。例如:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">memset</span>( buffer, <span class="number">0</span>, SIZE );</span><br></pre></td></tr></table></figure><p>把 <code>buffer</code>的前 <code>SIZE</code> 个字节都初始化为 <code>0</code>。</p>]]></content>
      
      
      <categories>
          
          <category> C </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C </tag>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C和指针学习笔记(三)——字符操作</title>
      <link href="/2021/10/28/C-note-3/"/>
      <url>/2021/10/28/C-note-3/</url>
      
        <content type="html"><![CDATA[<blockquote><p>这个系列主要是我学习《C和指针》这本书的一些笔记，主要关于一些小的细节，目的是供自己学习和参考，详细地部分建议大家可以阅读一下《C和指针》这本书</p></blockquote><hr><h1 id="字符分类"><a href="#字符分类" class="headerlink" title="字符分类"></a>字符分类</h1><p>每个分类函数接受一个包含字符值的整型参数。函数测试这个字符并返回一个整型值，表示真或假。下表列出了这些字符分类函数以及它们每个所执行的测试。</p><span id="more"></span><table><thead><tr><th>函数</th><th>如果它的参数符合下列条件就返回真</th></tr></thead><tbody><tr><td>iscntrl</td><td>任何控制字符</td></tr><tr><td>isspace</td><td>空白字符：空格’ ‘、换页 ‘\f’、换行’\n’、回车’\r’、制表符’\t’ 或垂直制表符’\v’</td></tr><tr><td>isdigit</td><td>十进制数字 0~9</td></tr><tr><td>isxdigit</td><td>十六进制数字，包括所有十进制数字、小写字母 a~f、大写字母 A~F</td></tr><tr><td>islower</td><td>小写字母 a~z</td></tr><tr><td>isupper</td><td>大写字母 A~Z</td></tr><tr><td>isalpha</td><td>字母 a~z 或 A~Z</td></tr><tr><td>isalnum</td><td>字母或数字 (a~z、A~Z 或 0~9)</td></tr><tr><td>ispunct</td><td>标点符号，任何不属于数字或字母的图形字符（可打印字符）</td></tr><tr><td>isgraph</td><td>任何图形字符</td></tr><tr><td>isprint</td><td>任何可打印字符，包括图形字符和空白字符</td></tr></tbody></table><h1 id="字符转换"><a href="#字符转换" class="headerlink" title="字符转换"></a>字符转换</h1><p>转换函数用于把大写字母转换为小写字母或者把小写字母转换为大写字母、</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">tolower</span><span class="params">( <span class="keyword">int</span> ch )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">toupper</span><span class="params">( <span class="keyword">int</span> ch )</span></span>;</span><br></pre></td></tr></table></figure><p><code>toupper</code> 函数返回其参数的对应大写形式，<code>tolower</code> 函数返回其参数的对应小写形式。如果函数的参数并不是一个处于适当大小写状态的字符（即 <code>toupper</code> 的参数不是小写字母或 <code>tolower</code>的参数不是个大写字母），函数将不修改参数，而是直接返回。<br><strong>注意</strong><br>直接测试或操作字符会降低程序的可移植性。例如，考虑下面这条语句，它试图测试 <code>ch</code>是否是一个大写字符。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>( ch &gt;= <span class="string">&#x27;A&#x27;</span> &amp;&amp; ch &lt;= <span class="string">&#x27;Z&#x27;</span> )</span><br></pre></td></tr></table></figure><p>   这条语句在使用 <code>ASCII</code> 字符集的机器上能够运行，但在使用 <code>EBCDIC</code> 字符集的机器上将会失败。另外，下面这条语句</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>( <span class="built_in">isupper</span>( ch ) )</span><br></pre></td></tr></table></figure><p>无论机器使用哪个字符集，它都能顺利运行。</p>]]></content>
      
      
      <categories>
          
          <category> C </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C </tag>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C和指针学习笔记(二)——字符串常用库函数</title>
      <link href="/2021/10/28/C-note-2/"/>
      <url>/2021/10/28/C-note-2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>这个系列主要是我学习《C和指针》这本书的一些笔记，主要关于一些小的细节，目的是供自己学习和参考，详细地部分建议大家可以阅读一下《C和指针》这本书</p></blockquote><hr><h1 id="字符串长度"><a href="#字符串长度" class="headerlink" title="字符串长度"></a>字符串长度</h1><p>库函数 <code>strlen</code> 的原型如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">size_t</span> <span class="title">strlen</span><span class="params">( <span class="keyword">char</span> <span class="keyword">const</span> *<span class="built_in">string</span> )</span></span>;</span><br></pre></td></tr></table></figure><p>注意 <code>strlen</code> 返回一个类似为 <code>size_t</code> 的值。这个类型是在头文件 <code>stddef.h</code> 中定义的，它是一个无符号整数类型。在表达式中使用无符号数可能导致不可预料的结果。例如，下面两个表达式看上去是相等的：</p><span id="more"></span><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>( <span class="built_in">strlen</span>( x ) &gt;= <span class="built_in">strlen</span>( y ) ) ...</span><br><span class="line"><span class="keyword">if</span>( <span class="built_in">strlen</span>( x ) - <span class="built_in">strlen</span>( y ) &gt;= <span class="number">0</span> ) ...</span><br></pre></td></tr></table></figure><p>但事实上它们是不相等的。第 <strong>1</strong> 条语句将按照你预想的那样工作，但第 <strong>2</strong> 条语句的结果将永远是真。<code>strlen</code> 的结果是个无符号数，所以操作符 <code>&gt;=</code> 左边的表达式也将是无符号数，而无符号数绝不可能是负的。<br><strong>一个栗子</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">char</span> s[] = <span class="string">&quot;123456&quot;</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, <span class="built_in">strlen</span>(s)); <span class="comment">//输出6</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="不受限制的字符串函数"><a href="#不受限制的字符串函数" class="headerlink" title="不受限制的字符串函数"></a>不受限制的字符串函数</h1><p>最常用的字符串都是 “不受限制” 的，也就是说它们只是通过寻找字符串参数结尾的 <code>NUL</code> 字节来判断它的长度，这些函数一般都指定一块内存用于存放结果字符串。在使用这些函数时，程序员必须保证结果字符串不会溢出这块内存。</p><h2 id="复制字符串"><a href="#复制字符串" class="headerlink" title="复制字符串"></a>复制字符串</h2><p>用于复制字符串的函数是 <code>strcpy</code> ，它的原型如下所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">char</span> *<span class="title">strcpy</span><span class="params">( <span class="keyword">char</span> *dst, <span class="keyword">char</span> <span class="keyword">const</span> *src )</span></span>;</span><br></pre></td></tr></table></figure><p>这个函数把参数 <code>src</code> 字符串复制到 <code>dst</code> 参数，返回结果为一个指向目标字符数组的指针。如果参数 <code>src</code> 和 <code>dst</code> 在内存中出现重叠，其结果是未定义的。由于 <code>dst</code> 参数将进行修改，因此它必须是个字符数组或者是一个指向动态分配内存的数组的指针，不能使用字符串常量。<br><strong>需要注意目标字符数组的空间足以容纳需要复制的字符串。否则将会覆盖数组后面的内存空间的值。</strong><br><strong>一个栗子</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">char</span> s1[] = <span class="string">&quot;123456&quot;</span>;</span><br><span class="line">    <span class="keyword">char</span> s2[] = <span class="string">&quot;890&quot;</span>;</span><br><span class="line">    <span class="built_in">strcpy</span>(s1, s2);</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>; s1[i]; ++i)</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>, s1[i]); <span class="comment">//输出 890</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h2 id="连接字符串"><a href="#连接字符串" class="headerlink" title="连接字符串"></a>连接字符串</h2><p>要想把一个字符串添加（连接）到另一个字符串的后面，可以使用 <code>strcat</code> 函数。它的原型如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">char</span> *<span class="title">strcat</span><span class="params">( <span class="keyword">char</span> *dst, <span class="keyword">char</span> <span class="keyword">const</span> *src )</span></span>;  </span><br></pre></td></tr></table></figure><p><code>strcat</code>函数要求 <code>dst</code> 参数原先已经包含了一个字符串(可以是空字符串)。它找到这个字符串的末尾，并把 <code>src</code> 字符串的一份副本添加到这个位置，返回结果为指向目标字符数组的指针。如果 <code>src</code> 和 <code>dst</code> 的位置发生重叠，其结果是未定义的。<br><strong>一个栗子</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">char</span> s1[<span class="number">100</span>] = <span class="string">&quot;123456&quot;</span>;</span><br><span class="line">    <span class="keyword">char</span> s2[] = <span class="string">&quot;890&quot;</span>;</span><br><span class="line">    <span class="built_in">strcat</span>(s1, s2);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; s1[i]; ++i)</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>, s1[i]); <span class="comment">//输出 1234567890</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h2 id="字符串比较"><a href="#字符串比较" class="headerlink" title="字符串比较"></a>字符串比较</h2><p>库函数 <code>strcmp</code> 用于比较两个字符串，它的原型如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">strcmp</span><span class="params">( <span class="keyword">char</span> <span class="keyword">const</span> *s1, <span class="keyword">char</span> <span class="keyword">const</span> *s2 )</span></span>;</span><br></pre></td></tr></table></figure><p>如果 <code>s1</code> 小于 <code>s2</code>，<code>strcmp</code>函数返回一个小于零的值；如果 <code>s1</code> 大于 <code>s2</code>，函数返回一个大于零的值；如果两个字符串相等，函数就返回零。<br><strong>注意这里是词典比较，且相等是输出 0 而不是 1</strong><br><strong>一个栗子</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">char</span> s1[<span class="number">100</span>] = <span class="string">&quot;123456&quot;</span>;</span><br><span class="line">    <span class="keyword">char</span> s2[] = <span class="string">&quot;890&quot;</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, <span class="built_in">strcmp</span>(s1, s2)); <span class="comment">//输出 -1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="长度受限的字符串函数"><a href="#长度受限的字符串函数" class="headerlink" title="长度受限的字符串函数"></a>长度受限的字符串函数</h1><p>标准库还包含了一些函数，它们以一种不同的方式处理字符串。这些函数接受一个显式的长度参数，用于限定进行复制或比较的字符数。这些函数提供了一种方便的机制，可以防止难以预料的长字符串从它们的目标数组溢出。<br>这些函数的原型如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">char</span> *<span class="title">strncpy</span><span class="params">( <span class="keyword">char</span> *dst, <span class="keyword">char</span> <span class="keyword">const</span> *src, <span class="keyword">size_t</span> len )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">char</span> *<span class="title">strncat</span><span class="params">( <span class="keyword">char</span> *dst, <span class="keyword">char</span> <span class="keyword">const</span> *src, <span class="keyword">size_t</span> len )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">strncmp</span><span class="params">( <span class="keyword">char</span> <span class="keyword">const</span> *s1, <span class="keyword">char</span> <span class="keyword">const</span> *s2, <span class="keyword">size_t</span> len )</span></span>;</span><br></pre></td></tr></table></figure><p>和 <code>strcpy</code> 一样，<code>strncpy</code>把源字符串的字符复制到目标数组。然而，它总是正好向 <code>dst</code> 写入 <code>len</code> 个字符。如果 <code>strlen( stc )</code> 的值小于 <code>len</code>，<code>dst</code> 数组就用额外的 <code>NUL</code> 字节填充到 <code>len</code> 长度；如果 <code>strlen( src )</code> 的值大于或等于 <code>len</code>，那么只有 <code>len</code> 个字符被复制到 <code>dst</code> 中。<strong>注意！它的结果将不会以 NUL 字节结尾。</strong></p><hr><h1 id="字符串查找函数"><a href="#字符串查找函数" class="headerlink" title="字符串查找函数"></a>字符串查找函数</h1><h2 id="查找一个字符"><a href="#查找一个字符" class="headerlink" title="查找一个字符"></a>查找一个字符</h2><p>在一个字符串中查找一个特定字符最容易的方法是使用 <code>strchr</code> 和 <code>strrchr</code> 函数，它们的原型如下所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">char</span> *<span class="title">strchr</span><span class="params">( <span class="keyword">char</span> <span class="keyword">const</span> *str, <span class="keyword">int</span> ch )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">char</span> *<span class="title">strrchr</span><span class="params">( <span class="keyword">char</span> <span class="keyword">const</span> *str, <span class="keyword">int</span> ch )</span></span>;</span><br></pre></td></tr></table></figure><p>注意，它们的第 <strong>2</strong> 个参数是一个整型值。但是，它包含了一个字符值。<code>strchr</code> 在字符串 <code>str</code> 中查找字符 <code>ch</code> 第 <strong>1</strong> 次出现的位置，找到后函数返回一个指向该位置的指针。如果该字符并不存在于字符串中，函数就返回一个 <code>NULL</code> 指针。 <code>strrchr</code> 的功能和 <code>strchr</code> 基本一致，只是它所返回的是一个指向字符串该字符最后一次出现的位置（最右边那个）。<br><strong>一个栗子</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">char</span> <span class="built_in">string</span>[<span class="number">20</span>] = <span class="string">&quot;Hello there, honey.&quot;</span>;</span><br><span class="line">    <span class="keyword">char</span> *ans;</span><br><span class="line"></span><br><span class="line">    ans = <span class="built_in">strchr</span>( <span class="built_in">string</span>, <span class="string">&#x27;h&#x27;</span>);</span><br><span class="line">    <span class="keyword">while</span>(*ans)</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>, *ans++); <span class="comment">//输出 here, honey.</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h2 id="查找任何几个字符"><a href="#查找任何几个字符" class="headerlink" title="查找任何几个字符"></a>查找任何几个字符</h2><p><code>strpbrk</code> 是个更为常见的函数。它并不是查找某个特定的字符，而是查找任何一组字符第一次在字符串中出现的位置。它的原型如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">char</span> *<span class="title">strpbrk</span><span class="params">( <span class="keyword">char</span> <span class="keyword">const</span> *str, <span class="keyword">char</span> <span class="keyword">const</span> *group )</span></span>;</span><br></pre></td></tr></table></figure><p>这个函数返回一个指向 <code>str</code> 中第 <strong>1</strong> 个匹配 <code>group</code> 中任何一个字符的字符位置。如果未找到匹配，函数返回一个 <code>NULL</code> 指针。<br><strong>一个栗子</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">char</span> <span class="built_in">string</span>[<span class="number">20</span>] = <span class="string">&quot;Hello there, honey.&quot;</span>;</span><br><span class="line">    <span class="keyword">char</span> *ans;</span><br><span class="line"></span><br><span class="line">    ans = <span class="built_in">strpbrk</span>( <span class="built_in">string</span>, <span class="string">&quot;aeiou&quot;</span>);</span><br><span class="line">    <span class="keyword">while</span>(*ans)</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>, *ans++); <span class="comment">//输出 ello there, honey.</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h2 id="查找一个子串"><a href="#查找一个子串" class="headerlink" title="查找一个子串"></a>查找一个子串</h2><p>为了在字符串中查找一个子串，可以使用 <code>strstr</code> 函数，它的原型如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">char</span> *<span class="title">strstr</span><span class="params">( <span class="keyword">char</span> <span class="keyword">const</span> *s1, <span class="keyword">char</span> <span class="keyword">const</span> *s2 )</span></span>; </span><br></pre></td></tr></table></figure><p>这个函数在 <code>s1</code> 中查找整个 <code>s2</code> 第一次出现的起始位置，并返回一个指向该位置的指针。如果 <code>s2</code> 并没有完整地出现在 <code>s1</code> 的任何地方，函数将返回一个 <code>NULL</code> 指针。如果第 <strong>2</strong> 个参数是一个空字符串，函数就返回 <code>s1</code>。</p><hr><h2 id="查找一个字符串前缀"><a href="#查找一个字符串前缀" class="headerlink" title="查找一个字符串前缀"></a>查找一个字符串前缀</h2><p><code>strspn</code> 和 <code>strcspn</code> 函数用于在字符串的起始位置对字符计数。它们的原型如下所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">size_t</span> <span class="title">strspn</span><span class="params">( <span class="keyword">char</span> <span class="keyword">const</span> *str, <span class="keyword">char</span> <span class="keyword">const</span> *group )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">size_t</span> <span class="title">strcspn</span><span class="params">( <span class="keyword">char</span> <span class="keyword">const</span> *str, <span class="keyword">char</span> <span class="keyword">const</span> *group )</span></span>;</span><br></pre></td></tr></table></figure><p><code>group</code> 字符串指定一个或多个字符。<code>strspn</code>返回 <code>str</code>起始部分匹配 <code>group</code> 中任意字符的字符数。<br><strong>一个栗子</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> len1, len2;</span><br><span class="line">    <span class="keyword">char</span> buffer[] = <span class="string">&quot;25,142,330,Smith,J,239-4123&quot;</span>;</span><br><span class="line">    len1 = <span class="built_in">strspn</span>( buffer, <span class="string">&quot;0123456789&quot;</span> ); <span class="comment">// 2</span></span><br><span class="line">    len2 = <span class="built_in">strspn</span>( buffer, <span class="string">&quot;,0123456789&quot;</span>); <span class="comment">// 11</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d %d\n&quot;</span>, len1, len2 ); <span class="comment">// 输出 2 11</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h2 id="查找标记"><a href="#查找标记" class="headerlink" title="查找标记"></a>查找标记</h2><p><code>strtok</code>函数从字符串中隔离各个单独的称为标记( token )的部分，并丢弃分隔符。它的原型如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">char</span> *<span class="title">strtok</span><span class="params">( <span class="keyword">char</span> *str, <span class="keyword">char</span> <span class="keyword">const</span> *sep )</span></span>;</span><br></pre></td></tr></table></figure><p><code>sep</code> 参数是个字符串，定义了用作分隔符的字符集合。第 <strong>1</strong> 参数指定一个字符串，它包含零个或多个由 <code>sep</code> 字符串中一个或多个分隔符分隔的标记。<code>strtok</code> 找到 <code>str</code> 的下一个标记，并将其用 <code>NUL</code> 结尾，然后返回一个指向这个标记的指针。<br><strong>一个栗子</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">char</span> whitespace[] = <span class="string">&quot; \t\f\r\v\n&quot;</span>;</span><br><span class="line">    <span class="keyword">char</span> *token;</span><br><span class="line">    <span class="keyword">char</span> line[] = <span class="string">&quot;Hello, nice to meet you.&quot;</span>;</span><br><span class="line">    <span class="keyword">for</span>( token = strtok( line, whitespace );</span><br><span class="line">        token != <span class="literal">NULL</span>;</span><br><span class="line">        token = strtok( <span class="literal">NULL</span>, whitespace))</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Next token is %s\n&quot;</span>, token );</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/8b01e407352d40adb5320e2f1aa5b23f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAbmVmdV9jYnc=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="运行结果"></p>]]></content>
      
      
      <categories>
          
          <category> C </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C </tag>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C和指针学习笔记(一)——const常量</title>
      <link href="/2021/10/27/C-note-1/"/>
      <url>/2021/10/27/C-note-1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>这个系列主要是我学习《C和指针》这本书的一些笔记，主要关于一些小的细节，目的是供自己学习和参考，详细地部分建议大家可以阅读一下《C和指针》这本书</p></blockquote><h1 id="一般情况"><a href="#一般情况" class="headerlink" title="一般情况"></a>一般情况</h1><p>我们在编程的过程中，可能会遇到一种量，它的值不会被改变，或者说我们不希望在之后的代码执行过程中改变这个值。<strong>C</strong> 中通过引入 <code>const</code> 修饰符来表示这种量，即常量。如果在代码的执行过程中修改了常量，那么编译器就会报错（暂且算是一种对数据自动的保护机制吧）。</p><span id="more"></span><p><strong>例如</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> N = <span class="number">100</span>; <span class="comment">//定义一个值为100的常量</span></span><br></pre></td></tr></table></figure><hr><h1 id="和指针联用"><a href="#和指针联用" class="headerlink" title="和指针联用"></a>和指针联用</h1><p>一般情况非常容易理解，但 <code>const</code> 修饰符也可以和指针联用来达到一些目的，会有以下三种情况</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> * point1;</span><br><span class="line"><span class="keyword">int</span> <span class="keyword">const</span> * point2;</span><br><span class="line"><span class="keyword">int</span> * <span class="keyword">const</span> point3;</span><br></pre></td></tr></table></figure><p>前面两种情况即 <code>point1</code> 和 <code>point2</code> 都表示指针指向的数据是只读的，但指针本身是可以更改的（改变其指向的地址）<br>最后一种情况，即 <code>point3</code> 表示指针本身是只读的（不可以改变其指向的地址），但指针指向的数据的值是可以改变的。<br><strong>一个具体的栗子</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> b = <span class="number">100</span>;</span><br><span class="line">    <span class="keyword">int</span> c = <span class="number">100</span>;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> a = <span class="number">100</span>;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> * point1;</span><br><span class="line">    <span class="keyword">int</span> <span class="keyword">const</span> * point2;</span><br><span class="line">    <span class="keyword">int</span> * <span class="keyword">const</span> point3 = &amp;b;</span><br><span class="line">    *point3 = <span class="number">101</span>;</span><br><span class="line">    point1 = &amp;a;</span><br><span class="line">    <span class="comment">// *point1 = 101; // 报错</span></span><br><span class="line">    b = <span class="number">101</span>;</span><br><span class="line">    <span class="comment">// point3 = &amp;c; // 报错</span></span><br><span class="line">    <span class="keyword">int</span> * <span class="keyword">const</span> point4 = &amp;a; <span class="comment">// 如果指向一个常量那么可以通过指针修改这个常量</span></span><br><span class="line">    *point4 = <span class="number">101</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, *point4); <span class="comment">// 输出 101</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, a); <span class="comment">//输出 101</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><p>还可以用两个 <code>const</code> 表示一个指向常量的只读指针。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> * <span class="keyword">const</span> point5;</span><br><span class="line"><span class="keyword">int</span> <span class="keyword">const</span> * <span class="keyword">const</span> point6;</span><br></pre></td></tr></table></figure><hr><h1 id="const和函数形参"><a href="#const和函数形参" class="headerlink" title="const和函数形参"></a>const和函数形参</h1><p><code>const</code> 通常用在函数形参中，如果形参是一个指针，为了防止在指针内部修改指针指向的数据，就可以用 <code>const</code> 来限制<br><strong>例如C语言标准库，有很多参数的形参被const限制</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">size_t</span> <span class="title">strlen</span> <span class="params">( <span class="keyword">const</span> <span class="keyword">char</span> * str )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">strcmp</span> <span class="params">( <span class="keyword">const</span> <span class="keyword">char</span> * str1, <span class="keyword">const</span> <span class="keyword">char</span> * str2 )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">char</span> * <span class="title">strcat</span> <span class="params">( <span class="keyword">char</span> * destination, <span class="keyword">const</span> <span class="keyword">char</span> * source )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">char</span> * <span class="title">strcpy</span> <span class="params">( <span class="keyword">char</span> * destination, <span class="keyword">const</span> <span class="keyword">char</span> * source )</span></span>;</span><br></pre></td></tr></table></figure><p>自己也可以使用 <code>const</code> 来限制形参。<br><strong>一个具体的栗子</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">output</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> * a)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// *a = 101; // 报错</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, *a); <span class="comment">// 输出 100</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> b = <span class="number">100</span>;</span><br><span class="line">    output(&amp;b);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h1 id="const-和-非const-类型转换"><a href="#const-和-非const-类型转换" class="headerlink" title="const 和 非const 类型转换"></a>const 和 非const 类型转换</h1><p>当一个指针变量 <code>point1</code> 被 <code>const</code> 限制时，并且类似 <code>const int *point1</code> 这种形式，说明指针指向的数据不能被修改；如果将 <code>point1</code> 赋值给另外一个未被 <code>const</code> 修饰的指针变量 <code>point2</code>，就有可能发生危险。因为通过 <code>point1</code> 不能修改数据，而赋值后通过 <code>point2</code> 能够修改数据了，意义发生了转变，所以编译器不提倡这种行为，会给出错误或警告 (实测有的编译器并不会给出警报和错误，并且能正常运行，比如CB)。<br>也就是说，<code>const int * </code> 和 <code>int *</code> 是不同的类型，不能将 <code>const int *</code> 类型的数据赋值给 <code>int *</code> 类型的变量。但反过来是可以的，编译器允许将 <code>int *</code> 类型的数据赋值给 <code>const int *</code> 类型的变量。<br>这种限制很容易理解，<code>int *</code> 指向的数据有读取和写入权限，而 <code>const int *</code> 指向的数据只有读取权限，降低数据的权限不会带来任何问题，但提升数据的权限就有可能发生危险。<br>C语言标准库中很多函数的参数都被 <code>const</code> 限制了，但我们在以前的编码过程中并没有注意这个问题，经常将非 <code>const</code> 类型的数据传递给 <code>const</code> 类型的形参，这样做从未引发任何副作用，原因就是上面讲到的，将非 <code>const</code> 类型转换为 <code>const</code> 类型是允许的。</p><hr><p><strong>下面是一个将 const 类型赋值给非 const 类型的例子：</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">output</span><span class="params">(<span class="keyword">int</span> * point2)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    *point2 = <span class="number">101</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, *point2); <span class="comment">//输出101</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> b = <span class="number">100</span>;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> * point1 = &amp;b;</span><br><span class="line">    output(point1);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, b); <span class="comment">//输出101</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><p><strong>参考博客</strong><br><a href="http://c.biancheng.net/view/2041.html">C语言const的用法详解，C语言常量定义详解</a></p>]]></content>
      
      
      <categories>
          
          <category> C </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C </tag>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>(=^_^=)</title>
      <link href="/2021/10/27/Welcom/"/>
      <url>/2021/10/27/Welcom/</url>
      
        <content type="html"><![CDATA[<h1 id="Welcom-to-my-blog-site"><a href="#Welcom-to-my-blog-site" class="headerlink" title="Welcom to my blog site !"></a>Welcom to my blog site !</h1>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
